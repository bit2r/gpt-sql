---
editor: 
  markdown: 
    wrap: 72
editor_options: 
  chunk_output_type: console
---

# SQL 데이터셋

[@dataherald2023texttosql]

GPT-4와 Bard 같은 AI 모델의 자연어 처리 능력이 급격히 향상되면서,
자연어로 질문된 내용에 대한 SQL 쿼리를 생성하는 '텍스트-투-SQL'과 같은
다양한 NLP 사용 사례에 대한 발전이 가속화되고 있다. 여러 접근 방식과
솔루션이 시장에 나오면서 어느 것이 가장 효율적인지, 어느 것이 정확한
답을 더 신뢰성 있게 생성하는지, 어느 것이 다양한 데이터셋에 가장 잘
적응하는지 평가하는 문제가 생겼다. 이 질문들에 답하기 위해 오픈소스
산업과 학계는 여러 벤치마크를 제시했지만, 오늘날 가장 많이 사용되는 세
가지는 WikiSQL, Spider, BIRD(BIg Bench for LaRge-scale Database Grounded
Text-to-SQL Evaluation)이다. WikiSQL은 Salesforce에 의해 2017년 말에
소개된 최초의 대규모 텍스트-투-SQL 데이터 집합이지만, 단순함이라는 큰
단점이 있다. 제공되는 모든 SQL 쿼리는 SELECT, FROM, WHERE 절만을
포함하는 매우 간단하며, 데이터셋 내의 테이블들은 다른 테이블과의 연결이
없다. WikiSQL로 훈련된 모델은 새로운 데이터베이스에서도 작동할 수
있지만, 간단한 자연어 질문에 대해서만 답할 수 있다. 이러한 이유로 최근
텍스트-투-SQL 분야의 연구는 더 복잡한 벤치마크에 초점을 맞추고 있다.
실제로 WikiSQL 리더보드에는 2021년 이전의 제출물만 있으며, 테스트 정확도
90% 이상을 달성한 여러 제출물들이 있지만(가장 성능이 좋은 제출물은 93%에
도달함), 이제 실무자들은 WikiSQL로는 턱없이 부족한 훨씬 더 복잡한 쿼리
생성에 초점을 맞추고 있다.

Spider 데이터셋은 WikiSQL 데이터셋의 단점 중 일부를 보완하려고 한다.
예일 대학의 11명 학생들이 1,000시간 이상의 노력을 통해 개발된 Spider
데이터셋은 복잡성과 교차 도메인성이라는 두 가지 중요한 요소를 도입한다.
복잡성 측면에서 SQL 쿼리는 WikiSQL이 한정된 간단한 SELECT와 WHERE 절을
넘어서, 더 복잡한 GROUP BY, ORDER BY, HAVING 절과 중첩된 쿼리를
포함한다. 또한, 모든 데이터베이스는 외래 키를 통해 여러 테이블이
연결되어 있어 테이블 간에 조인하는 복잡한 쿼리를 가능하게 한다. 교차
도메인성 측면에서 Spider는 200개의 복잡한 데이터베이스를 많은 도메인에
걸쳐 포함하여, 테스트 세트에서 본 적 없는 데이터베이스를 포함시켜 모델의
일반화 가능성을 테스트할 수 있게 한다. 

## Sqlite3와 DuckDB



SQLite3와 DuckDB는 각각 OLTP(Online Transaction Processing)와
OLAP(Online Analytical Processing) 관점으로 살펴보면, SQLite3는 OLTP에
더 적합한 데이터베이스로, 애플리케이션 거래 처리(transaction)를 위한
운영 데이터 관리에 사용되고, 빠른 쓰기와 읽기, 낮은 지연 시간, 높은
트랜잭션 보장이 필요한 환경에 맞게 설계되었다. 특히, SQLite는 가벼운
구조와 서버리스 아키텍처로 인해 임베디드 시스템, 모바일 애플리케이션,
소규모 웹 애플리케이션에서 데이터를 저장하고 관리하는 데 자주 사용된다.

반면, DuckDB는 OLAP에 더 적합하며 데이터 분석 작업에 최적화된
데이터베이스로, 큰 규모 데이터셋에 대한 복잡한 쿼리와 데이터 분석을
빠르게 수행할 수 있다. DuckDB의 벡터화 쿼리 처리와 멀티 코어 시스템에서
병렬 처리 능력은 대용량 데이터 분석, 보고서 생성, 데이터 마이닝과 같은
작업에 탁월한 성능을 제공한다. DuckDB는 주로 데이터 과학자들과
분석가들이 사용하는 도구로써, 빅데이터의 효율적인 처리와 복잡한 분석
쿼리를 빠르게 실행시킬 수 있다.

![](images/two_database.jpg)

## 시카고 범죄 데이터

-   [2021년](https://data.cityofchicago.org/Public-Safety/Crimes-2021/dwme-t96c)
-   [2022년](https://data.cityofchicago.org/Public-Safety/Crimes-2022/9hwr-2zxp)
-   [2023년](https://data.cityofchicago.org/Public-Safety/Crimes-2023/xguy-4ndq)

```{r}
library(tidyverse)
library(duckdb)

crime_csv <- fs::dir_ls("data/crime/")

crime_raw <- crime_csv |> 
  enframe(value = "filepath") |> 
  select(-name) |> 
  mutate(data = map(filepath, read_csv)) |> 
  mutate(year = str_extract(filepath, "\\d{4}")) |> 
  select(year, data) 

crime_tbl <- crime_raw |> 
  unnest(data) |> 
  janitor::clean_names()

  
crime_tbl |> 
  glimpse()
```

```{r}
crime_tbl |> 
  count(primary_type, sort = TRUE) |> 
  head(10) |> 
  ggplot(aes(x = fct_reorder(primary_type, n), y = n)) +
    geom_col() +
    coord_flip() +
    labs(x = "범죄 유형", y = "범죄 건수", title = "시카고 범죄 유형별 건수")
```

`DuckDB`는 `Analytical SQLite`라는 별명을 갖고 있다. SQLite가 OLTP
데이터베이스라면, `DuckDB` OLAP 데이터베이스라고 볼 수 있다.

```{r}
con_dd <- duckdb::dbConnect(duckdb::duckdb())

duckdb::dbWriteTable(con_dd, "crime_tbl", crime_tbl, overwrite = TRUE)

duckdb::dbListTables(con_dd)

dbGetQuery(con_dd, "SELECT COUNT(*) AS '범죄수' FROM crime_tbl")
```

```{r}
time <- function(call) {
  print(system.time(call())[[1]])
}

time(\() duckdb::dbWriteTable(con_dd, "crime_tbl", crime_tbl, overwrite = TRUE))

time(\() dbGetQuery(con_dd, "SELECT COUNT(*) AS '범죄수' FROM crime_tbl"))

```

```{r}
library(RSQLite)

con_sqlite <- dbConnect(RSQLite::SQLite())

time(\() RSQLite::dbWriteTable(con_sqlite, "crime_tbl", crime_tbl, overwrite = TRUE))

```

```{r}
crime_schema <- DBI::dbGetQuery(con_dd, 'SELECT * FROM duckdb_tables;')

crime_schema |> 
  select(sql)

```

```{r}
complex_query <- "
  SELECT 
      primary_type,
      ROUND(AVG(latitude), 5) AS avg_latitude,
      ROUND(AVG(longitude), 5) AS avg_longitude,
      SUM(CASE WHEN arrest THEN 1 ELSE 0 END) AS total_arrests,
      COUNT(*) AS total_crimes,
      year
  FROM 
      crime_tbl
  WHERE 
      year >= '2021' AND year <= '2023'
  GROUP BY 
      primary_type, year
  HAVING 
      COUNT(*) > 100
  ORDER BY 
      total_crimes DESC, primary_type
  LIMIT 5;
"

dbGetQuery(con_dd, complex_query)
```

작성된 SQL 쿼리는 시카고 범죄 데이터베이스에서 2021년부터 2023년까지
가장 흔한 범죄 유형 상위 5가지를 찾고, 이들의 평균 발생 위치, 체포 건수,
연도별 발생 횟수를 파악하는 것이다.

-   `WHERE` 절: 범죄 발생 연도를 2021년부터 2023년 사이로 범위를
    제한한다.
-   `GROUP BY` 절: 결과를 범죄 유형(`primary_type`)과 발생
    연도(`year`)별로 그룹화한다.
-   `ROUND(AVG(latitude), 5)` 및 `ROUND(AVG(longitude), 5)`: 각 범죄
    유형의 평균 위도와 경도를 계산하여 범죄가 일반적으로 발생하는 위치를
    파악한다. 평균은 소수점 다섯째 자리까지 반올림된다.
-   `SUM(CASE WHEN arrest THEN 1 ELSE 0 END) AS total_arrests`: 각 범죄
    유형별로 발생한 총 체포 건수를 합산하고, `arrest`가 참일 때마다 1을
    더하는 방식으로 계산한다.
-   `COUNT(*) AS total_crimes`: 각 범죄 유형별로 발생한 총 범죄 건수를
    계산한다.
-   `HAVING COUNT(*) > 100`: 100건 이상 발생한 범죄 유형만을 필터링하여
    신뢰성 있는 데이터만을 대상으로 한다.
-   `ORDER BY total_crimes DESC, primary_type`: 총 범죄 건수가 많은
    순으로 결과를 정렬하고, 동일한 건수일 경우 범죄
    유형(`primary_type`)에 따라 정렬한다.
-   `LIMIT 5`: 결과를 상위 5가지 범죄 유형으로 한정한다.

```{r}
time(\() dbGetQuery(con_dd, complex_query) )

time(\() dbGetQuery(con_sqlite, complex_query) )
```

# `survey.db`

::: {.panel-tabset}

### 프롬프트

``` bash
You are an expert in SQL. The following table definitions have been provided to you. Please convert my query into an appropriate SQL statement.

CREATE TABLE Person(
        ident    text,
        personal text,
        family   text
);
CREATE TABLE Site(
        name text,
        lat  real,
        long real
);
CREATE TABLE Visited(
        ident integer,
        site  text,
        dated text
);
CREATE TABLE Survey(
        taken   integer,
        person  text,
        quant   text,
        reading real
);

Let's write an SQL query to display the names of scientists on the screen.
```

### 출력결과

To write an SQL query that displays the names of scientists, we need to determine which table and column(s) contain the relevant information about the scientists. Based on the provided table definitions, it seems that the `Person` table holds the information about individuals, which likely includes scientists. The columns `personal` and `family` in the `Person` table seem to be the ones that store the names of individuals.

The query would be straightforward, as it involves selecting data from a single table without any joins or complex conditions. Here is the SQL statement:

```sql
SELECT personal, family
FROM Person;
```

This query will display the personal (given name) and family (surname) of each individual in the `Person` table. If you need just the full names combined or have other specific requirements, the query can be adjusted accordingly.

:::

::: {#fig-prompt layout-ncol=2}

![챗GPT 자연어 질의](images/chatGPT_sql_prompt.jpg)

![챗GPT SQL 쿼리 생성](images/chatGPT_sql_result.jpg)

챗GPT 자연어 질의와 SQL 쿼리 생성

:::


## 프로그래밍

GUI 챗팅 인터페이스 대신 프로그래밍을 통해 파악해보자. 
자연어로 SQL 프로그래밍 들어가기 전에 기본적인 설정을 다음과 같이 설정한다. 파이썬에서 OpenAI의 GPT 모델을 사용해 사용자 질문에 자동으로 답하는 스크립트를 작성한다.

1. **모듈 가져오기**: 
   - `os`는 운영 체제와 상호작용하고, 환경 변수에 접근하는 데 사용된다.
   - `openai`는 OpenAI의 Python 클라이언트 라이브러리로, GPT 모델을 사용하는 데 필요하다.
   - `dotenv`는 `.env` 파일에서 환경 변수를 로드하는 데 사용된다.

2. **환경 변수 로드**:
   - `load_dotenv()`는 프로젝트 루트의 `.env` 파일로부터 환경 변수를 로드한다. `.env` 파일에 저장된 `OPENAI_API_KEY` 환경변수를 가져온다.

3. **OpenAI 클라이언트 초기화**:
   - `OpenAI`를 사용해 API 클라이언트를 생성한다.
   - `api_key=os.getenv('OPENAI_API_KEY')`는 환경 변수에서 `OPENAI_API_KEY`를 가져와 클라이언트를 인증한다.

4. **채팅 완성 생성**:
   - `client.chat.completions.create`는 OpenAI의 채팅 완성 API를 사용해 채팅 대화를 생성한다.
   - `messages`는 사용자의 입력 메시지를 담고 있다. 이 경우 "SQL이 뭔지 간략하게 설명해줘"라는 질문이 포함되어 있다.
   - `model="gpt-3.5-turbo"`는 사용할 GPT 모델을 지정한다.

5. **결과 출력**:
   - `print(chat_completion.choices[0].message.content)`는 생성된 채팅 대화에서 첫 번째 선택 항목의 메시지 내용을 출력한다. 이는 GPT 모델이 생성한 답변을 보여준다.

```{python}
#| eval: false
import os
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

client = OpenAI(
    api_key=os.getenv('OPENAI_API_KEY'),
)

chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "SQL이 뭔지 간략하게 설명해줘",
        }
    ],
    model="gpt-3.5-turbo",
)

print(chat_completion.choices[0].message.content)
```

``` bash
SQL(Structured Query Language)은 데이터베이스 관리 시스템(DBMS)에서 데이터를 관리하고 조작하는 데 사용하는 표준화된 프로그래밍 언어입니다. SQL은 사용자가 데이터베이스에 대한 쿼리를 작성하여 데이터를 검색, 삽입, 수정, 삭제하는 등 데이터베이스에 대한 다양한 작업을 수행할 수 있게 해줍니다. SQL은 간결한 구문과 명확한 명령어를 사용하며, 이를 통해 데이터베이스에 저장된 대량의 데이터를 효율적으로 조작할 수 있습니다. SQL은 관계형 데이터베이스 시스템(RDBMS)에서 주로 사용되며, 사용자의 요구에 따라 데이터를 가져오거나 수정하는 등 다양한 작업을 수행할 수 있으므로 데이터베이스 관리에 필수적인 언어로 사용됩니다.
```


```{python}
#| eval: false

sql_message = """
You are an expert in SQL. The following table definitions have been provided to you. Please convert my query into an appropriate SQL statement.

CREATE TABLE Person(
        ident    text,
        personal text,
        family   text
);
CREATE TABLE Site(
        name text,
        lat  real,
        long real
);
CREATE TABLE Visited(
        ident integer,
        site  text,
        dated text
);
CREATE TABLE Survey(
        taken   integer,
        person  text,
        quant   text,
        reading real
);

Let's write an SQL query to display the names of scientists on the screen.
"""

chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": sql_message,
        }
    ],
    model="gpt-3.5-turbo",
)

print(chat_completion.choices[0].message.content)
```

``` bash
To write an SQL query to display the names of scientists on the screen, we need to identify what table contains the names of scientists. Based on the given table definitions, it appears that the "Person" table contains the relevant information. Therefore, we can use the following SQL statement to achieve the desired result:

SELECT personal, family
FROM Person;
```

```{python}
#| eval: false

def create_message(query):

    class message:
        def __init__(message, system, user):
            message.system = system
            message.user = user
    
    system_message = """
    You are an expert in SQL. The following table definitions have been provided to you. Please convert my query into an appropriate SQL statement. \n
    
    CREATE TABLE Person(
            ident    text,
            personal text,
            family   text
    );
    CREATE TABLE Site(
            name text,
            lat  real,
            long real
    );
    CREATE TABLE Visited(
            ident integer,
            site  text,
            dated text
    );
    CREATE TABLE Survey(
            taken   integer,
            person  text,
            quant   text,
            reading real
    ); \n
    """

    user_message = "No explanation. Write only SQL query that returns - {}"

    system = system_message
    user = user_message.format(query)

    m = message(system = system, user = user)
    
    return m


query = "display the names of scientists on the screen"

msg = create_message(query = query)

# print(msg.system)
print(msg.user)
```

``` bash
Write an SQL query that returns - display the names of scientists on the screen
```

```{python}
#| eval: false

query = "display the names of scientists on the screen"
prompt = create_message(query = query)

response = client.chat.completions.create(
    messages = [
      {
        "role": "system",
        "content": prompt.system
      },
      {
        "role": "user",
        "content": prompt.user
      }
    ],
    model="gpt-3.5-turbo",
)

sql = response.choices[0].message.content

print(sql)
```

``` bash
'SELECT personal FROM Person;'
```


```{python}
#| eval: false

def translate_sql(query):
  
  prompt = create_message(query = query)

  response = client.chat.completions.create(
      messages = [
        {
          "role": "system",
          "content": prompt.system
        },
        {
          "role": "user",
          "content": prompt.user
        }
      ],
      model="gpt-3.5-turbo",
  )

  sql = response.choices[0].message.content
  
  return sql

translate_sql(query = 'aggregate the hours for each scientist separately')

```


``` bash
'SELECT person, SUM(reading) AS total_hours\nFROM Survey\nGROUP BY person;'
```

## `dplyr` 연결

## R에서 바라본 SQL  {#r-sql}

NoSQL과 빅데이터가 주목을 받고 있지만, 데이터 분석을 하는 입장에서는 여전히 SQL의 중요성이 크다. SQL에 대한 이해는 데이터 조작의 기본을 다지는 데 필수적이며, 이를 바탕으로 `DBI` 패키지를 사용해 `dplyr`과 연결하여 활용하는 방법을 살펴볼 수 있다.

![dplyr, dbi, sqlite3 변환](images/dplyr-dbi-sqlite.png)


R 개발자들은 데이터 분석을 할 때 `dplyr`을 사용하고, 데이터베이스 작업을 할 때는 `SQL`을 사용하는 것이 일반적인 작업 흐름이었다. 이렇게 두 가지 다른 도구를 사용하는 것은 동일한 작업을 중복해서 수행한다는 불편함을 가져왔다. 그러나 `dplyr`을 다양한 데이터베이스 시스템에 `DBI`와 `odbc`와 연결하면 문제를 해결할 수 있다. 즉, `dplyr` 동사를 직접 사용하여 SQL 작업을 수행할 수 있어 `dplyr` 동사를 데이터베이스에 직접 던져서 작업을 수행할 수 있는 중간 통역이 제공되어 보다 효율적으로 작업을 진행할 수 있게 된다.

### SQL 자료처리 {#sql-basic}

자료를 원하는 방향으로 처리하기 위해서는 다음과 같은 다양한 기본적인 자료 처리 방법을 조합하여 사용한다.

 - 데이터 선택하기
 - 정렬과 중복 제거하기
 - 필터링(filtering)
 - 새로운 값 계산하기
 - 결측 데이터 (Missing Data)
 - 집합 (Aggregation)
 - 데이터 조합하기 (Combining Data)

``` {r}
#| label: sql-select
#| eval: false

# 칼럼과 행 선택
SELECT 칼럼명1, 칼럼명2....칼럼명N
FROM   테이블명
WHERE  조건;

# 그룹에 따른 정렬 및 총계(aggregation)
SELECT SUM(칼럼명)
FROM   테이블명
WHERE  조건
ORDER BY 칼럼명 {오름차순|내림차순};
GROUP BY 칼럼명;
```

### SQLite와 실습 데이터베이스 {#sqlite}

먼저 이론을 이해하는 것과 더블어 예제 데이터베이스를 설치하고 실습을 진행하기 위해서 
먼저 명령-라인을 사용하여 어떻게 디렉토리 여기저기 이동하는지와 명령-라인에서 명령문을 어떻게 실행하는지 숙지할 필요가 있다.

이런 주제와 친숙하지 않다면, [유닉스 쉘(Unix Shell)](http://software-carpentry.org/v5/novice/shell/index.html) 학습을 참조한다. 
우선, `SQLite` 데이터베이스가 어떻게 동작하는지 설명을 할 필요가 있다.

인터랙티브하게 학습을 수행하기 위해서는 [설치 방법](http://software-carpentry.org/v5/setup.html)에 언급된 SQLite 를 참조하여 설치하고, 
학습자가 선택한 위치에 "software_carpentry_sql" 디렉토리를 생성한다. 예를 들어,

1. 명령-라인 터미널 윈도우를 연다.
2. 다음과 같이 명령어를 타이핑해서 디렉토리를 생성한다.

``` {r create-directory, eval=FALSE}
$ mkdir ~/swc/sql
```

3. 생성한 디렉토리로 현재 작업 디렉토리를 변경한다.

``` {r change-directory, eval=FALSE}
$ cd ~/swc/sql
```

## SQLite 설치 [^install-sqlite3] {#install-sqlite}

[^install-sqlite3]: [SQLite3 설치 및 간단한 사용법](http://blog.simplism.kr/?p=2329)





:::{.callout-note}
### 느긋한 계산법

데이터베이스를 다룰 때, `dplyr`은 가능한 느긋(laziness)하게 동작한다.

- 명시적으로 요청하지 않는 한, 데이터를 R 환경으로 바로 가져오지 않는다.
- 가능한 마지막 순간까지 작업을 지연시킨다 - 작업하고 싶은 모든 것을 모아 한 단계로 데이터베이스로 보낸다.

:::

## SQLite DB 연결/설치 테스트 {#connect-sqlite}

생성된 데이터베이스에 연결하기 위해서, 
데이터베이스를 생성한 디렉토리 안에서 SQLite를 시작한다. 
그래서 `~/swc/sql` 디렉토리에서 다음과 같이 타이핑한다.

``` {r run-survey-db, eval=FALSE}
root@hangul:~/swc/sql$ sqlite3 survey.db
```

`sqlite3 survey.db` 명령문이 데이터베이스를 열고 데이터베이스 명령-라인 프롬프트로 안내한다. 
SQLite에서 데이터베이스는 플랫 파일(flat file)로 명시적으로 열 필요가 있다. 
그리고 나서 SQLite 시작되고 `sqlite`로 명령-라인 프롬프트가 다음과 같이 변경되어 표시된다.


``` {r run-survey-db-output, eval=FALSE}
SQLite version 3.20.0 2017-08-01 13:24:15
Enter ".help" for usage hints.
Connected to a transient in-memory database.
Use ".open FILENAME" to reopen on a persistent database.
sqlite>  
```

다음 출력결과가 보여주듯이 `.databases` 명령문으로 소속된 데이터베이스 이름과 파일 목록을 확인한다.

``` {r check-database, eval=FALSE}
sqlite> .databases
seq  name             file                                                      
---  ---------------  ----------------------------------------------------------
0    main             ~/novice/sql/survey.db
```

다음과 같이 타이핑해서 필요한 "Person", "Survey", "Site" "Visited" 테이블이 존재하는 것을 확인한다.
`.table`의 출력결과는 다음과 같다.

``` {r check-tables, eval=FALSE}
sqlite> .tables
Person   Site     Survey   Visited
```

# `dplyr` 동사로 데이터베이스 작업 {#sql-dplyr}

## 데이터베이스 연결 {#db-connection}

가장 먼저 앞에서 생성한 sqlite3 데이터베이스에 R과 연결시킨다. 
그리고 연결된 데이터베이스에 들어있는 테이블을 살펴본다.

``` {r}
# 0. 환경설정 -----------------------

library(dbplyr)
library(tidyverse)

# 1. 데이터 연결 -----------------------

survey_con <- DBI::dbConnect(RSQLite::SQLite(), "data/survey.db")
dbListTables(survey_con)
```

## SQL을 직접 던지기 {#dplyr-sql}

`dbGetQuery` 명령어를 통해 연결된 `con`을 통해 데이터베이스에 질의문(query)를 직접 던질 수 있다.

``` {r sql-query}
# 2. SQL 활용 -----------------------
dbGetQuery(survey_con, 'SELECT * FROM Person LIMIT 5')
```

## dplyr 동사 활용 {#dplyr-dplyr}

`tbl` 함수로 `con` 으로 연결된 데이터베이스의 특정 테이블 "Survey"를 뽑아낸다.

``` {r}
#| label: extract-table

# 3. dplyr 방식 -----------------------

survey_df <- tbl(survey_con, "Survey")
head(survey_df)
```

## 데이터프레임 변환 {#dataframe}

`tbl` 함수로 `con` 으로 연결된 데이터베이스의 특정 테이블 "Survey"를 뽑아낸 상태는 아직
R에서 작업이 가능한 데이터프레임이 아니라 `collect` 함수를 활용해서 데이터프레임으로 변환시켜 
후속 작업을 R에서 실행한다.

``` {r convert-to-dataframe}
# 4. 데이터프레임 변환 -----------------------

survey_df %>% collect() %>% 
    ggplot(aes(x= quant, y=reading)) +
    geom_boxplot()
```

## SQL 변환 과정 살펴보기 {#conversion}

`show_query` 함수를 사용해서 `dplyr` 동사가 SQL 질의문으로 변환된 상황을 살펴볼 수도 있다.

``` {r show-query}
# 5. 내부 SQL 변환과정 살펴보기 --------------


survey_df |> 
  filter(quant == "sal") |> 
  show_query()
```

## 데이터베이스 연결 끊기 {#disconnect}

데이터베이스는 혼자 사용하는 것이 아니라 사용하지 않는 경우 필히 연결시켜 놓은 `con`을 반듯이 끊어 놓는다.

``` {r}
#| label: db-disconnect

# 7. 연결 끊기 -----------------------

dbDisconnect(survey_con)
```

