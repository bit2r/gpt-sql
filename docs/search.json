[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "챗GPT SQL",
    "section": "",
    "text": "감사의 글\n이 책이 탄생할 수 있도록 도움을 주신 여러분께 깊은 감사의 마음을 표합니다.\n기술적인 부분에서 깊은 통찰력을 제공해주신 한국 R 사용자회 유충현 회장님, 챗GPT가 국내에 소개된 후 가장 먼저 챗GPT를 세밀하게 조명할 수 있도록 교육 기회를 주신 경기도의회 문승호, 이자영, 장한별 의원님, 광명시 박승원 시장님, 김규식 부시장님, 김종업 센터장님, 지방행정연구원 최인수, 전대욱, 김필 박사님, 경기도청 AI빅데이터 산업과 이수재 과장님, 원금동, 최정환, 윤여찬 팀장님, 안양시청 엄순용 주무관님, 순천향대학교 박여진 팀장님, 경기도 인재개발원 박선현 주무관님, 나이스 디앤알 박정우 대표님, 남영민 본부장님, 우민호 실장님, 씨지인사이드 박선춘 대표님, 서울교육청 조희연 교육감님, 양신호 원장님, 김선자 장학관님, 서울고 학부모회 오혜석님, 디플래닉스 김범진 전대표님, 장석호 대표님, 이용빈님, 경기도 경제과학진흥원 임문영 상임이사님, 건국대 미래지식교육원 이영범 원장님께 감사드립니다.\n이 책의 공개와 출판이 가능했던 것은 한국 R 사용자회의 지원 덕분입니다. 행정사법인 광화문 최순영 대표님, 한채민 과장님, 법무법인 평안 김형주 변호사님, 법률사무소 하우림 정병운 변호사님, 홍성학 감사님, 김호성님, 김현철님, 형환희님, 한국텍학회 김강수님, 경상국립대 백원희 교수님께 진심으로 감사드립니다.\n한국 R 사용자회 활동에서 소프트웨어 카펜트리의 영향은 결코 무시할 수 없습니다. 소프트웨어 카펜트리를 설립한 Greg Wilson 박사님, 카펜트리 재단의 Kari Jordan 박사님, AsiaR 커뮤니티를 이끌고 계신 Janani Ravi 박사님, 서울 R 미트업에서 발표해주신 제빈 웨스트 교수님, 그리고 곽수영, 장연훈, 김송규, 나성호, 안영찬, 박남호, 공병규, 김용우, 이현진 교수님께 감사의 말씀을 드립니다.\n지적 자극을 주시고 더 넓은 세상을 보게 해주신 국가교육위원회 이배용 위원장님, 정대화 상임위원님, 김수환 전문위원님, 삼정 KPMG 장지수 부대표님, 박문구 전무님, 가톨릭 의대 문건웅 교수님, 성균관대 최재성 교수님, 국무조정실 장명헌 사무관님, 제주대 안도현 교수님, 명지대 박순만 교수님, 이희정 전대표님, 고길곤 교수님, 이원일 교수님에게 깊은 감사의 말씀을 전합니다.\n공공정책분야의 빅데이터 분석 활성화를 격려해주신 노웅래 의원님, 김병욱 의원님, 성남시의회 조정식 의원님, 환경보전협회 남광우 전 상근부회장님, 공공의창 최정묵 박사님, 조원씨앤아이 김대진 대표님, 그리고 이 책 출판에 관심이 많으신 오마이뉴스의 김지현 기자님, 나눔국민운동본부 위정희 이사님에게 감사의 인사를 전합니다.\n이 책이 출간되는데 있어 이들 모든 분들의 도움 없이는 어려웠을 것입니다. 그동안의 관심과 지원에 깊은 감사를 드리며, 이 책이 데이터 과학의 발전과 독자들에게 도움이 될 수 있기를 바라는 마음으로 마무리하겠습니다.",
    "crumbs": [
      "감사의 글"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "들어가며",
    "section": "",
    "text": "엑셀로 대표되는 스프레드시트를 사용하는 것은 많은 사람들에게 익숙한 경험이다. 이들은 데이터를 쉽게 조작하고 분석할 수 있는 기본적인 도구로 활용되지만, 데이터셋이 복잡해지면서 한계에 부딪힌다. 이때 스프레드시트의 한계를 넘어서 데이터베이스의 역할이 중요해진다. 간단한 수치 연산에는 스프레드시트가 충분할 수 있지만, 복잡하고 큰 데이터셋을 빠르고 효율적으로 처리하려면 데이터베이스가 필요하다. SQL(Structured Query Language)은 데이터베이스를 관리하고 조작하는 데 있어 중요한 역할을 한다. 데이터베이스가 어떻게 작동하는지 이해하는 것은 단순한 데이터 조작 능력을 넘어서, 우리가 사용하는 다양한 시스템들이 왜 그런 방식으로 작동하는지, 그리고 왜 데이터를 특정한 방식으로 구조화하는지에 대한 깊은 이해를 제공한다.\n이 책은 데이터베이스의 기본 개념과 SQL을 다룬다. 데이터베이스의 기본 개념을 이해하고 SQL을 사용하는 방법을 익히면, 데이터베이스를 사용하는 다양한 시스템들을 쉽게 이해할 수 있다. 또한 데이터베이스를 사용하는 다양한 시스템들을 이해하면, 데이터베이스 기본 개념과 SQL을 더 깊게 이해할 수 있다.",
    "crumbs": [
      "들어가며"
    ]
  },
  {
    "objectID": "setup.html#sqlite-설치",
    "href": "setup.html#sqlite-설치",
    "title": "1  SQLite3",
    "section": "1.1 SQLite 설치",
    "text": "1.1 SQLite 설치\n명령-라인(command-line)을 통해 디렉토리를 이동하고 명령문을 실행하는 방법을 알고 있어야만 이후 학습내용을 빠르게 습득할 수 있다. 명령-라인, 콘솔, 쉘 등 주제가 낯설다면 챗GPT 유닉스 쉘(Unix Shell) 학습 자료를 확인해보길 권한다.\n데이터베이스와 SQL을 본격적으로 학습하기 전에, SQLite3를 설치해야 한다. SQLite3를 설치하는 방법은 운영 체제에 따라 차이가 난다.\n\n1.1.1 윈도우즈 SQLite3 설치\n\nSQLite 다운로드: SQLite 공식 웹사이트(https://www.sqlite.org/download.html)에서 Windows용 바이너리 파일을 다운로드한다.\n압축 해제: 다운로드한 파일을 압축 해제한다.\n시스템 환경 변수 설정: 압축 해제한 SQLite 실행 파일의 경로를 시스템 환경 변수에 추가하여 명령 프롬프트에서 어디서나 SQLite를 실행할 수 있도록 설정한다.\n\n\n\n1.1.2 맥OS SQLite3 설치\n맥OS에는 기본적으로 SQLite3가 설치되어 있지만, 최신 버전을 사용하고 싶다면, 다음 방법을 실행한다.\n\nHomebrew 설치: Homebrew가 설치되어 있지 않다면, 터미널에서 /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" 명령을 실행하여 설치한다.\nSQLite 설치: 터미널에서 brew install sqlite3 명령을 실행하여 SQLite를 설치한다.\n\n\n\n1.1.3 리눅스 SQLite3 설치\n리눅스 배포판 대부분에는 SQLite3가 이미 설치되어 있다. 만약 설치되어 있지 않거나 최신 버전을 설치하고 싶다면, 다음 방법을 사용하여 설치한다.\n\n패키지 관리자 설치: 리눅스 배포판 대부분에는 패키지 관지라를 제공하기 때문에, 우분투(Ubuntu)와 같은 데비안(Debian) 기반 시스템에서는 sudo apt-get install sqlite3 명령을 사용하고, 페도라(Fedora)와 같은 RPM 기반 시스템에서는 sudo yum install sqlite 명령으로 설치한다.\n\n\n\n1.1.4 설치 확인\n설치가 완료되면, 명령 프롬프트나 터미널에서 sqlite3 --version 명령을 실행하여 설치된 SQLite의 버전을 확인할 수 있다.\n$ sqlite3 --version\n3.40.1 2022-12-28 14:03:47 df5c253c0b3dd24916e4ec7cf77d3db5294cc9fd45ae7b9c5e82ad8197f38a24",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>SQLite3</span>"
    ]
  },
  {
    "objectID": "setup.html#데이터베이스-설치",
    "href": "setup.html#데이터베이스-설치",
    "title": "1  SQLite3",
    "section": "1.2 데이터베이스 설치",
    "text": "1.2 데이터베이스 설치\nSQLite3를 설치했다면, 이제 데이터베이스(database)를 설치해야 한다. 데이터베이스는 테이블(table)과 뷰(view) 등의 객체가 포함된 파일이다. SQLite3는 데이터베이스를 생성할 때, 확장자를 지정하지 않는다. 데이터베이스 파일의 이름만 지정해도 되지만, 일반적으로 .db, .sqlite, .sqlite3 등 확장자를 사용하여 데이터베이스 파일임을 명확히 하는 것을 권장한다.\n\n1.2.1 survey.db 생성\n소프트웨어 카펜트리 “데이터베이스와 SQL” 학습 자료에서 사용할 데이터베이스 파일은 웹사이트(https://swcarpentry.github.io/sql-novice-survey/index.html)에서 다음과 같이 로컬 컴퓨터에 다운로드 받아 넣어두면 된다. 데이터베이스 파일 이름은 survey.db로 되어 있다.\n\n\n\nsurvey.db 다운로드\n\n\n또 다른 방법은 명령 프롬프트나 터미널에서 다음과 같이 직접 데이터베이스 파일을 생성하는 것이다.\n\n명령 라인 터미널 윈도우를 연다.\n다음과 같이 타이핑한다.\n\n$ mkdir ~/swc/sql\n\n생성한 디렉토리로 현재 작업 디렉토리를 변경한다.\n\n$ cd ~/swc/sql\n\nGitHub에서 “gen-survey-database.sql” 파일을 다운로드 한다.\n\n\n~/swc/sql 디렉토리로 이동한 후에 그 디렉토리에서 github 사이트 (https://github.com/swcarpentry/bc/blob/master/novice/sql/gen-survey-database.sql) 에 위치한 SQL 파일(“gen-survey-database.sql”)을 다운로드한다.\n파일이 GitHub 저장소 내에 위치하고 있어서, 전체 Git 저장소(git repo)를 복제(cloning)하지 않고 단일 파일만 로컬로 가져온다.\n이 목적을 달성하기 위해서, HTTP, HTTPS, FTP 프로토콜을 지원하는 명령-라인 웹크롤러(web-crawler) 소프트웨어 GNU Wget 혹은, 다양한 프로토콜을 사용하여 데이터를 전송하는데 사용되는 라이브러리이며 명령-라인 도구인 cURL을 사용한다. 두가지 도구 모두 크로스 플랫폼(cross platform)으로 다양한 운영체제를 지원한다.\n\nWget 혹은 cURL을 로컬에 설치한 후에, 터미널에서 다음 명령어를 실행한다.\n\n만약 cURL을 선호한다면, 다음 명령문에서 “wget”을 “curl -O”로 대체한다.\n\n$ wget https://raw.githubusercontent.com/swcarpentry/bc/master/novice/sql/gen-survey-database.sql\n상기 명령문으로 Wget은 HTTP 요청을 생성해서 github 저장소의 “gen-survey-database.sql” 파일만 현재 작업 디렉토리로 가져온다. 성공적으로 완료되면 터미널은 다음 출력결과를 화면에 표시한다.\n\n--2024-01-01 11:49:13--  https://raw.githubusercontent.com/swcarpentry/bc/master/novice/sql/gen-survey-database.sql\n\nLoaded CA certificate '/usr/ssl/certs/ca-bundle.crt'\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3297 (3.2K) [text/plain]\nSaving to: ‘gen-survey-database.sql’\n\n     0K ...                                                   100% 4.15M=0.001s\n\n2024-01-01 11:49:13 (4.15 MB/s) - ‘gen-survey-database.sql’ saved [3297/3297]\nsqlite3 survey.db &lt; gen-survey-database.sql 명령어는 SQLite3 데이터베이스 엔진을 사용하여 survey.db라는 데이터베이스 파일에 gen-survey-database.sql 파일에 포함된 SQL 명령들을 실행한다. 참고로, gen-survey-database.sql 파일에는 데이터베이스 구조를 정의하고 데이터를 삽입하는 SQL 명령들을 포함하고 있다. 예를 들어, Person 테이블 에는 ‘ident’, ‘personal’, ‘family’라는 세 개의 열이 정의되어 있고, 여러 사람의 정보를 테이블에 삽입하는 명령이 포함되어 있으며, ’dyer’, ‘William’, ’Dyer’와 같은 사람이 각각의 열에 맞추어 삽입된다.\n$ sqlite3 survey.db &lt; gen-survey-database.sql",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>SQLite3</span>"
    ]
  },
  {
    "objectID": "setup.html#sqlite-db-연결",
    "href": "setup.html#sqlite-db-연결",
    "title": "1  SQLite3",
    "section": "1.5 SQLite DB 연결",
    "text": "1.5 SQLite DB 연결\n생성된 데이터베이스에 연결하기 위해서, 데이터베이스를 생성한 디렉토리 안에서 SQLite를 시작한다. 그래서 ~/swc/sql 디렉토리에서 다음과 같이 타이핑한다.\n$ sqlite3 survey.db\n“sqlite3 survey.db” 명령문이 데이터베이스를 열고 데이터베이스 명령-라인 프롬프트로 안내한다. SQLite에서 데이터베이스는 플랫 파일(flat file)로 명시적으로 열 필요가 있다. 그리고 나서 SQLite 시작되고 “sqlite”로 명령-라인 프롬프트로 다음과 같이 변경되어 표시된다.\n$ sqlite3 survey.db \nSQLite version 3.34.1 2021-01-20 14:10:07\nEnter \".help\" for usage hints.\nsqlite&gt;\n다음 출력결과가 보여주듯이 .databases 명령문으로 소속된 데이터베이스 이름과 파일 목록을 확인한다.\nsqlite&gt; .databases\nseq  name             file                                                      \n---  ---------------  ----------------------------------------------------------\n0    main             ~/swc/sql/survey.db &lt;/code&gt;&lt;/pre&gt;\n다음과 같이 타이핑해서 필요한 “Person”, “Survey”, “Site” “Visited” 테이블이 존재하는 것을 확인한다.\nsqlite&gt; .tables\n그리고 “.table”의 출력결과는 다음과 같다.\nsqlite&gt; .tables\nPerson   Site     Survey   Visited\n이제, 설치를 완료해서 다음 학습으로 진행할 수 있다. 현재 명령-라인 SQLite 세션에서 다음 연습을 수행할 수 있다.\n\n1.5.1 SQLite3 빠져 나오기\nSQLite3를 빠져나오기 위해서, 다음과 같이 타이핑한다.\nsqlite&gt; .quit\n\n\n\n\n\n\nSQLite3 CLI 대신 IPython notebook 사용방법\n\n\n\n만약 실습으로 IPython notebook 사용을 선호한다면, IPython이 로컬 컴퓨터에 설치되었는지 점검하라. 만약 설치되어 있지 않다면, 설치 방법을 참고하여 설치한다. 만약 IPython이 이미 로컬 컴퓨터에 설치되어 있다면 notebook을 열기 위해서 작업 폴더 ~/swc/sql으로 이동해서 “ipython notebook”을 타이핑한다.\n$ ipython notebook\n상기 명령어가 IPython 커널을 구동해서 디폴트 브라우져에 인터랙티브 노트북을 화면에 표시해서 편집할 수 있게 된다. 작업이 종료되면 변경사항을 간직하기 위해 노트북 저장을 기억하다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>SQLite3</span>"
    ]
  },
  {
    "objectID": "database.html#r-db-what-it-is",
    "href": "database.html#r-db-what-it-is",
    "title": "13  데이터베이스와 SQL",
    "section": "13.1 데이터베이스가 뭔가요?",
    "text": "13.1 데이터베이스가 뭔가요?\n데이터베이스(database)는 데이터를 저장하기 위한 목적으로 조직된 파일이다. 대부분의 데이터베이스는 키(key)와 값(value)를 매핑한다는 의미에서 딕셔너리처럼 조직되었다. 가장 큰 차이점은 데이터베이스는 디스크(혹은 다른 영구 저장소)에 위치하고 있어서, 프로그램 종료 후에도 정보가 계속 저장된다. 데이터베이스가 영구 저장소에 저장되어서, 컴퓨터 주기억장치(memory) 크기에 제한받는 딕셔너리보다 훨씬 더 많은 정보를 저장할 수 있다.\n딕셔너리처럼, 데이터베이스 소프트웨어는 엄청난 양의 데이터 조차도 매우 빠르게 삽입하고 접근하도록 설계되었다. 컴퓨터가 특정 항목으로 빠르게 찾아갈 수 있도록 데이터베이스에 인덱스(indexes)를 추가한다. 데이터베이스 소프트웨어는 인덱스를 구축하여 성능을 보장한다.\n다양한 목적에 맞춰 서로 다른 많은 데이터베이스 시스템이 개발되어 사용되고 있다. Oracle, MySQL, Microsoft SQL Server, PostgreSQL, SQLite이 여기에 포함된다. 이 책에서는 SQLite를 집중해서 살펴볼 것이다. 왜냐하면 매우 일반적인 데이터베이스이며 파이썬에 이미 내장되어 있기 때문이다. 응용프로그램 내부에서 데이터베이스 기능을 제공하도록 SQLite가 다른 응용프로그램 내부에 내장(embedded)되도록 설계되었다. 예를 들어, 다른 많은 소프트웨어 제품이 그렇듯이, 파이어폭스 브라우져도 SQLite를 사용한다.\n\nhttp://sqlite.org/\n\n이번 장에서 기술하는 트위터 스파이더링 응용프로그램처럼 정보과학(Informatics)에서 마주치는 몇몇 데이터 조작 문제에 SQLite가 적합하다.",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>데이터베이스와 SQL</span>"
    ]
  },
  {
    "objectID": "database.html#r-db-concept",
    "href": "database.html#r-db-concept",
    "title": "13  데이터베이스와 SQL",
    "section": "13.2 데이터베이스 개념",
    "text": "13.2 데이터베이스 개념\n처음 데이터베이스를 볼때 드는 생각은 마치 엑셀같은 다중 시트를 지닌 스프레드쉬트(spreadsheet)같다는 것이다. 데이터베이스에서 주요 데이터 구조물은 테이블(tables), 행(rows), and 열(columns)이 된다.\n\n\n\n데이터베이스 개념\n\n\n관계형 데이터베이스의 기술적인 면을 설명하면 테이블, 행, 열의 개념은 관계(relation), 튜플(tuple), 속성(attribute) 각각 형식적으로 매칭된다. 이번 장에서는 조금 덜 형식 용어를 사용한다.",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>데이터베이스와 SQL</span>"
    ]
  },
  {
    "objectID": "database.html#r-db-firefox",
    "href": "database.html#r-db-firefox",
    "title": "13  데이터베이스와 SQL",
    "section": "13.3 파이어폭스 SQLite 관리자",
    "text": "13.3 파이어폭스 SQLite 관리자\nSQLite 데이터베이스 파일에 있는 데이터를 다루기 위해서 이번장에서 주로 R 사용에 집중을 하지만, 다음 웹사이트에서 무료로 이용 가능한 SQLite 데이터베이스 매니저(SQLite Database Manager)로 불리는 파이어폭스 애드온(add-on)을 사용해서 좀더 쉽게 많은 작업을 수행할 수 있다. 파이어폭스 애드온은 크롬 확장 프로그램과 유사한 개념으로 파이어폭스는 개발자들이 많이 사용하는 웹브라우져 중 하나다.\n\nhttps://addons.mozilla.org/en-us/firefox/addon/sqlite-manager/\n\n브라우져를 사용해서 쉽게 테이블을 생성하고, 데이터를 삽입, 편집하고 데이터베이스 데이터에 대해 간단한 SQL 질의를 실행할 수 있다.\n이러한 점에서 데이터베이스 매니저는 텍스트 파일을 작업할 때 사용하는 텍스트 편집기와 유사하다. 텍스트 파일에 하나 혹은 몇개 작업만 수행하고자 하면, 텍스트 편집기에서 파일을 열어 필요한 수정작업을 하고 닫으면 된다. 텍스트 파일에 작업할 사항이 많은 경우는 종종 간단한 R 프로그램을 작성하여 수행한다. 데이터베이스로 작업할 때도 동일한 패턴이 발견된다. 간단한 작업은 데이터베이스 매니저를 통해서 수행하고, 좀더 복잡한 작업은 R로 수행하는 것이 더 편리하다.",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>데이터베이스와 SQL</span>"
    ]
  },
  {
    "objectID": "database.html#r-db-create-table",
    "href": "database.html#r-db-create-table",
    "title": "13  데이터베이스와 SQL",
    "section": "13.4 데이터베이스 테이블 생성",
    "text": "13.4 데이터베이스 테이블 생성\n데이터베이스는 R 리스트 혹은 딕셔너리보다 좀더 명확히 정의된 구조를 요구한다. 1\n데이터베이스에 테이블(table)을 생성할 때, 열(column)의 명칭과 각 열(column)에 저장하는 테이터 형식을 사전에 정의해야 한다. 데이터베이스 소프트웨어가 각 열의 데이터 형식을 인식하게 되면, 데이터 형식에 따라 데이터를 저장하고 찾아오는 방법을 가장 효율적인 방식을 선택할 수 있다.\n다음 url에서 SQLite에서 지원되는 다양한 데이터 형식을 살펴볼 수 있다.\n\nhttp://www.sqlite.org/datatypes.html\n\n처음에는 데이터 구조를 사전에 정의하는 것이 불편하게 보이지만, 대용량의 데이터가 데이터베이스에 포함되더라도 데이터의 빠른 접근을 보장하는 잇점이 있다.\n데이터베이스 파일과 데이터베이스에 두개의 열을 가진 Tracks 이름의 테이블을 생성하는 코드는 다음과 같다.\n\nlibrary(RSQLite)\n\nmusic_db  &lt;- \"data/music.sqlite\"\nconn &lt;- dbConnect(drv = SQLite(), dbname= music_db)\n\ndbSendQuery(conn, \"INSERT INTO Tracks (title, plays) VALUES ( ?, ? )\", c('Thunderstruck', 20))\ndbSendQuery(conn, \"INSERT INTO Tracks (title, plays) VALUES ( ?, ? )\", c('My Way', 15))\n\ndbDisconnect(conn)\n\n연결 (connect) 연산은 현재 디렉토리 data/music.sqlite3 파일에 저장된 데이터베이스에 “연결(connection)”한다. 파일이 존재하지 않으면, 자동 생성된다. “연결(connection)”이라고 부르는 이유는 때때로 데이터베이스가 응용프로그램이 실행되는 서버로부터 분리된 “데이터베이스 서버(database server)”에 저장되기 때문이다. 지금 간단한 예제 파일의 경우에 데이터베이스가 로컬 파일 형태로 R 코드 마찬가지로 동일한 디렉토리에 있다.\n파일을 다루는 파일 핸들(file handle)처럼 데이터베이스에 저장된 파일에 연산을 수행하기 위해서 커서(cursor)를 사용한다. cursor()를 호출하는 것은 개념적으로 텍스트 파일을 다룰 때 readLines()을 호출하는 것과 개념적으로 매우 유사하다.\n\n\n\n데이터베이스 커서\n\n\n커서가 생성되면, dbGetQuery() 함수를 사용하여 데이터베이스 콘텐츠에 명령어 실행을 할 수 있다.\n데이터베이스 명령어는 특별한 언어로 표현된다. 단일 데이터베이스 언어를 학습하도록 서로 다른 많은 데이터베이스 업체 사이에서 표준화되었다.\n데이터베이스 언어를 SQL(Structured Query Language 구조적 질의 언어)로 부른다.\n\nhttp://en.wikipedia.org/wiki/SQL\n\n상기 예제에서, 데이터베이스에 두개의 SQL 명령어를 실행했다. 관습적으로 데이터베이스 키워드는 대문자로 표기한다. 테이블명이나 열의 명칭처럼 사용자가 추가한 명령어 부분은 소문자로 표기한다.\n첫 SQL 명령어는 만약 존재한다면 데이터베이스에서 Tracks 테이블을 삭제한다. 동일한 프로그램을 실행해서 오류 없이 반복적으로 Tracks 테이블을 생성하도록하는 패턴이다. DROP TABLE 명령어는 데이터베이스 테이블 및 테이블 콘텐츠 전부를 삭제하니 주의한다. (즉, “실행취소(undo)”가 없다.)\n`dbGetQuery(conn, 'DROP TABLE IF EXISTS Tracks ') `\n두번째 명령어는 title 문자형 열과 plays 정수형 열을 가진 Tracks으로 명명된 테이블을 생성한다.\n`dbGetQuery(conn, 'CREATE TABLE Tracks (title TEXT, plays INTEGER)')`\n이제 Tracks으로 명명된 테이블을 생성했으니, SQL INSERT 연산을 통해 테이블에 데이터를 넣을 수 있다. 다시 한번, 데이터베이스에 연결하여 커서(cursor)를 얻어 작업을 시작한다. 그리고 나서 커서를 사용해서 SQL 명령어를 수행한다.\nSQL INSERT 명령어는 어느 테이블을 사용할지 특정한다. 그리고 나서 (title, plays) 포함할 필드 목록과 테이블 새로운 행에 저장될 VALUES 나열해서 신규 행을 정의를 마친다. 실제 값이 execute() 호출의 두번째 매개변수로 튜플 ('My Way', 15) 로 넘겨는 것을 표기하기 위해서 값을 물음표 (?, ?)로 명기한다.\n\nlibrary(RSQLite)\n\nmusic_db  &lt;- \"data/music.sqlite\"\nconn &lt;- dbConnect(drv = SQLite(), dbname= music_db)\n\ndbSendQuery(conn, \"INSERT INTO Tracks (title, plays) VALUES ( ?, ? )\", \n            c('Thunderstruck', 20))\ndbSendQuery(conn, \"INSERT INTO Tracks (title, plays) VALUES ( ?, ? )\", \n            c('My Way', 15))\n\nprint('Tracks:')\n\ndbGetQuery(conn, 'SELECT title, plays FROM Tracks')\n\ndbSendQuery(conn, \"DELETE FROM Tracks WHERE plays &lt; 100\")\n\ndbDisconnect(conn)\n\n먼저 테이블에 두개 열을 삽입(INSERT)하여 데이터를 데이터베이스에 저장되도록 했다. 그리고 나서, SELECT 명령어를 사용하여 테이블에 방금 전에 삽입한 행을 불러왔다. SELECT 명령어에서 데이터를 어느 열(title, plays)에서, 어느 테이블Tracks에서 가져올지 명세한다. 프로그램 실행결과는 다음과 같다.\n\n&gt; dbGetQuery(conn, 'SELECT title, plays FROM Tracks')\n          title plays\n1 Thunderstruck    20\n2        My Way    15\n\n프로그램 마지막에 SQL 명령어를 실행 사용해서 방금전에 생성한 행을 모두 삭제(DELETE)했기 때문에 프로그램을 반복해서 실행할 수 있다. 삭제(DELETE) 명령어는 WHERE 문을 사용하여 선택 조건을 표현할 수 있다. 따라서 명령문에 조건을 충족하는 행에만 명령문을 적용한다. 이번 예제에서 기준이 모든 행에 적용되어 테이블에 아무 것도 없게 된다. 따라서 프로그램을 반복적으로 실행할 수 있다. 삭제(DELETE)를 실행한 후에 데이터베이스에서 데이터를 완전히 제거했다.",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>데이터베이스와 SQL</span>"
    ]
  },
  {
    "objectID": "database.html#r-db-sql",
    "href": "database.html#r-db-sql",
    "title": "13  데이터베이스와 SQL",
    "section": "13.5 SQL 요약",
    "text": "13.5 SQL 요약\n지금까지, R 예제를 통해서 SQL(Structured Query Language)을 사용했고, SQL 명령어에 대한 기본을 다루었다. 이번 장에서는 SQL 언어를 보고 SQL 구문 개요를 살펴본다.\n대단히 많은 데이터베이스 업체가 존재하기 때문에 호환성의 문제로 SQL(Structured Query Language)이 표준화되었다. 그래서, 여러 업체가 개발한 데이터베이스 시스템 사이에 호환하는 방식으로 커뮤니케이션 가능하다.\n관계형 데이터베이스는 테이블, 행과 열로 구성된다. 열(column)은 일반적으로 텍스트, 숫자, 혹은 날짜 자료형을 갖는다. 테이블을 생성할 때, 열의 명칭과 자료형을 지정한다.\nCREATE TABLE Tracks (title TEXT, plays INTEGER)\n테이블에 행을 삽입하기 위해서 SQL INSERT 명령어를 사용한다.\nINSERT INTO Tracks (title, plays) VALUES ('My Way', 15)\nINSERT 문장은 테이블 이름을 명기한다. 그리고 나서 새로운 행에 놓고자 하는 열/필드 리스트를 명시한다. 그리고 나서 키워드 VALUES와 각 필드 별로 해당하는 값을 넣는다.\nSQL SELECT 명령어는 데이터베이스에서 행과 열을 가져오기 위해 사용된다. SELECT 명령문은 가져오고자 하는 행과 WHERE절을 사용하여 어느 행을 가져올지 지정한다. 선택 사항으로 ORDER BY 절을 이용하여 반환되는 행을 정렬할 수도 있다.\nSELECT * FROM Tracks WHERE title = 'My Way'\n* 을 사용하여 WHERE 절에 매칭되는 각 행의 모든 열을 데이터베이스에서 가져온다.\n주목할 점은 R과 달리 SQL WHERE 절은 등식을 시험하기 위해서 두개의 등치 기호 대신에 단일 등치 기호를 사용한다. WHERE에서 인정되는 다른 논리 연산자는 &lt;,&gt;,&lt;=,&gt;=,!= 이고, 논리 표현식을 생성하는데 AND, OR, 괄호를 사용한다.\n다음과 같이 반환되는 행이 필드값 중 하나에 따라 정렬할 수도 있다.\nSELECT title,plays FROM Tracks ORDER BY title\n행을 제거하기 위해서, SQL DELETE 문장에 WHERE 절이 필요하다. WHERE 절이 어느 행을 삭제할지 결정한다.\nSELECT title,plays FROM Tracks ORDER BY title\n다음과 같이 SQL UPDATE 문장을 사용해서 테이블에 하나 이상의 행 내에 있는 하나 이상의 열을 갱신(UPDATE)할 수 있다.\nUPDATE Tracks SET plays = 16 WHERE title = 'My Way'\nUPDATE 문장은 먼저 테이블을 명시한다. 그리고 나서, SET 키워드 다음에 변경할 필드 리스트 와 값을 명시한다. 그리고 선택사항으로 갱신될 행을 WHERE절에 지정한다. 단일 UPDATE 문장은 WHERE절에서 매칭되는 모든 행을 갱신한다. 혹은 만약 WHERE절이 지정되지 않으면,테이블 모든 행에 대해서 갱신(UPDATE)을 한다.\n네가지 기본 SQL 명령문(INSERT, SELECT, UPDATE, DELETE)은 데이터를 생성하고 유지 관리하는데 필요한 기본적인 4가지 작업을 가능케 한다.",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>데이터베이스와 SQL</span>"
    ]
  },
  {
    "objectID": "database.html#r-datamodeling-basics",
    "href": "database.html#r-datamodeling-basics",
    "title": "13  데이터베이스와 SQL",
    "section": "13.6 데이터 모델링 기초",
    "text": "13.6 데이터 모델링 기초\n관계형 데이터베이스의 진정한 힘은 다중 테이블과 테이블 사이의 관계를 생성할 때 생긴다. 응용프로그램 데이터를 쪼개서 다중 테이블과 두 테이블 간에 관계를 설정하는 것을 데이터 모델링(data modeling)이라고 한다. 테이블 정보와 테이블 관계를 표현하는 설계 문서를 데이터 모델(data model)이라고 한다.\n데이터 모델링(data modeling)은 상대적으로 고급 기술이여서 이번 장에서는 관계형 데이터 모델링의 가장 기본적인 개념만을 소개한다. 데이터 모델링에 대한 좀더 자세한 사항은 다음 링크에서 시작해 볼 수 있다.\n\nhttp://en.wikipedia.org/wiki/Relational_model\n\n트위터 스파이더 응용프로그램으로 단순히 한 사람의 친구가 몇명인지 세는 대신에, 모든 관계 리스트를 가지고서 특정 계정에 팔로잉하는 모든 사람을 찾는다.\n모두 팔로잉하는 계정을 많이 가지고 있어서, 트위터(Twitter) 테이블에 단순히 하나의 열만을 추가해서는 해결할 수 없다. 그래서 친구를 짝으로 추적할 수 있는 새로운 테이블을 생성한다. 다음이 간단하게 상기 테이블을 생성하는 방식이다.\n    CREATE TABLE Pals (from_friend TEXT, to_friend TEXT)\ndrchuck을 팔로잉하는 사람을 마주칠 때마다, 다음과 같은 형식의 행을 삽입한다.\n    INSERT INTO Pals (from_friend,to_friend) VALUES ('drchuck', 'lhawthorn')\ndrchuck 트위터 피드에서 친구 20명을 처리하면서, “drchuck”을 첫 매개변수로 가지는 20개 레코드를 삽입해서 데이터베이스에 중복되는 많은 문자열이 생길 것이다.\n문자열 데이터 중복은 데이터베이스 정규화(database normalization) 모범 사례(berst practice)를 위반하게 만든다. 기본적으로 데이터베이스 정규화는 데이터베이스에 결코 한번 이상 동일한 문자열을 저장하지 않는다. 만약 한번 이상 데이터가 필요하다면, 그 특정 데이터에 대한 숫자 키(key)를 생성하고, 그 키를 사용하여 실제 데이터를 참조한다.\n실무에서, 문자열이 컴퓨터 주기억장치나 디스크에 저장되는 정수형 자료보다 훨씬 많은 공간을 차지하고 더 많은 처리시간이 비교나 정렬에 소요된다. 항목이 단지 수백개라면, 저장소나 처리 시간이 그다지 문제되지 않는다. 하지만, 데이터베이스에 수백만명의 사람 정보와 1억건 이상의 링크가 있다면, 가능한 빨리 데이터를 스캔하는 것이 정말 중요하다.\n앞선 예제에서 사용된 Twitter 테이블 대신에 People로 명명된 테이블에 트위커 계정을 저장한다. People 테이블은 트위터 사용자에 대한 행과 관련된 숫자키를 저장하는 추가 열(column)이 있다. SQLite는 데이터 열의 특별한 자료형(INTEGER PRIMARY KEY)을 이용하여 테이블에 삽입할 임의 행에 대해서 자동적으로 키값을 추가하는 기능이 있다.\n다음과 같이 추가적인 id 열을 가진 People 테이블을 생성할 수 있다.\n    CREATE TABLE People \n        (id INTEGER PRIMARY KEY, name TEXT UNIQUE, retrieved INTEGER)\nPeople 테이블의 각 행에서 친구 숫자를 더 이상 유지관리하고 있지 않음을 주목하세요. id 열 자료형으로 INTEGER PRIMARY KEY 선택할 때 함축되는 의미는 다음과 같다., 사용자가 삽입하는 각 행에 대해서 SQLite가 자동으로 유일한 숫자 키를 할당하고 관리하게 한다. UNIQUE 키워드를 추가해서 SQLite에 name에 동일한 값을 가진 두 행을 삽입하지 못하게 한다.\n상기 Pals 테이블을 생성하는 대신에, 데이터베이스에 from_id, to_id 두 정수 자료형 열을 지닌 Follows 테이블을 생성한다. Follows 테이블은 from_id과 to_id의 조합으로 테이블이 유일하다는 제약사항도 가진다. (즉, 중복된 행을 삽입할 수 없다.)\n    CREATE TABLE Follows \n        (from_id INTEGER, to_id INTEGER, UNIQUE(from_id, to_id) )\n테이블에 UNIQUE절을 추가한다는 의미는 레코드를 삽입할 때 데이터베이스에서 지켜야하는 규칙 집합을 의사소통하는 것이다. 잠시 후에 보겠지만, 프로그램상에 편리하게 이러한 규칙을 생성한다. 이러한 규칙 집합은 실수를 방지하게 하고 코드를 작성을 간결하게 한다.\n본질적으로 Follows 테이블을 생성할 때, “관계(relationship)”를 모델링하여 한 사람이 다른 사람을 “팔로우(follow)”하고 이것을 (a) 사람이 연결되어 있고, (b) 관계을 방향성이 나타나도록 숫자를 짝지어 표현한다.\n\n\n\n트위터 관계 데이터베이스 모델링\n\n\n\n13.6.1 테이블 제약사항\n테이블 구조를 설계할 때, 데이터베이스 시스템에 몇 가지 규칙을 설정할 수 있다. 이러한 규칙은 실수를 방지하고 잘못된 데이터가 테이블에 들어가는 것을 막는다. 테이블을 생성할 때:\ndbSendQuery( conn, 'CREATE TABLE IF NOT EXISTS People (id INTEGER PRIMARY KEY, name TEXT UNIQUE, retrieved INTEGER)\")\n\ndbSendQuery( conn, 'CREATE TABLE IF NOT EXISTS Follows (from_id INTEGER, to_id INTEGER, UNIQUE(from_id, to_id))')\nPeople 테이블에 name 칼럼이 유일(UNIQUE)함을 나타낸다. Follows 테이블의 각 행에서 두 숫자 조합은 유일하다는 것도 나타낸다. 하나 이상의 동일한 관계를 추가하는 것 같은 실수를 이러한 제약 사항을 통해서 방지한다.\n다음 코드에서 이런 제약사항의 장점을 확인할 수 있다.\ndbSendQuery( conn, 'INSERT OR IGNORE INTO People (name, retrieved) VALUES ( ?, 0)', c( 'friend', ) )\nINSERT 문에 OR IGNORE 절을 추가해서 만약 특정 INSERT가 “name이 유일(unique)해야 한다”를 위반하게 되면, 데이터베이스 시스템은 INSERT를 무시한다. 데이터베이스 제약 사항을 안전망으로 사용해서 무언가가 우연히 잘못되지 않게 방지한다.\n마찬가지로, 다음 코드는 정확히 동일 Follows관계를 두번 추가하지 않는다.\ndbSendQuery( conn, 'INSERT OR IGNORE INTO Follows (from_id, to_id) VALUES (?, ?)', c(id, friend_id) )\n다시 한번, Follows 행에 대해 지정한 유일한 제약사항을 위반하게 되면 INSERT 시도를 무시하도록 데이터베이스에 지시한다.",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>데이터베이스와 SQL</span>"
    ]
  },
  {
    "objectID": "database.html#db-three-keys",
    "href": "database.html#db-three-keys",
    "title": "13  데이터베이스와 SQL",
    "section": "13.7 세 종류 키",
    "text": "13.7 세 종류 키\n지금까지 데이터를 다중 연결된 테이블에 넣고 키(keys)를 사용하여 행을 연결하는 방식으로 데이터 모델을 생성했는데, 키와 관련된 몇몇 용어를 살펴볼 필요가 있다. 일반적으로 데이터베이스 모델에서 세가지 종류의 키가 사용된다.\n\n논리 키(logical key)는 “실제 세상”이 행을 찾기 위해서 사용하는 키다. 데이터 모델 예제에서, name 필드는 논리키다. 사용자에 대해서 screen_name이고, name 필드를 사용하여 프로그램에서 여러번 사용자 행을 찾을 수 있다. 논리 키에 UNIQUE 제약 사항을 추가하는 것이 의미있다는 것을 종종 이해하게 된다. 논리 키는 어떻게 바깥 세상에서 행을 찾는지 다루기 때문에, 테이블에 동일한 값을 가진 다중 행이 존재한다는 것은 의미가 없다.\n주키(primary key)는 통상적으로 데이터베이스에서 자동 대입되는 숫자다. 프로그램 밖에서는 일반적으로 의미가 없고, 단지 서로 다른 테이블에서 행을 열결할 때만 사용된다. 테이블에 행을 찾을 때, 통상적으로 주키를 사용해서 행을 찾는 것이 가장 빠르게 행을 찾는 방법이다. 주키는 정수형이어서, 매우 적은 저장공간을 차지하고 매우 빨리 비교 혹은 정렬할 수 있다. 이번에 사용된 데이터 모델에서 id 필드가 주키의 한 예가 된다.\n외부 키(foreign key)는 일반적으로 다른 테이블에 연관된 행의 주키를 가리키는 숫자다. 이번에 사용된 데이터 모델의 외부 키의 사례는 from_id다.\n\n주키 id필드명을 호출하고, 항상 외부키에 임의 필드명에 접미사로 _id 붙이는 명명규칙을 사용한다.",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>데이터베이스와 SQL</span>"
    ]
  },
  {
    "objectID": "database.html#db-debugging",
    "href": "database.html#db-debugging",
    "title": "13  데이터베이스와 SQL",
    "section": "13.8 디버깅",
    "text": "13.8 디버깅\nSQLite 데이터베이스에 연결하는 파이썬 프로그램을 개발할 때 하나의 일반적인 패턴은 파이썬 프로그램을 실행하고 SQLite 데이터베이스 브라우저를 통해서 결과를 확인하는 것이다. 브라우저를 통해서 빠르게 프로그램이 정상적으로 작동하는지를 확인할 수 있다.\nSQLite에서 두 프로그램이 동시에 동일한 데이터를 변경하지 못하기 때문에 주의가 필요하다. 예를 들어, 브라우저에서 데이터베이스를 열고 데이터베이스에 변경을 하고 “저장(save)”버튼을 누르지 않는다면, 브라우져는 데이터베이스 파일에 “락(lock)”을 걸구, 다른 프로그램이 파일에 접근하는 것을 막는다. 특히, 파일이 잠겨져 있으면 작성하고 있는 파이썬 프로그램이 파일에 접근할 수 없다.\n해결책은 데이터베이스가 잠겨져 있어서 파이썬 코드가 작동하지 않는 문제를 피하도록 파이썬에서 데이터베이스에 접근하려 시도하기 전에 데이터베이스 브라우져를 닫거나 혹은 File 메뉴를 사용해서 브라우져 데이터베이스를 닫는 것이다.",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>데이터베이스와 SQL</span>"
    ]
  },
  {
    "objectID": "database.html#db-terminology",
    "href": "database.html#db-terminology",
    "title": "13  데이터베이스와 SQL",
    "section": "13.9 용어정의",
    "text": "13.9 용어정의\n\n속성(attribute): 튜플 내부에 값의 하나. 좀더 일반적으로 “열”, “칼럼”, “필드”로 불린다.\n제약(constraint): 데이터베이스가 테이블의 필드나 행에 규칙을 강제하는 것. 일반적인 제약은 특정 필드에 중복된 값이 없도록 하는 것(즉, 모든 값이 유일해야 한다.)\n커서(cursor): 커서를 사용해서 데이터베이스에서 SQL 명령어를 수행하고 데이터베이스에서 데이터를 가져온다. 커서는 네트워크 연결을 위한 소켓이나 파일의 파일 핸들러와 유사하다.\n데이터베이스 브라우져(database browser): 프로그램을 작성하지 않고 직접적으로 데이터베이스에 연결하거나 데이터베이스를 조작할 수 있는 소프트웨어.\n외부 키(foreign key): 다른 테이블에 있는 행의 주키를 가리키는 숫자 키. 외부 키는 다른 테이블에 저장된 행사이에 관계를 설정한다.\n인텍스(index): 테이블에 행이 추가될 때 정보 검색하는 것을 빠르게 하기 위해서 데이터베이스 소프트웨어가 유지관리하는 추가 데이터.\n논리 키(logical key): “외부 세계”가 특정 행의 정보를 찾기 위해서 사용하는 키. 사용자 계정 테이블의 예로, 사람의 전자우편 주소는 사용자 데이터에 대한 논리 키의 좋은 후보자가 될 수 있다.\n정규화(normalization): 어떠한 데이터도 중복이 없도록 데이터 모델을 설계하는 것. 데이터베이스 한 장소에 데이터 각 항목 정보를 저장하고 외부키를 이용하여 다른 곳에서 참조한다.\n주키(primary key): 다른 테이블에서 테이블의 한 행을 참조하기 위해서 각 행에 대입되는 숫자 키. 종종 데이터베이스는 행이 삽입될 때 주키를 자동 삽입하도록 설정되었다.\n관계(relation): 튜플과 속성을 담고 있는 데이터베이스 내부 영역. 좀더 일반적으로 “테이블(table)”이라고 한다.\n튜플(tuple):데이터베이스 테이블에 단일 항목으로 속성 집합이다. 좀더 일반적으로 “행(row)”이라고 한다.",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>데이터베이스와 SQL</span>"
    ]
  },
  {
    "objectID": "select.html#기본-지식",
    "href": "select.html#기본-지식",
    "title": "3  데이터 선택하기",
    "section": "3.1 기본 지식",
    "text": "3.1 기본 지식\n관계형 데이터베이스(relational database)는 테이블(tables)로 정렬된 정보를 저장하고 다루는 방식이다. 각 테이블은 데이터를 기술하는 필드(fields)로도 알려진 열(column)과 데이터를 담고 있는 레코드(records)로 알려진 행(row)으로 구성된다.\n스프레드쉬트를 사용할 때, 이전 값에 기초하여 새로운 값을 계산할 때 공식을 셀(cell)에 넣어서 구한다. 데이터베이스를 사용할 때는 쿼리(queries, 질의)로 불리는 명령문을 데이터베이스 관리자(database manager)에게 보낸다. 데이터베이스 관리자는 사용자를 대신해서 데이터베이스를 조작하는 프로그램이다. 데이터베이스 관리자는 쿼리가 명기하는 임의의 조회작업과 계산작업을 수행하고 다음 쿼리작업 시작점으로 사용될 수 있는 테이블 형식으로 결과값을 반환한다.\n\n\n\n\n\n\n데이터베이스 상호호환\n\n\n\n모든 데이터베이스 관리자(IBM DB2, PostgreSQL, MySQL, Microsoft Access, SQLite)는 서로 다른 고유한 방식으로 데이터를 저장하기 때문에, 특정 데이터베이스로 저장된 데이터를 다른 곳의 데이터베이스에서 직접적으로 사용할 수는 없다. 하지만, 모든 데이터베이스 관리자에는 데이터를 다양한 형식으로 가져오기(import)와 내보내기(export) 기능을 제공한다. 그래서 한 곳에서 다른 곳으로 정보를 이동하는 것이 가능하다.\n\n\n쿼리는 SQL로 불리는 언어로 작성된다. SQL 은 “Structured Query Language”(구조적 질의 언어)의 약자다. SQL은 데이터를 분석하고 다시 조합할 수 있는 수백개의 다른 방식을 제공한다. 본서에서 일부를 살펴볼 것이지만, 일부작업이 데이터 과학자가 수행하는 일의 대부분을 처리할 것이다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>데이터 선택하기</span>"
    ]
  },
  {
    "objectID": "select.html#조사-데이터베이스",
    "href": "select.html#조사-데이터베이스",
    "title": "3  데이터 선택하기",
    "section": "3.2 조사 데이터베이스",
    "text": "3.2 조사 데이터베이스\nSQLite를 사용하여 본격적인 쿼리문 작성에 앞서 실습에 사용될 데이터베이스 구조를 살펴보자.\n\n\nPerson: 측정값을 기록한 사람, id는 해당 인물을 위한 고유 식별자를 나타낸다.\n\n\n\nid\npersonal\nfamily\n\n\n\n\ndyer\nWilliam\nDyer\n\n\npb\nFrank\nPabodie\n\n\nlake\nAnderson\nLake\n\n\nroe\nValentina\nRoerich\n\n\ndanforth\nFrank\nDanforth\n\n\n\nSite: 측정값이 기록된 sites의 위치를 나타낸다.\n\n\n\nname\nlat\nlong\n\n\n\n\nDR-1\n-49.85\n-128.57\n\n\nDR-3\n-47.15\n-126.72\n\n\nMSK-4\n-48.87\n-123.4\n\n\n\nVisited: 측정 위지에서 측정값이 기록된 구체적인 위치와 날짜에 대한 특정 식별 id를 나타낸다.\n\n\n\nid\nsite\ndated\n\n\n\n\n619\nDR-1\n1927-02-08\n\n\n622\nDR-1\n1927-02-10\n\n\n734\nDR-3\n1930-01-07\n\n\n735\nDR-3\n1930-01-12\n\n\n751\nDR-3\n1930-02-26\n\n\n752\nDR-3\n-null-\n\n\n837\nMSK-4\n1932-01-14\n\n\n844\nDR-1\n1932-03-22\n\n\n\n\n\nSurvey: 각 측정지의 정확한 위치에서 취한 측정값들로, taken으로 식별된다. quant 필드는 ‘양’을 의미하는 줄임말로 측정 대상을 나타낸다. 값은 각각 ’방사능’, ‘염도’, ’온도’를 의미하는 rad, sal, temp로 표시된다.\n\n\n\ntaken\nperson\nquant\nreading\n\n\n\n\n619\ndyer\nrad\n9.82\n\n\n619\ndyer\nsal\n0.13\n\n\n622\ndyer\nrad\n7.8\n\n\n622\ndyer\nsal\n0.09\n\n\n734\npb\nrad\n8.41\n\n\n734\nlake\nsal\n0.05\n\n\n734\npb\ntemp\n-21.5\n\n\n735\npb\nrad\n7.22\n\n\n735\n-null-\nsal\n0.06\n\n\n735\n-null-\ntemp\n-26.0\n\n\n751\npb\nrad\n4.35\n\n\n751\npb\ntemp\n-18.5\n\n\n751\nlake\nsal\n0.1\n\n\n752\nlake\nrad\n2.19\n\n\n752\nlake\nsal\n0.09\n\n\n752\nlake\ntemp\n-16.0\n\n\n752\nroe\nsal\n41.6\n\n\n837\nlake\nrad\n1.46\n\n\n837\nlake\nsal\n0.21\n\n\n837\nroe\nsal\n22.5\n\n\n844\nroe\nrad\n11.25\n\n\n\n\n\n3개 항목 (Visited 테이블에서 1개, Survey 테이블에서 2개)은 실제 데이터가 아닌 특별한 -null- 항목을 가지고 있다. 왜냐하면 어떠한 값도 담고 있지 않아서 그렇다. 뒤에서 결측값(missing)을 다시 다룰 것이다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>데이터 선택하기</span>"
    ]
  },
  {
    "objectID": "select.html#데이터-유무-확인하기",
    "href": "select.html#데이터-유무-확인하기",
    "title": "3  데이터 선택하기",
    "section": "3.3 데이터 유무 확인하기",
    "text": "3.3 데이터 유무 확인하기\n쉘 명령으로, survey.db를 저장한 디렉토리로 작업 디렉토리를 변경한다. 만약 바탕화면에 저장했다면 다음 명령어를 사용해야 한다.\n$ cd Desktop\n$ ls | grep survey.db\nsurvey.db\n동일한 출력이 나오면 다음 명령어를 실행할 수 있다.\n$ sqlite3 survey.db\nSQLite version 3.8.8 2015-01-16 12:08:06\nEnter \".help\" for usage hints.\nsqlite&gt;\nSQLite에 survey.db 파일에 있는 데이터베이스를 로드하라는 명령어다.\n유용한 시스템 명령어 목록을 보려면 .help를 입력한다.\nSQLite 시스템 명령어들은 SQL 명령어와 구별하기 위해 .로 시작한다.\n데이터베이스의 테이블 목록을 보려면 .tables를 입력한다.\n.tables\nPerson   Site     Survey   Visited\nIf you had the above tables, you might be curious what information was stored in each table. To get more information on the tables, type .schema to see the SQL statements used to create the tables in the database. The statements will have a list of the columns and the data types each column stores.\n위와 같은 테이블이 있다면 각 테이블에 어떤 정보가 저장되어 있는지 궁금할 수 있다. 테이블에 대한 자세한 정보를 얻으려면 .schema를 입력해 데이터베이스의 테이블을 생성하는 데 사용된 SQL 문을 확인한다. 테이블명과 함께 테이블을 구성하는 칼럼과 칼럼 자료형이 목록으로 나열된다.\n.schema\nCREATE TABLE Person(\n        ident    text,\n        personal text,\n        family   text\n);\nCREATE TABLE Site(\n        name text,\n        lat  real,\n        long real\n);\nCREATE TABLE Visited(\n        ident integer,\n        site  text,\n        dated text\n);\nCREATE TABLE Survey(\n        taken   integer,\n        person  text,\n        quant   text,\n        reading real\n);\n출력 형식은 &lt;columnName dataType&gt;로 되어 있다. 따라서 첫 번째 줄에서 Person 테이블에 세 개의 열이 있음을 알 수 있다:\n\nid는 text 자료형\npersonal는 text 자료형\nfamily는 text 자료형\n\n참고: 사용 가능한 자료형은 데이터베이스 관리자에 따라 다르며, 지원되는 자료형은 온라인에서 검색할 수 있다.\nSQLite 설정을 변경하여 출력 가독성을 높일 수 있다. 먼저, 왼쪽 정렬 출력 모드를 설정한다. 그런 다음 칼럼명 헤더 표시를 켠다.\n.mode column\n.header on\n또 다른 방법으로, .sqliterc 파일을 생성하여 설정사항을 자동으로 가져올 수 있다. 위의 명령어를 추가하고 SQLite를 다시 연다. 윈도우에서는 C:\\Users\\&lt;yourusername&gt;.sqliterc를 사용한다. 리눅스와 맥(Linux/MacOS)에서는 /Users/&lt;yourusername&gt;/.sqliterc를 사용한다.\nSQLite를 종료하고 쉘 명령줄로 돌아가려면, .quit 또는 .exit를 사용하여 종료한다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>데이터 선택하기</span>"
    ]
  },
  {
    "objectID": "select.html#sql-헬로월드",
    "href": "select.html#sql-헬로월드",
    "title": "3  데이터 선택하기",
    "section": "3.4 SQL 헬로월드",
    "text": "3.4 SQL 헬로월드\n과학자의 이름을 화면에 표시하는 SQL 쿼리문을 작성해 보자. SQL SELECT 문을 사용해서 원하는 칼럼의 이름과 해당 열이 있는 테이블을 지정한다. 쿼리와 결과는 다음과 같다.\nSELECT family, personal FROM Person;\n\n\n\nfamily\npersonal\n\n\n\n\nDyer\nWilliam\n\n\nPabodie\nFrank\n\n\nLake\nAnderson\n\n\nRoerich\nValentina\n\n\nDanforth\nFrank\n\n\n\n쿼리 끝에 세미콜론(;)은 쿼리가 완료되어 실행준비 되었다고 데이터베이스 관리자에게 알린다. 명령문과 칼럼 이름을 모두 소문자로 작성했고, 테이블 이름은 타이틀 케이스(Title Case, 단어의 첫 문자를 대문자로 표기)로 작성했다. 하지만 그렇게 반듯이 할 필요는 없다. 아래 예제가 보여주듯이, SQL은 대소문자 구분하지 않는다(case insensitive).\nSeLeCt FaMiLy, PeRsOnAl FrOm PeRsOn;\n\n\n\nfamily\npersonal\n\n\n\n\nDyer\nWilliam\n\n\nPabodie\nFrank\n\n\nLake\nAnderson\n\n\nRoerich\nValentina\n\n\nDanforth\nFrank\n\n\n\n모두 소문자, 타이틀 케이스, 소문자 낙타 대문자(Lower Camel Case)를 선택하든지 관계없이 일관성을 가져라. 무작위 대문자를 추가적으로 인지하지 않더라고 복잡한 쿼리는 충분히 그 자체로 이해하기 어렵다.\nSQL의 대소문자 구분이 없는 특성을 이용해 SQL 문의 다른 부분을 구분할 수 있다. 일반적인 SQL 문 작성사례로, SQL 키워드(예: SELECT, FROM)는 대문자로, 테이블 이름은 타이틀 케이스로, 필드 이름은 소문자로 사용하는 관례를 따른다. 어떤 대소문자 사용 관례를 선택하든 일관성을 유지하는 것이 중요하다.\n\n\n\n\n\n\n노트\n\n\n\nSQL 구문의 한 측면인 ; (세미콜론)으로 명령을 마치지 않는 것은 초보자와 전문가 모두에게 혼란을 주고 있다. ;를 추가하지 않고 명령어를 입력한 후 엔터를 누르면 다음과 같은 상황이 발생한다.\nSELECT id FROM Person\n...&gt;\n...&gt;\n이것은 SQL이 추가 명령을 기다리거나 ;를 통해 SQL에게 명령을 마칠 준비가 되었음을 알리는 프롬프트다. 이 문제는 쉽게 해결할 수 있다! 단순히 ;를 입력하고 엔터를 누르면 된다!\n\n\n쿼리로 돌아가서, 데이터베이스 테이블의 행과 칼럼이 특정한 순서로 저장되어 있지 않는다는 것을 이해하는 것이 중요하다. 어떤 순서로 항상 표시되지만, 다양한 방식으로 출력을 제어할 수 있다. 예를 들어, 쿼리를 다음과 같이 작성해서 칼럼을 교환할 수 있다.\nSELECT personal, family FROM Person;\n\n\n\npersonal\nfamily\n\n\n\n\nWilliam\nDyer\n\n\nFrank\nPabodie\n\n\nAnderson\nLake\n\n\nValentina\nRoerich\n\n\nFrank\nDanforth\n\n\n\n혹은 심지어 칼럼을 반복할 수도 있다.\nSELECT id, id, id FROM Person;\n\n\n\nid\nid\nid\n\n\n\n\ndyer\ndyer\ndyer\n\n\npb\npb\npb\n\n\nlake\nlake\nlake\n\n\nroe\nroe\nroe\n\n\ndanforth\ndanforth\ndanforth\n\n\n\n손쉬운 방법으로, *을 사용해서 테이블의 모든 칼럼을 선택할 수도 있다.\nSELECT * FROM Person;\n\n\n\nid\npersonal\nfamily\n\n\n\n\ndyer\nWilliam\nDyer\n\n\npb\nFrank\nPabodie\n\n\nlake\nAnderson\nLake\n\n\nroe\nValentina\nRoerich\n\n\ndanforth\nFrank\nDanforth",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>데이터 선택하기</span>"
    ]
  },
  {
    "objectID": "select.html#연습문제",
    "href": "select.html#연습문제",
    "title": "3  데이터 선택하기",
    "section": "연습문제",
    "text": "연습문제\n\nCREATE 쿼리문\n데이터베이스 SQL 문을 작성할 때 테이블 칼럼 자료형(문자, 숫자, 날짜 등)을 파악하고 있어야 버그없는 깔끔한 쿼리를 작성할 수 있다.\n정수를 포함하는 칼럼을 확인하기 위해, .schema 명령어를 사용하면 확인할 수 있다.\n.schema\nCREATE TABLE Person (id text, personal text, family text);\nCREATE TABLE Site (name text, lat real, long real);\nCREATE TABLE Survey (taken integer, person text, quant text, reading real);\nCREATE TABLE Visited (id integer, site text, dated text);\n출력 결과에서, Survey 테이블(3번째 줄)의 taken 칼럼이 실수 자료형임을 확인할 수 있다.\n\n\n사이트 이름 선택하기\nSite 테이블에서 name 칼럼만 선택하는 쿼리를 작성한다.\nSELECT name FROM Site;\n\n\n\nname\n\n\n\n\nDR-1\n\n\nDR-3\n\n\nMSK-4\n\n\n\n\n\n쿼리 스타일\n많은 사람들은 쿼리를 다음과 같이 작성한다.\nSELECT personal, family FROM person;\n또는,\nselect Personal, Family from PERSON;\n어떤 스타일이 가장 읽기 쉽다고 생각하며, 그 이유는 무엇인가?\n읽기 쉬운 쿼리 스타일은 주로 개인적인 선호와 경험에 따라 달라질 수 있다. 그러나 일반적으로 첫 번째 예시처럼 SQL 키워드를 대문자로, 테이블과 칼럼 이름을 소문자로 쓰는 방식이 가독성이 높다고 여겨진다. SQL 키워드와 테이블, 칼럼 이름 사이의 명확한 구분을 제공하여 쿼리를 더 쉽게 읽고 이해할 수 있게 한다. 반면, 두 번째 예시처럼 모든 것을 소문자나 대문자로 쓰는 방식은 이러한 구분을 덜 명확하게 만들어 쿼리의 구조를 파악하기 어렵게 할 수 있다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>데이터 선택하기</span>"
    ]
  },
  {
    "objectID": "sort-dup.html#정렬",
    "href": "sort-dup.html#정렬",
    "title": "4  정렬과 중복제거",
    "section": "4.1 정렬",
    "text": "4.1 정렬\n두 경우 모두에서, 중복된 값이 제거되었음을 알 수 있다. 데이터베이스 테이블에서 해당 행들이 인접해 있지 않아도 마찬가지다.\n다음 과제로 Person 테이블에서 탐사에 참여한 과학자들을 식별하는 것이다. 앞서 언급했듯이, 데이터베이스 레코드는 일반적으로 특정한 순서로 저장되지 않는다. 쿼리 결과가 반드시 정렬되어 있지 않으며, 설사 정렬되어 있다 해도, 원하는 다른 방식(예를 들어, 개인 이름 대신 식별자 등)으로 정렬 결과를 보고 싶을 때가 많다는 의미기도 하다. SQL에서는 쿼리에 ORDER BY 절을 추가함으로써 간단하게 구현할 수 있다.\nSELECT * FROM Person ORDER BY id;\n\n\n\nid\npersonal\nfamily\n\n\n\n\ndanfort\nFrank\nDanforth\n\n\ndyer\nWilliam\nDyer\n\n\nlake\nAnderson\nLake\n\n\npb\nFrank\nPabodie\n\n\nroe\nValentina\nRoerich\n\n\n\n기본설정으로 ORDER BY를 사용할 때, 결과는 지정한 칼럼 오름차순으로 정렬된다 (즉, 가장 작은 값에서 가장 큰 값으로).\nDESC(내림차순을 의미하는 “descending”의 약자)를 사용하여 반대 순서로 정렬할 수 있다.\n\n\n\n\n\n\n정렬 참고 사항\n\n\n\n데이터베이스에 쿼리문을 전송할 때마다 레코드가 일관되게 보이는 이유는 지금까지 아무도 데이터를 변경하거나 수정하지 않았기 때문이다. 행이 일관성을 갖고 예측 가능한 순서로 반환되기를 원한다면 ORDER BY를 사용하는 것을 기억하라.\n\n\n(오름차순 정렬을 명확히 하고 싶다면, DESC 대신 ASC를 사용한다.)\n각 사이트 방문 때 어떤 과학자가 양을 측정했는지 살펴보려면, 다시 Survey 테이블을 봐야 한다. 여러 칼럼을 한 번에 정렬할 수도 있다. 예를 들어, 다음 쿼리는 결과를 먼저 taken에 따라 오름차순으로 정렬한 다음, 각각의 동일한 taken 값 그룹 내에서 person에 따라 내림차순으로 정렬한다.\nSELECT taken, person, quant FROM Survey ORDER BY taken ASC, person DESC;\n\n\n\ntaken\nperson\nquant\n\n\n\n\n619\ndyer\nrad\n\n\n619\ndyer\nsal\n\n\n622\ndyer\nrad\n\n\n622\ndyer\nsal\n\n\n734\npb\nrad\n\n\n734\npb\ntemp\n\n\n734\nlake\nsal\n\n\n735\npb\nrad\n\n\n735\n-null-\nsal\n\n\n735\n-null-\ntemp\n\n\n751\npb\nrad\n\n\n751\npb\ntemp\n\n\n751\nlake\nsal\n\n\n752\nroe\nsal\n\n\n752\nlake\nrad\n\n\n752\nlake\nsal\n\n\n752\nlake\ntemp\n\n\n837\nroe\nsal\n\n\n837\nlake\nrad\n\n\n837\nlake\nsal\n\n\n844\nroe\nrad",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>정렬과 중복제거</span>"
    ]
  },
  {
    "objectID": "sort-dup.html#중복제거",
    "href": "sort-dup.html#중복제거",
    "title": "4  정렬과 중복제거",
    "section": "4.2 중복제거",
    "text": "4.2 중복제거\n데이터베이스에서 중복 데이터의 존재는 정보의 해석을 복잡하게 만들 수 있다. 같은 데이터가 반복되면, 결과의 해석이 어려워지고, 필요한 정보를 찾는 데 시간이 더 걸릴 수 있다. DISTINCT 키워드는 이러한 중복을 제거하여 결과를 더 명확하고 간결하게 만드는 역할을 한다. 예를 들어, 여러 번의 측정에서 동일한 과학자가 나타날 수 있는데, DISTINCT를 사용하면 각 과학자가 수행한 고유한 측정 유형만을 표시하여 데이터의 중복을 최소화하고 결과를 더 쉽게 해석할 수 있다.\n다음 쿼리를 통해 어떤 과학자가 방문에 관여했으며, 방문 동안 어떤 측정을 수행했는지를 잘 파악할 수 있다.\n테이블을 살펴보면, 일부 과학자들이 특정 종류의 측정에 전문화되어 있는 것처럼 보인다. 적절한 칼럼을 선택하고 중복을 제거함으로써 어떤 과학자가 어떤 측정을 수행했는지 선명히 드러난다.\nSELECT DISTINCT quant, person FROM Survey ORDER BY quant ASC;\n\n\n\nquant\nperson\n\n\n\n\nrad\ndyer\n\n\nrad\npb\n\n\nrad\nlake\n\n\nrad\nroe\n\n\nsal\ndyer\n\n\nsal\nlake\n\n\nsal\n-null-\n\n\nsal\nroe\n\n\ntemp\npb\n\n\ntemp\n-null-\n\n\ntemp\nlake\n\n\n\n데이터베이스 테이블의 레코드는 본질적으로 정렬되어 있지 않기 때문에, 특정 순서대로 표시하고 싶다면, ORDER BY를 명시적으로 사용하여 그 순서를 지정해야 한다. 데이터베이스 저장된 값은 고유함이 보장되지 않기 때문에, 중복을 제거하고 싶다면, DISTINCT를 사용하여 명시적으로 지정하여 처리해야만 된다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>정렬과 중복제거</span>"
    ]
  },
  {
    "objectID": "sort-dup.html#연습문제",
    "href": "sort-dup.html#연습문제",
    "title": "4  정렬과 중복제거",
    "section": "연습문제",
    "text": "연습문제\n\n중복 날짜\nVisited 테이블에서 별개로 구별되는 고유한(distinct) 날짜들을 선택하는 쿼리를 작성하시오.\n다음 쿼리는 Visited 테이블에서 중복 없이 모든 고유한 ‘dated’ 칼럼의 값을 반환한다.\nSELECT DISTINCT dated FROM Visited;\n\n\n\ndated\n\n\n\n\n1927-02-08\n\n\n1927-02-10\n\n\n1930-01-07\n\n\n1930-01-12\n\n\n1930-02-26\n\n\n \n\n\n1932-01-14\n\n\n1932-03-22\n\n\n\n\n\n조사자명\nPerson 테이블에 있는 과학자들 전체 이름을 표시하고, 가족 이름(family name)으로 정렬하는 쿼리문을 작성하시오.\n다음 쿼리는 Person 테이블에서 개인 이름(personal)과 가족 이름(family)을 결합하여 전체 이름(fullname)을 생성하고, 그 결과를 가족 이름으로 정렬해 반환한다. 여기서 ||는 문자열을 연결하는 SQL 연산자다.\nSELECT personal, family FROM Person ORDER BY family ASC;\n\n\n\npersonal\nfamily\n\n\n\n\nFrank\nDanforth\n\n\nWilliam\nDyer\n\n\nAnderson\nLake\n\n\nFrank\nPabodie\n\n\nValentina\nRoerich",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>정렬과 중복제거</span>"
    ]
  },
  {
    "objectID": "filter.html#부울-연산자",
    "href": "filter.html#부울-연산자",
    "title": "5  필터",
    "section": "5.1 부울 연산자",
    "text": "5.1 부울 연산자\n데이터를 필터링할 때 부울 연산자(Boolean Operators)를 사용한다. 이는 특정 조건을 만족하는 데이터를 선택하거나 제외하는 데 유용하다. 예를 들어, DR-1 사이트에서 1930년 이후로 수집된 모든 정보를 요청하는 경우, 부울 연산자를 사용하여 ‘사이트 이름이 DR-1이고, 수집 연도가 1930년 이후인’ 데이터를 필터링할 수 있다. 이렇게 SQL 쿼리에서 부울 연산자를 사용하면, 복잡한 데이터 집합에서 필요한 정보를 정확하고 효율적으로 추출할 수 있다.\nSELECT * FROM Visited WHERE site = 'DR-1' AND dated &lt; '1930-01-01';\n\n\n\nid\nsite\ndated\n\n\n\n\n619\nDR-1\n1927-02-08\n\n\n622\nDR-1\n1927-02-10\n\n\n\n\n\n\n\n\n\n날짜 자료형\n\n\n\n거의 모든 데이터베이스 관리자는 날짜 자료 처리를 위한 특별한 자료형(Data Type)을 가지고 있다. 실제로 많은 데이터베이스는 크게 두개로 갈린다. 하나는 “1971년 5월 31일”과 같은 날짜용이고, 다른 하나는 “31일”과 같은 기간용(duration)이다. 하지만, SQLite는 그렇지 않다. 대신, SQLite는 날짜를 텍스트(ISO-8601 표준 형식 “YYYY-MM-DD HH:MM:SS.SSSS”), 실수(율리우스 일자, 기원전 4714년 11월 24일부터 일수), 또는 정수(유닉스 시간, 1970년 1월 1일 자정 이후의 초 수)로 저장한다. 만약 복잡하게 들린다면, 그럴수도 있다 하지만 옛날 스웨덴 날짜를 파악하는 것만큼 복잡하지는 않다.\n\n\nLake나 Roerich에 의해 수행된 측정이 무엇인지 알아보려면, 그들의 이름에 대한 검사를 OR를 사용하여 결합한다.\nSELECT * FROM Survey WHERE person = 'lake' OR person = 'roe';\n\n\n\ntaken\nperson\nquant\nreading\n\n\n\n\n734\nlake\nsal\n0.05\n\n\n751\nlake\nsal\n0.1\n\n\n752\nlake\nrad\n2.19\n\n\n752\nlake\nsal\n0.09\n\n\n752\nlake\ntemp\n-16.0\n\n\n752\nroe\nsal\n41.6\n\n\n837\nlake\nrad\n1.46\n\n\n837\nlake\nsal\n0.21\n\n\n837\nroe\nsal\n22.5\n\n\n844\nroe\nrad\n11.25\n\n\n\n다른 방식으로, IN을 사용하여 특정 집합에 값이 있는지 확인할 수 있다.\nSELECT * FROM Survey WHERE person IN ('lake', 'roe');\n\n\n\ntaken\nperson\nquant\nreading\n\n\n\n\n734\nlake\nsal\n0.05\n\n\n751\nlake\nsal\n0.1\n\n\n752\nlake\nrad\n2.19\n\n\n752\nlake\nsal\n0.09\n\n\n752\nlake\ntemp\n-16.0\n\n\n752\nroe\nsal\n41.6\n\n\n837\nlake\nrad\n1.46\n\n\n837\nlake\nsal\n0.21\n\n\n837\nroe\nsal\n22.5\n\n\n844\nroe\nrad\n11.25\n\n\n\nAND와 OR을 결합할 수 있지만, 어떤 연산자가 먼저 실행되는지 주의해야 한다. 괄호를 사용하지 않으면, 다음과 같은 결과를 얻게 된다:\nSELECT * FROM Survey WHERE quant = 'sal' AND person = 'lake' OR person = 'roe';\n\n\n\ntaken\nperson\nquant\nreading\n\n\n\n\n734\nlake\nsal\n0.05\n\n\n751\nlake\nsal\n0.1\n\n\n752\nlake\nsal\n0.09\n\n\n752\nroe\nsal\n41.6\n\n\n837\nlake\nsal\n0.21\n\n\n837\nroe\nsal\n22.5\n\n\n844\nroe\nrad\n11.25\n\n\n\n이 쿼리는 Lake에 의한 염도(salinity) 측정과 Roerich에 의한 모든 측정을 포함한다. 대신에 아마도 다음과 같은 결과를 얻고자 했을 것이다.\nSELECT * FROM Survey WHERE quant = 'sal' AND (person = 'lake' OR person = 'roe');\n\n\n\ntaken\nperson\nquant\nreading\n\n\n\n\n734\nlake\nsal\n0.05\n\n\n751\nlake\nsal\n0.1\n\n\n752\nlake\nsal\n0.09\n\n\n752\nroe\nsal\n41.6\n\n\n837\nlake\nsal\n0.21\n\n\n837\nroe\nsal\n22.5",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>필터</span>"
    ]
  },
  {
    "objectID": "filter.html#like-키워드",
    "href": "filter.html#like-키워드",
    "title": "5  필터",
    "section": "5.2 LIKE 키워드",
    "text": "5.2 LIKE 키워드\nSQL 필터링에서 LIKE 키워드의 중요성은 부분 일치를 통해 데이터를 필터링할 수 있게 해준다는 데에 있다. 예를 들어, ’DR’로 시작하는 사이트 이름과 같이 특정 패턴이나 문자열을 포함하는 레코드를 찾고 싶을 때 LIKE 키워드를 사용한다. 퍼센트 기호(%)는 와일드카드로서, 그 위치에 어떤 문자열이든 일치할 수 있게 한다. 이를 통해 문자열의 시작, 중간, 끝 부분에서 특정 패턴을 검색할 수 있다. LIKE와 와일드카드의 조합은 SQL 쿼리에서 매우 유연한 문자열 검색을 가능하게 하며, 복잡하거나 정확하지 않은 데이터에서 원하는 정보를 효과적으로 추출하는 데 중요한 역할을 한다.\nSELECT * FROM Visited WHERE site LIKE 'DR%';\n\n\n\nid\nsite\ndated\n\n\n\n\n619\nDR-1\n1927-02-08\n\n\n622\nDR-1\n1927-02-10\n\n\n734\nDR-3\n1930-01-07\n\n\n735\nDR-3\n1930-01-12\n\n\n751\nDR-3\n1930-02-26\n\n\n752\nDR-3\n\n\n\n844\nDR-1\n1932-03-22\n\n\n\n마지막으로, DISTINCT를 WHERE와 함께 사용하여, 두 번째 수준 필터링 작업을 수행한다.\nSELECT DISTINCT person, quant FROM Survey WHERE person = 'lake' OR person = 'roe';\n\n\n\nperson\nquant\n\n\n\n\nlake\nsal\n\n\nlake\nrad\n\n\nlake\ntemp\n\n\nroe\nsal\n\n\nroe\nrad\n\n\n\n하지만, 기억하라. DISTINCT는 처리될 때 선택된 칼럼에 표시되는 값에만 적용되고 전체 행에는 적용되지 않는다.\n\n\n\n\n\n\n쿼리작성 방법\n\n\n\n방금 수행한 방식이 대부분의 사람들이 SQL 쿼리를 “발전시키는” 방식이기도 하다. 의도한 것의 일부를 수행하는 단순한 것에서부터 시작했다. 그리고 절을 하나씩 하나씩 추가하면서 효과를 테스트했다. 좋은 전략이다. 사실 복잡한 쿼리를 작성할 때, 거의 유일한 전략이다. 하지만 이런 전략은 빠른 결과 확인과 더불어, 올바른 결과를 얻었을 때 빠른 인식에도 상당히 의존한다.\n빠른 결과 확인을 이루는 가장 좋은 방법은 데이터의 일부를 임시 데이터베이스에 저장하고 그 위에서 쿼리를 실행하는 것이거나, 혹은 합리적으로 구성된 레코드로 소규모 데이터베이스를 채워두고 실험하는 것이다. 예를 들어, 실제 2000만 호주 인구의 데이터베이스에서 쿼리를 실행하기보다는 1만 명의 샘플을 추출하여 실험을 하거나, 무작위 또는 그럴듯한 1만 명의 레코드를 생성할 수 있는 작은 프로그램을 작성해 사용하는 것이다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>필터</span>"
    ]
  },
  {
    "objectID": "filter.html#연습문제",
    "href": "filter.html#연습문제",
    "title": "5  필터",
    "section": "연습문제",
    "text": "연습문제\n\n5.2.1 쿼리 디버깅\n극에서 48&deg보다 고위도에 위치한 모든 사이트를 선택하고자 한다고 가정하자. 작성한 첫번째 쿼리는 다음과 같다.\nSELECT * FROM Site WHERE (lat &gt; -48) OR (lat &lt; 48);\n왜 이 쿼리가 잘못된 것인지 설명하세요. 그리고 쿼리를 다시 작성해서 올바르게 동작하게 만드세요.\n\nOR를 사용했기 때문에, 예를 들어 남극에 있는 사이트도 두 번째 기준을 만족하여 포함된다. 대신에, 두 가지 기준 모두를 충족하는 사이트만을 포함시키고 싶다면 다음과 같이 쿼리를 수정한다.\nSELECT * FROM Site WHERE (lat &gt; -48) AND (lat &lt; 48);\n작성된 쿼리는 위도가 -48보다 크고 48보다 작은 Site 테이블의 모든 레코드를 선택한다. 이는 사실상 남극과 북극 사이의 사이트들만을 대상으로 한다.\n\n\n5.2.2 이상치 탐지\n정규화된 염분 수치는 0.0에서 1.0 사이에 있어야 한다. 상기 범위 밖에 있는 염분수치를 가진 모든 레코드를 Survey 테이블에서 선택하는 쿼리를 작성하세요.\nSELECT * FROM Survey WHERE quant = 'sal' AND ((reading &gt; 1.0) OR (reading &lt; 0.0));\n\n\n\ntaken\nperson\nquant\nreading\n\n\n\n\n752\nroe\nsal\n41.6\n\n\n837\nroe\nsal\n22.5\n\n\n\n\n\n5.2.3 패턴 매칭\n다음 표현식 중 참은 무엇인가?\n\n'a' LIKE 'a'\n'a' LIKE '%a'\n'beta' LIKE '%a'\n'alpha' LIKE 'a%%'\n'alpha' LIKE 'a%p%'\n\n\n표현식들이 참인 이유는 다음과 같습니다:\n\nTrue - ’a’와 ’a’는 동일한 문자이기 때문이다.\nTrue - 와일드카드는 제로 또는 그 이상의 문자와 일치할 수 있기 때문이다.\nTrue - ’%’가 ’bet’과 일치하고, ’a’가 마지막 ’a’와 일치한다.\nTrue - 첫 번째 와일드카드가 ’lpha’와 일치하고, 두 번째 와일드카드는 제로 문자(또는 그 반대)와 일치한다.\nTrue - 첫 번째 와일드카드가 ’l’과 일치하고, 두 번째 와일드카드가 ’ha’와 일치한다.\n\n만약 명명된 칼럼의 값이 주어진 패턴과 일치한다면 SQL 테스트 *column-name* like *pattern*은 참이다. “0 혹은 그 이상의 문자와 매칭”된다는 것을 의미하기 위해서 ’%’문자를 패턴에 임의 숫자 횟수에 사용한다. 반면, 표현식 *column-name* not like *pattern*은 매칭을 거꾸로 한다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>필터</span>"
    ]
  },
  {
    "objectID": "calc.html#합집합",
    "href": "calc.html#합집합",
    "title": "6  새로운 값 계산",
    "section": "6.1 합집합",
    "text": "6.1 합집합\nUNION 연산자는 두 개의 쿼리 결과를 결합한다.\nSELECT * FROM Person WHERE id = 'dyer' UNION SELECT * FROM Person WHERE id = 'roe';\n\n\n\nid\npersonal\nfamily\n\n\n\n\ndyer\nWilliam\nDyer\n\n\nroe\nValentina\nRoerich\n\n\n\nUNION ALL 명령은 UNION 연산자와 동일하지만, UNION ALL은 모든 값을 선택한다는 점에서 차이가 있다. 차이점은 UNION ALL이 중복 행을 제거하지 않는다는 것이다. 대신, UNION ALL은 쿼리의 모든 행을 가져와서 하나의 테이블로 결합한다. UNION 명령은 결과 세트에 대해 SELECT DISTINCT를 수행한다. 만약 합병할 모든 레코드가 고유하다면, DISTINCT 단계를 건너뛰므로 더 빠른 결과를 얻기 위해 UNION ALL을 사용한다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>새로운 값 계산</span>"
    ]
  },
  {
    "objectID": "calc.html#연습문제",
    "href": "calc.html#연습문제",
    "title": "6  새로운 값 계산",
    "section": "6.2 연습문제",
    "text": "6.2 연습문제\n\n6.2.1 염도 측정치 수정\n추가로 정보를 살펴본 결과, 발렌티나 로에리히(Valentina Roerich)가 염도를 백분율로 보고했다는 것을 알게 되었다. Survey 테이블에서 모든 염도 측정치를 100으로 나눈 값으로 반환하는 쿼리를 작성하시오.\nSELECT taken, reading / 100 FROM Survey WHERE person = 'roe' AND quant = 'sal';\n\n\n\ntaken\nreading / 100\n\n\n\n\n752\n0.416\n\n\n837\n0.225\n\n\n\n\n\n6.2.2 통합 측정목록\nUNION을 사용하여 발렌티나 로에리히(Roerich가)의 염도 측정치를 앞선 도전과제에서 설명한 대로 수정하고, 발렌티나 로에리히만의 측정치로 통합된 염도 측정치 목록을 만든다. 출력 결과는 다음과 같아야 한다.\n\n\n\ntaken\nreading\n\n\n\n\n619\n0.13\n\n\n622\n0.09\n\n\n734\n0.05\n\n\n751\n0.1\n\n\n752\n0.09\n\n\n752\n0.416\n\n\n837\n0.21\n\n\n837\n0.225\n\n\n\nSELECT taken, reading FROM Survey WHERE person != 'roe' AND quant = 'sal' UNION SELECT taken, reading / 100 FROM Survey WHERE person = 'roe' AND quant = 'sal' ORDER BY taken ASC;\n\n\n6.2.3 주요 사이트 식별자\nVisited 테이블의 사이트 식별자는 ’-’로 구분된 두 부분으로 이루어져 있다.\nSELECT DISTINCT site FROM Visited;\n\n\n\nsite\n\n\n\n\nDR-1\n\n\nDR-3\n\n\nMSK-4\n\n\n\n일부 주요 사이트 식별자(즉, 문자 코드)는 두 글자 길이이고 일부는 세 글자 길이이다. “문자열 내” 함수인 instr(X, Y)는 문자열 X 내에서 문자열 Y가 처음 나타나는 1-기반 인덱스를 반환하며, X 안에 Y가 존재하지 않으면 0을 반환한다. 부분 문자열 함수 substr(X, I, [L])는 X의 I 인덱스에서 시작하는 부분 문자열을 반환하며, 선택적으로 길이 L을 지정할 수 있다. 이 두 함수를 사용하여 고유한 주요 사이트 식별자 목록을 생성한다. (이 데이터의 경우, 목록은 “DR”과 “MSK”만을 포함해야 한다).\nSELECT DISTINCT substr(site, 1, instr(site, '-') - 1) AS MajorSite FROM Visited;",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>새로운 값 계산</span>"
    ]
  },
  {
    "objectID": "null.html#연습문제",
    "href": "null.html#연습문제",
    "title": "7  결측 데이터",
    "section": "7.1 연습문제",
    "text": "7.1 연습문제\n\n7.1.1 알려진 날짜별로 정렬\n날짜가 알려지지 않은 (즉 null) 항목은 빼고, 날짜 순으로 Visited 테이블에 있는 레코드를 정렬한\nSELECT * FROM Visited WHERE dated IS NOT NULL ORDER BY dated ASC;\n\n\n\nid\nsite\ndated\n\n\n\n\n619\nDR-1\n1927-02-08\n\n\n622\nDR-1\n1927-02-10\n\n\n734\nDR-3\n1930-01-07\n\n\n735\nDR-3\n1930-01-12\n\n\n751\nDR-3\n1930-02-26\n\n\n837\nMSK-4\n1932-01-14\n\n\n844\nDR-1\n1932-03-22\n\n\n\n\n\n7.1.2 집합에서 NULL\n다음 쿼리가 어떤 결과를 생성할 것으로 예상하는가?\nSELECT * FROM Visited WHERE dated IN ('1927-02-08', NULL);\n실제로 어떤 결과를 생성하는가?\n\n위 쿼리는 ‘1927-02-08’ 또는 NULL인 ‘dated’ 행을 반환할 것으로 예상할 수 있다. 하지만 실제로는 ’1927-02-08’인 행만 반환한다. 이는 다음과 같은 더 간단한 쿼리에서 얻을 수 있는 결과와 동일하다:\nSELECT * FROM Visited WHERE dated IN ('1927-02-08');\n이런 결과가 나타나는 이유는 IN 연산자가 값들의 집합과 작동하는데, NULL은 정의상 값이 아니며 따라서 단순히 무시되기 때문이다.\n실제로 NULL을 포함시키고자 한다면, 쿼리를 다음과 같이 IS NULL 조건을 사용하여 다시 작성해야 한다:\nSELECT * FROM Visited WHERE dated = '1927-02-08' OR dated IS NULL;\n이 쿼리는 ’dated’가 ’1927-02-08’이거나 NULL인 행을 모두 반환한다.\n\n\n7.1.3 표식값 장단점\n일부 데이터베이스 설계자들은 null 대신 표식값(sentienl value)을 사용하여 누락된 데이터를 표시하는 것을 선호한다. 예를 들어, 누락된 날짜에 “0000-00-00”을 사용하거나, 염도나 방사능 측정치가 누락된 경우 -1.0을 사용한다(실제 측정치는 음수가 될 수 없으므로). 이러한 접근방법이 단순화시킨 것은 무엇인가? 어떤 부담이나 위험을 도입하는가?\n\n표식값은 누락된 데이터의 존재를 명확히 표현한다. null보다 직관적으로 이해될 수 있고, 특정 값으로 데이터를 표시하면 null 값을 다룰 때 발생할 수 있는 복잡성(예: IS NULL 조건)을 피할 수 있다.\n표식값은 실제 데이터와 혼동될 위험이 있다. 예를 들어, “0000-00-00”이나 -1.0이 실제 측정치로 잘못 해석될 수 있다. 센티넬 값은 데이터 분석 시 추가적인 검증 단계를 필요로 한다. 예를 들어, 평균을 계산할 때 -1.0과 같은 표식값을 제외해야 한다. 센티넬 값의 사용은 데이터베이스 설계 및 유지 관리를 더 복잡하게 만들 수 있다. 모든 사용자 및 개발자가 표식값의 의미를 정확히 이해하고 있어야 한다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>결측 데이터</span>"
    ]
  },
  {
    "objectID": "agg.html#연습-문제",
    "href": "agg.html#연습-문제",
    "title": "7  집계",
    "section": "7.1 연습 문제",
    "text": "7.1 연습 문제\n\n7.1.1 온도 측정횟수 세기\n프랭크 파보디(Frank Pabodie)가 기록한 온도 측정횟수는 몇 번이며, 그 평균 값은 얼마인가?\nSELECT count(reading), avg(reading) FROM Survey WHERE quant = 'temp' AND person = 'pb';\n\n\n\ncount(reading)\navg(reading)\n\n\n\n\n2\n-20.0\n\n\n\n\n\n7.1.2 NULL 포함 평균 계산\n집합 값의 평균은 값들의 합을 값들의 개수로 나눈 것이다. 이는 avg 함수가 1.0, null, 5.0이라는 값들이 주어졌을 때 2.0 또는 3.0을 반환한다는 것을 의미하는가?\n\n정답은 3.0이다. NULL은 값이 아니라 값이 없음을 나타낸다. 따라서 계산에 포함되지 않는다. SQL avg 함수는 null 값을 무시하고, null이 아닌 값들만을 사용하여 평균을 계산한다. 따라서 주어진 값이 1.0, null, 5.0일 때, avg 함수는 null을 제외한 1.0과 5.0의 평균을 계산한다. 이는 (1.0 + 5.0) / 2 = 3.0 이므로, 함수는 3.0을 반환한다.\n다음 코드를 실행하여 이를 확인할 수 있다:\nSELECT AVG(a) FROM (\n    SELECT 1 AS a\n    UNION ALL SELECT NULL\n    UNION ALL SELECT 5);\n\n\n7.1.3 쿼리가 의미하는 바는?\n각 개별 방사능 측정값과 모든 방사능 측정값의 평균 사이의 차이를 계산하고자 한다. 이를 위해 다음과 같은 쿼리를 작성했다.\nSELECT avg(reading) FROM Survey WHERE quant='rad';\n쿼리가 실제로 어떤 결과를 생성하며, 그 이유는 무엇일까?\n\n쿼리는 각 측정값에 대한 결과 대신 단 하나의 결과 행만을 생성한다. avg() 함수는 단일 값을 생성하며, 먼저 실행되기 때문에 테이블이 단일 행으로 축소된다. reading 값은 단순히 임의의 값일 뿐이다.\n원하는 결과를 얻기 위해서는 두 개의 쿼리를 실행해야 한다:\nSELECT avg(reading) FROM Survey WHERE quant='rad';\n이는 평균값(6.5625)을 생성하는데, 이 값을 다음과 같은 두 번째 쿼리에 삽입할 수 있다.\nSELECT reading - 6.5625 FROM Survey WHERE quant = 'rad';\n이 쿼리는 우리가 원하는 결과를 생성하지만, 하위 쿼리(subquery)를 사용하여 이를 단일 쿼리로 결합할 수 있다.\nSELECT reading - (SELECT avg(reading) FROM Survey WHERE quant='rad') FROM Survey WHERE quant = 'rad';\n이 방법을 사용하면 두 개의 쿼리를 실행할 필요가 없다.\n요약하자면, 원래 쿼리에서 avg(reading)을 (SELECT avg(reading) FROM Survey WHERE quant='rad')로 대체한 것이다.\n\n\n7.1.4 group_concat 함수 사용\ngroup_concat(field, separator) 함수는 지정된 구분자 문자(또는 구분자가 지정되지 않은 경우 ‘,’)를 사용하여 필드의 모든 값을 연결한다. 이를 사용하여 과학자들의 이름을 한 줄 목록으로 생성하면 출력결과는 다음과 같다.\nWilliam Dyer, Frank Pabodie, Anderson Lake, Valentina Roerich, Frank Danforth\n쉼표로 구분된 모든 과학자들의 성을 나열하는 쿼리를 작성하세요. 쉼표로 구분된 모든 과학자들의 개인 이름과 성을 나열하는 쿼리를 작성하세요.\n\n쉼표로 구분된 모든 성을 나열하는 쿼리는 다음과 같다.\nSELECT group_concat(family, ',') FROM Person;\n쉼표로 구분된 모든 전체 이름을 나열하는 쿼리는 다음과 같다.\nSELECT group_concat(personal || ' ' || family, ',') FROM Person;",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>집계</span>"
    ]
  },
  {
    "objectID": "join.html",
    "href": "join.html",
    "title": "9  조인(Join)",
    "section": "",
    "text": "두 테이블을 조인(join)하는 쿼리 연산을 설명한다.\n의미있는 값의 조합만 포함하기 위해서 조인문을 포함하는 쿼리 결과를 어떻게 제한하는지 설명한다.\n동일한 키를 갖는 테이블을 조인하는 쿼리를 작성한다.\n기본키(primary key)와 외래키(foreign key)가 무엇인지 그리고 왜 유용한지 설명한다.\n원자값(atomic value)이 무엇이고, 왜 데이터베이스 필드는 원자값만 포함해야하는지 설명한다.\n\n과거 기상 데이터를 집계하는 웹사이트에 데이터를 제출하기 위해, 위도, 경도, 날짜, 측정량, 측정값 형식으로 데이터를 체계적으로 만들 필요가 있을 수 있다. 그러나, 위도와 경도는 Site 테이블에 있고, 측정 날짜는 Visited 테이블에, 측정값 자체는 Survey 테이블에 있다. 어떤 방식이든지 상기 테이블을 조합할 필요가 있다.\n테이블들 간 관계는 다음 그림을 통해 확인할 수 있다.\n\n\n\n조사 데이터베이스 구조\n\n\n이러한 작업을 하는 SQL 명령어가 JOIN이다. 어떻게 동작하는지 확인하기 위해서, Site와 Visited 테이블을 조인하면서 살펴보자.\nSELECT * FROM Site JOIN Visited;\n\n\n\n\n\n\n\n\n\n\n\nname\nlat\nlong\nid\nsite\ndated\n\n\n\n\nDR-1\n-49.85\n-128.57\n619\nDR-1\n1927-02-08\n\n\nDR-1\n-49.85\n-128.57\n622\nDR-1\n1927-02-10\n\n\nDR-1\n-49.85\n-128.57\n734\nDR-3\n1930-01-07\n\n\nDR-1\n-49.85\n-128.57\n735\nDR-3\n1930-01-12\n\n\nDR-1\n-49.85\n-128.57\n751\nDR-3\n1930-02-26\n\n\nDR-1\n-49.85\n-128.57\n752\nDR-3\n-null-\n\n\nDR-1\n-49.85\n-128.57\n837\nMSK-4\n1932-01-14\n\n\nDR-1\n-49.85\n-128.57\n844\nDR-1\n1932-03-22\n\n\nDR-3\n-47.15\n-126.72\n619\nDR-1\n1927-02-08\n\n\nDR-3\n-47.15\n-126.72\n622\nDR-1\n1927-02-10\n\n\nDR-3\n-47.15\n-126.72\n734\nDR-3\n1930-01-07\n\n\nDR-3\n-47.15\n-126.72\n735\nDR-3\n1930-01-12\n\n\nDR-3\n-47.15\n-126.72\n751\nDR-3\n1930-02-26\n\n\nDR-3\n-47.15\n-126.72\n752\nDR-3\n-null-\n\n\nDR-3\n-47.15\n-126.72\n837\nMSK-4\n1932-01-14\n\n\nDR-3\n-47.15\n-126.72\n844\nDR-1\n1932-03-22\n\n\nMSK-4\n-48.87\n-123.4\n619\nDR-1\n1927-02-08\n\n\nMSK-4\n-48.87\n-123.4\n622\nDR-1\n1927-02-10\n\n\nMSK-4\n-48.87\n-123.4\n734\nDR-3\n1930-01-07\n\n\nMSK-4\n-48.87\n-123.4\n735\nDR-3\n1930-01-12\n\n\nMSK-4\n-48.87\n-123.4\n751\nDR-3\n1930-02-26\n\n\nMSK-4\n-48.87\n-123.4\n752\nDR-3\n-null-\n\n\nMSK-4\n-48.87\n-123.4\n837\nMSK-4\n1932-01-14\n\n\nMSK-4\n-48.87\n-123.4\n844\nDR-1\n1932-03-22\n\n\n\njoin은 두 테이블을 교차 곱(cross product)한다. 즉, 모든 가능한 조합을 표현하려고 한 테이블의 레코드 각각마다 다른 테이블의 각 레코드와 조인한다. Site 테이블에 3개 레코드가 있고, Visited 테이블에 8개 레코드가 있어서, 조인된 결과는 24개 레코드가 된다. 그리고, 각 테이블이 3개 필드가 있어서 출력은 6개의 필드가 된다.\n조인이 수행하지 않은 것은 조인되는 레코드가 서로 관계가 있는지를 파악하는 것이다. 어떻게 조인할지 명시할 때까지 레코드가 서로 관계가 있는지 없는지 알 수 있는 방법은 없다. 이를 위해서 동일한 사이트 이름을 가진 조합에만 관심있다는 것을 명시하는 절(clause)을 추가한다.\n%%sqlite survey.db\nselect * from Site join Visited on Site.name=Visited.site;\n\n\n\n\nDR-1\n\n\n-49.85\n\n\n-128.57\n\n\n619\n\n\nDR-1\n\n\n1927-02-08\n\n\n\n\nDR-1\n\n\n-49.85\n\n\n-128.57\n\n\n622\n\n\nDR-1\n\n\n1927-02-10\n\n\n\n\nDR-1\n\n\n-49.85\n\n\n-128.57\n\n\n844\n\n\nDR-1\n\n\n1932-03-22\n\n\n\n\nDR-3\n\n\n-47.15\n\n\n-126.72\n\n\n734\n\n\nDR-3\n\n\n1939-01-07\n\n\n\n\nDR-3\n\n\n-47.15\n\n\n-126.72\n\n\n735\n\n\nDR-3\n\n\n1930-01-12\n\n\n\n\nDR-3\n\n\n-47.15\n\n\n-126.72\n\n\n751\n\n\nDR-3\n\n\n1930-02-26\n\n\n\n\nDR-3\n\n\n-47.15\n\n\n-126.72\n\n\n752\n\n\nDR-3\n\n\nNone\n\n\n\n\nMSK-4\n\n\n-48.87\n\n\n-123.4\n\n\n837\n\n\nMSK-4\n\n\n1932-01-14\n\n\n\n\non 은 where와 같은 역할을 한다. 특정 테스트를 통과한 레코드만 간직한다. (on과 where의 차이점은 on은 레코드가 생성될 때 레코드를 필터링하는 반면에, where는 조인작업이 완료될 때까지 기다리고 난 뒤에 필터링을 한다.) 쿼리에 레코드를 추가하자 마자 데이터베이스 관리자는 두 다른 사이트에 관한 조합된 정보는 사용한 뒤에 버려버리고, 원하는 레코드만 남겨둔다.\n조인 결과에 필드이름을 명기하기 위해서 table.field를 사용한 것에 주목하세요. 이렇게 하는 이유는 테이블이 동일한 이름을 가질 수 있고 어느 필드를 언급하는지 좀더 구체성을 띌 필요가 있다. 예를 들어, person과 visited 테이블을 조인한다면, 결과는 각각의 원래 테이블에서 ident로 불리는 필드를 상속한다.\n이제는 조인에서 원하는 3개의 칼럼을 선택하려고 점 표기법(dotted notation)을 사용할 수 있다.\n%%sqlite survey.db\nselect Site.lat, Site.long, Visited.dated\nfrom   Site join Visited\non     Site.name=Visited.site;\n\n\n\n\n-49.85\n\n\n-128.57\n\n\n1927-02-08\n\n\n\n\n-49.85\n\n\n-128.57\n\n\n1927-02-10\n\n\n\n\n-49.85\n\n\n-128.57\n\n\n1932-03-22\n\n\n\n\n-47.15\n\n\n-126.72\n\n\nNone\n\n\n\n\n-47.15\n\n\n-126.72\n\n\n1930-01-12\n\n\n\n\n-47.15\n\n\n-126.72\n\n\n1930-02-26\n\n\n\n\n-47.15\n\n\n-126.72\n\n\n1939-01-07\n\n\n\n\n-48.87\n\n\n-123.4\n\n\n1932-01-14\n\n\n\n\n만약 두개의 테이블을 조인하는 것이 좋은 경우에, 많은 데이블을 조인하는 것은 더 좋아야한다. 더 많은 join 절과 의미없는 레코드 조합을 필터링해서 제거하는 더 많은 on 테스트를 단순히 추가해서 사실 쿼리에 임의 갯수의 테이블을 조인할 수 있다.\n%%sqlite survey.db\nselect Site.lat, Site.long, Visited.dated, Survey.quant, Survey.reading\nfrom   Site join Visited join Survey\non     Site.name=Visited.site\nand    Visited.ident=Survey.taken\nand    Visited.dated is not null;\n\n\n\n\n-49.85\n\n\n-128.57\n\n\n1927-02-08\n\n\nrad\n\n\n9.82\n\n\n\n\n-49.85\n\n\n-128.57\n\n\n1927-02-08\n\n\nsal\n\n\n0.13\n\n\n\n\n-49.85\n\n\n-128.57\n\n\n1927-02-10\n\n\nrad\n\n\n7.8\n\n\n\n\n-49.85\n\n\n-128.57\n\n\n1927-02-10\n\n\nsal\n\n\n0.09\n\n\n\n\n-47.15\n\n\n-126.72\n\n\n1939-01-07\n\n\nrad\n\n\n8.41\n\n\n\n\n-47.15\n\n\n-126.72\n\n\n1939-01-07\n\n\nsal\n\n\n0.05\n\n\n\n\n-47.15\n\n\n-126.72\n\n\n1939-01-07\n\n\ntemp\n\n\n-21.5\n\n\n\n\n-47.15\n\n\n-126.72\n\n\n1930-01-12\n\n\nrad\n\n\n7.22\n\n\n\n\n-47.15\n\n\n-126.72\n\n\n1930-01-12\n\n\nsal\n\n\n0.06\n\n\n\n\n-47.15\n\n\n-126.72\n\n\n1930-01-12\n\n\ntemp\n\n\n-26.0\n\n\n\n\n-47.15\n\n\n-126.72\n\n\n1930-02-26\n\n\nrad\n\n\n4.35\n\n\n\n\n-47.15\n\n\n-126.72\n\n\n1930-02-26\n\n\nsal\n\n\n0.1\n\n\n\n\n-47.15\n\n\n-126.72\n\n\n1930-02-26\n\n\ntemp\n\n\n-18.5\n\n\n\n\n-48.87\n\n\n-123.4\n\n\n1932-01-14\n\n\nrad\n\n\n1.46\n\n\n\n\n-48.87\n\n\n-123.4\n\n\n1932-01-14\n\n\nsal\n\n\n0.21\n\n\n\n\n-48.87\n\n\n-123.4\n\n\n1932-01-14\n\n\nsal\n\n\n22.5\n\n\n\n\n-49.85\n\n\n-128.57\n\n\n1932-03-22\n\n\nrad\n\n\n11.25\n\n\n\n\nSite, Visited, Survey 테이블의 어느 레코드가 서로 대응되지는 분간할 수 있는데 이유는 각 테이블이 기본키(primary keys)와 외래키(foreign keys)를 가지고 있기 때문이다.. 기본키는 하나의 값 혹은 여러 값의 조합으로 테이블의 각 레코드를 유일하게 식별한다. 외래키는 또 다른 테이블에 있는 유일하게 레코드를 식별하는 하나의 값(혹은 여러 값의 조합)이다. 다르게 표현하면, 외래캐는 다른 테이블에 존재하는 테이블의 기본키다. 예제 데이터베이스에서 Person.ident는 Person 테이블의 기본키인 반면에, Survey.person은 외래키로 Survey 테이블의 항목과 Person 테이블의 항목을 연결한다.\n대부분의 데이터베이스 디자이너는 모든 테이블은 잘 정의된 기본키가 있어야된다고 믿는다. 또한 이 키는 데이터와 떨어져서 만약 데이터를 변경할 필요가 있다면, 한 곳의 변경이 한 곳에만 변경을 만들어야만 한다. 이를 위한 쉬운 방법은 데이터베이스에 레코드를 추가할 때 임의의 유일한 ID를 각 레코드마다 추가하는 것이다. 실제로 이방법은 매우 흔하게 사용된다. “student numbers”, “patient numbers” 같은 이름을 ID로 사용하고, 몇몇 데이터베이스 시스템 혹은 다른 곳에서 원래 고유 레코드 식별자로 거의 항상 판명된다. 다음 쿼리가 시범으로 보여주듯이, 테이블에 레코드가 추가됨에 따라 SQLite는 자동으로 레코드에 숫자를 붙이고, 쿼리에서 이렇게 붙여진 레코드 숫자를 사용한다.\n%%sqlite survey.db\nselect rowid, * from Person;\n\n\n\n\n1\n\n\ndyer\n\n\nWilliam\n\n\nDyer\n\n\n\n\n2\n\n\npb\n\n\nFrank\n\n\nPabodie\n\n\n\n\n3\n\n\nlake\n\n\nAnderson\n\n\nLake\n\n\n\n\n4\n\n\nroe\n\n\nValentina\n\n\nRoerich\n\n\n\n\n5\n\n\ndanforth\n\n\nFrank\n\n\nDanforth\n\n\n\n\n\n9.0.1 데이터 위생 (Data Hygiene)\n지금까지 조인이 어떻게 동작하는지 살펴봤으니, 왜 관계형 모델이 그렇게 유용한지 그리고 어떻게 가장 잘 사용할 수 있는지 살펴보자. 첫번째 규칙은 모든 값은 독립 요소로 분해될 수 없는 원자(atomic)적 속성을 지녀야 한다. 즉, 구별해서 작업하고자 하는 부분을 포함해서는 안된다. 하나의 칼럼에 전체 이름을 넣는 대신에 별도로 구별되는 칼럼에 이름과 성을 저장해서 이름 컴포넌트를 뽑아내는 부분 문자열 연산(substring operation)을 사용할 필요가 없다. 좀더 중요하게는, 별도로 이름을 두 부분으로 저장한다. 왜냐하면, 공백으로 쪼개는 것은 신뢰성이 약하다. “Eloise St. Cyr” 혹은 “Jan Mikkel Steubart” 같은 이름을 생각하면 쉽게 알 수 있다.\n두번째 규칙은 모든 레코드는 유일한 기본키를 가져야한다. 내재적인 의미가 전혀없는 일련번호가 될 수 있고, 레코드의 값중의 하나 (Person 테이블의 ident 필드), 혹은 Survey 테이블에서 심지어 모든 측정값을 유일하게 식별하는 (taken, person, quant) 삼중값의 조합도 될 수 있다.\n세번째 규칙은 불필요한 정보가 없어야 한다. 예를 들어, Site테이블을 제거하고 다음과 같이 Visited 테이블을 다시 작성할 수 있다.\n\n\n\n619\n\n\n-49.85\n\n\n-128.57\n\n\n1927-02-08\n\n\n\n\n622\n\n\n-49.85\n\n\n-128.57\n\n\n1927-02-10\n\n\n\n\n734\n\n\n-47.15\n\n\n-126.72\n\n\n1939-01-07\n\n\n\n\n735\n\n\n-47.15\n\n\n-126.72\n\n\n1930-01-12\n\n\n\n\n751\n\n\n-47.15\n\n\n-126.72\n\n\n1930-02-26\n\n\n\n\n752\n\n\n-47.15\n\n\n-126.72\n\n\nnull\n\n\n\n\n837\n\n\n-48.87\n\n\n-123.40\n\n\n1932-01-14\n\n\n\n\n844\n\n\n-49.85\n\n\n-128.57\n\n\n1932-03-22\n\n\n\n사실, 스프레드쉬트와 마찬가지로 각 행에 각 측정값에 관한 모든 정보를 기록하는 하나의 테이블을 사용할 수도 있다. 문제는 이와 같은 방식으로 조직된 데이터를 일관성있게 관리하는 것은 매우 어렵다. 만약 특정한 사이트의 특정한 방문 날짜가 잘못된다면, 데이터베이스에 다수의 레코드를 변경해야한다. 더 안좋은 것은 다른 사이트도 그 날짜에 방문되었기 때문에 어느 레코드를 변경할지 추정해야하는 것이다.\n네번째 규칙은 모든 값의 단위는 명시적으로 저장되어야한다. 예제 데이터베이스는 그렇지 못해서 문제다.\nRoerich의 염분치는 다른 사람의 측정치보다 수천배 크다. 하지만, 천단위 대신에 백만 단위를 사용하고 있는지 혹은 1932년 그 사이트에 염분에 이상 실제로 있었는지 알지못한다.\n한걸음 물러나서 생각하자, 데이터와 저장하는데 사용되는 도구는 공생관계다. 테이블과 조인은 데이터가 특정 방식으로 잘 조직되었다면 매우 효과적이다. 하지만, 만약 특정 형태로 되어 있다면 효과적으로 다룰 수 있는 도구가 있기 때문에 데이터를 그와 같은 방식으로 조직하기도 한다. 인류학자가 말했듯이, 도구는 도구를 만드는 손을 만든다. (the tool shapes the hand that shapes the tool)\n\n도전 과제\n\nDR-1 사이트의 모든 방사선 측정치를 출력하는 쿼리를 작성하세요.\n“Frank” 가 방문한 모든 사이트를 출력하는 쿼리를 작성하세요.\n다음 쿼리가 무슨 결과를 산출하는지 말로 기술하세요.\nselect Site.name from Site join Visited\non Site.lat&lt;-49.0 and Site.name=Visited.site and Visited.dated&gt;='1932-00-00';\n\n\n\n주요점\n\n모든 사실은 데이터베이스에서 정확하게 한번만 표현되어야 한다.\n조인은 한 테이블의 레코드와 다른 테이블의 레코드를 모두 조합한 결과를 출력한다.\n기본키는 테이블의 레코드를 유일하게 식별하는 필드값(혹은 필드의 집합)이다.\n외래키는 또 다른 테이블의 기본키가되는 필드값(혹은 필드의 집합)이다.\n테이블사이에 기본키와 외래키를 매칭해서 의미없는 레코드의 조합을 제거할 수 있다.\n조인을 좀더 단순하고 효율적으로 만들기 위해서 키(key)는 원자값(atomic value)이 되어야 한다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>조인(Join)</span>"
    ]
  },
  {
    "objectID": "18-create.html",
    "href": "18-create.html",
    "title": "10  데이터 생성과 변형(Creating and Modifying Data)",
    "section": "",
    "text": "목표\n\n테이블을 생성하는 쿼리를 작성한다.\n레코드를 삽입, 변형, 삭제하는 쿼리를 작성한다.\n\n\n지금까지 어떻게 데이터베이스에서 정보를 추출하는지만 살펴봤다. 왜냐하면, 정보를 추가하는 것보다 정보를 조회하는 것이 더 자주 있는 일이기도 하고, 다른 연산자는 쿼리가 이해되어야만 의미가 통하기 때문이다. 만약 데이터를 생성하고 변형하고자 한다면, 다른 두짝의 명령어를 공부할 필요가 있다.\n첫번째 짝은 create table과 drop table이다. 두 단어로 작성되지만, 사실 하나의 단일 명령어다. 첫번째 명령어는 새로운 테이블을 생성한다. 인자는 테이블 칼럼의 이름과 형식이다. 예를 들어, 다음 문장은 survey 데이터베이스에 테이블 4개를 생성한다.\ncreate table Person(ident text, personal text, family text);\ncreate table Site(name text, lat real, long real);\ncreate table Visited(ident integer, site text, dated text);\ncreate table Survey(taken integer, person text, quant real, reading real);\n다음 명령어를 사용하여 테이블 중의 하나를 제거할 수도 있다.\ndrop table Survey;\n데이블을 제거할 때 매우 주의하라. 대부분의 데이터베이이스는 변경사항을 되돌리는 기능을 제공하지만, 이러한 기능에 의존하지 않는 것이 더 낫다.\n다른 데이터베이스 시스템은 테이블 칼럼의 다른 데이터 형식도 지원하지만, 대부분은 다음을 다음을 제공한다.\n\n\n\ninteger\n\n\n부호있는 정수형\n\n\n\n\nreal\n\n\n부동 소수점 실수\n\n\n\n\ntext\n\n\n문자열\n\n\n\n\nblob\n\n\n이미지 같은 “이진 대형 개체”\n\n\n\n대부분의 데이터베이스는 불(boolean)과 날짜/시간 값도 지원한다. SQLite는 불값을 정수 0 과 1 을 사용하고 날짜/시간은 앞선(earlier) 학습방식으로 표현한다. 점점 더 많은 데이터베이스가 위도와 경도 같은 지리정보 데이터 형식도 지원한다. 특정 시스템이 무슨 기능을 제공하고 제공하지 않는지 그리고 어떤 이름을 다른 데이터 형식에 부여하는지를 계속 파악하는 것은 끝없는 시스템 이식성에 대한 골치거리다.\n테이블을 생성할 때, 칼럼에 몇가지 제약사항을 지정할 수 있다. 예를 들어, Survey 테이블에 대한 좀더 좋은 정의는 다음과 같이 될 것이다.\ncreate table Survey(\n    taken   integer not null, -- where reading taken\n    person  text,             -- may not know who took it\n    quant   real not null,    -- the quantity measured\n    reading real not null,    -- the actual reading\n    primary key(taken, quant),\n    foreign key(taken) references Visited(ident),\n    foreign key(person) references Person(ident)\n);\n다시 한번, 정확하게 무슨 제약사항이 이용가능하고 어떻게 호출되는지는 어떤 데이터베이스 관리자를 사용하는야에 달려있다.\n테이블이 생성되자마자, 다른 명령어 짝 insert와 delete를 사용하여 레코드를 추가하고 제거할 수 있다. insert 문의 가장 간단한 형식은 순서대로 값을 목록으로 나열하는 것이다.\ninsert into Site values('DR-1', -49.85, -128.57);\ninsert into Site values('DR-3', -47.15, -126.72);\ninsert into Site values('MSK-4', -48.87, -123.40);\n또한, 다른 테이블에서 직접 값을 테이블에 삽입할 수도 있다.\ncreate table JustLatLong(lat text, long text);\ninsert into JustLatLong select lat, long from site;\n레코드를 삭제하는 것은 약간 난이도가 있다. 왜냐하면, 데이터베이스가 내부적으로 일관성을 보장할 필요가 있기 때문이다. 만약 하나의 단독 테이블만 관심을 둔다면, 삭제하고자 하는 레코드와 매칭되는 where절과 delete문을 함께 사용한다. 예를 들어, Frank Danforth가 어떤 측정도 하지 않았다는 것을 인지하자마자, 다음과 같이 Person 테이블에서 Frank Danforth를 제거할 수 있다.\ndelete from Person where ident = \"danforth\";\n하지만 대신에 Anderson Lake를 실수로 제거했다면 어떨까요? Survey 테이블은 Anderson Lake이 수행한 7개의 측정 레코드를 담고 있지만, 이것은 결코 일어나지 말아야 된다. Survey.person은 Person 테이블에 외래키이고, 모든 쿼리는 전자의 모든 값을 매칭하는 후자의 행이 있을 거라고 가정한다.\n이러한 문제를 참조 무결성(referential integrity)이라고 부른다. 테이블 사이의 모든 참조는 항상 제대로 해결될 수 있도록 확인할 필요가 있다. 참조 무결성을 보증하는 한 방법은 기본키로 사용하는 레코드를 삭제하기 전에 외래키로 'lake'를 사용하는 모든 레코드를 삭제하는 것이다. 만약 데이터베이스 관리자가 이 기능을 지원한다면, 연쇄적인 삭제(cascading delete)를 사용해서 자동화할 수 있다. 하지만, 이 기법은 여기서 다루는 학습 영역밖이다.\n\n모든 것을 데이터베이스에 저장하는 대신 많은 응용프로그램은 하이브리드 저장 모델을 사용한다. 천체 이미지 같은 실제 데이터는 파일에 저장되는 반면에, 파일 이름, 변경된 날짜, 커버하는 하늘의 영역, 스펙트럼 특성, 등등 정보는 데이터베이스에 저장한다. 대부분의 음악 재생기(MP3 플레이어) 소프트웨어가 작성되는 방식이기도 하다. 응용프로그램 내부 데이터베이스는 MP3 파일을 기억하고 있지만, MP3 파일 자체는 디스크에 있다.\n\n\n도전 과제\n\nSurvey.person의 null인 모든 사용자를 문자열 'unknown'으로 대체하는 SQL문을 작성하세요.\n동료중의 한명이 Robert Olmstead가 측정한 온도 측정치를 포함하는 다음과 같은 형식의 CSV 파일을 보내왔다.\nTaken,Temp\n619,-21.5\n622,-15.5\nsurvey 데이터베이스에 레코드로 추가하려고 CSV 파일을 읽고 SQL insert문을 출력하는 작은 파이썬 프로그램을 작성하세요. Person 테이블에 Olmstead 항목을 추가할 필요가 있을 것이다. 반복적으로 프로그램을 테스트하려면, SQL insert or replace 문을 자세히 살펴볼 필요도 있다.\nSQLite는 SQL 표준이 아닌 몇개 관리 명령어가 있다. 그중의 하나가 .dump로 데이터베이스를 다시 생성하는데 필요한 SQL 명령문을 출력한다. 또다른 것은 .load로 .dump에서 생성된 파일을 읽어서 데이터베이스를 복원한다. 여러분의 동료중의 한명이 텍스트인 dump 파일을 버젼 제어 시스템에 저장하는 것이 데이터베이스 변경사항을 추적하고 관리하는 좋은 방법이라고 생각한다. 이러한 접근법의 장점과 단점은 무엇일까요? (힌트: 레코드는 어느 특정한 순서로 저장되지 않는다.)\n\n\n\n주요점\n\n데이터베이스 테이블은 테이블 이름과 필드의 이름과 특성을 명시하는 쿼리를 사용해서 생성된다.\n쿼리를 사용해서 레코드는 삽입, 갱신, 삭제될 수 있다.\n모든 레코드가 유일한 기본키를 가질 때 데이터를 변경하는 것이 더 간단하고 안전하다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>데이터 생성과 변형(Creating and Modifying Data)</span>"
    ]
  },
  {
    "objectID": "19-prog.html",
    "href": "19-prog.html",
    "title": "11  데이터베이스로 프로그래밍",
    "section": "",
    "text": "목표\n\nSQL 쿼리를 실행하는 짧은 프로그램을 작성한다.\nSQL 쿼리를 포함하는 프로그램의 실행을 추적한다.\n왜 대부분의 데이터베이스 응용프로그램이 SQL 보다 다른 범용 언어로 작성되는지 설명한다.\n\n\n마무리 하면서, 파이썬 같은 범용 프로그래밍 언어에서 데이터베이스를 어떻게 접근하는지 삺펴보자. 다른 언어도 거의 같은 모델을 사용한다. 라이브러리와 함수 이름이 다를지 모르지만, 개념은 동일한다.\nsurvey.db라는 이름의 파일에 저장된 SQLite 데이터베이스에서 위도와 경도를 선택하는 짧은 파이썬 프로그램이 다음에 있다.\nimport sqlite3\nconnection = sqlite3.connect(\"survey.db\")\ncursor = connection.cursor()\ncursor.execute(\"select site.lat, site.long from site;\")\nresults = cursor.fetchall()\nfor r in results:\n    print r\ncursor.close()\nconnection.close()\n\n(-49.85, -128.57)\n(-47.15, -126.72)\n(-48.87, -123.4)\n\n\nsqlite3 라이브러리를 가져오는 것부터 프로그램이 시작한다. 만약 MySQL, DB2 혹은 다른 데이터베이스에 접속한다면, 다른 라이브러리를 가져올 것이지만, 동일한 기능을 제공한다. 그래서 만약 다른 이 데이터베이스에서 저 데이터베이스로 바꾼다면 프로그램의 나머지 부분은 변경할 필요(적어도 그렇게 많지는 않다.)가 었다.\n2번째 행이 데이터베이스에 연결을 설정한다. SQLite를 사용하기 때문에, 명시하는데 필요한 전부는 데이터베이스 파일 이름이다. 다른 데이터베이스 시스템은 사용자명과 비밀번호를 또한 제공하도록 요구할지도 모른다. 3번째 행은 연결을 이용하여 커서(cursor)를 생성한다. 편집기의 커서처럼, 커서의 역할은 데이터베이스에 어느 위치에 있는지 추적하는 것이다.\n4번째 행에서 커서를 사용해서 사용자를 대신해서 데이터베이스에 쿼리 실행 요청을 한다. 쿼리는 SQL로 작성되고 문자열로 cursor.execute에 전달된다. SQL이 제대로 작성되어 있는지 확실히 하는 것이 사용자의 몫이다. 만약 제대로 작성이 되어 있지 않거나 실행될 때 뭔가 잘못되었다면, 데이터베이스는 오류를 보고한다.\n5번째 행에 cursor.fetchall 호출에 응답하여 데이터베이스가 쿼리 결과를 반환한다. 결과는 결과집합에 각 레코드마다 하나의 항목을 가진 리스트다. 만약 리스트(6번째 행)를 루프 반복을 돌려서 리스트 항목(7번째 행)을 출력하면, 각각은 각 필드에 하나의 요소를 가진 튜플(tuple)인 것을 알 수 있다.\n마지막으로, 8번째와 9번째 행은 커서와 데이터베이스 연결을 종료한다. 왜냐하면 데이터베이스는 한번에 열수 있는 제한된 숫자의 연결만 유지할 수 있기 때문이다. 하지만, 연결을 설정하는 것은 시간이 소요되어서, 단지 백만분의 수초 후에 다시 연결을 하고 또 다른 작업을 하려는 연결을 하고, 작업을 하고 나서 연결을 종료하는 것은 하지 말아야 한다.\n실제 응용프로그램에서 쿼리는 사용자가 제공하는 값에 달려있다. 예를 들어, 다음 함수는 사용자의 ID를 매개변수로 받아서 이름을 반환한다.\nQueries in real applications will often depend on values provided by users. For example, this function takes a user’s ID as a parameter and returns their name:\ndef get_name(database_file, person_ident):\n    query = \"select personal || ' ' || family from Person where ident='\" + person_ident + \"';\"\n\n    connection = sqlite3.connect(database_file)\n    cursor = connection.cursor()\n    cursor.execute(query)\n    results = cursor.fetchall()\n    cursor.close()\n    connection.close()\n\n    return results[0][0]\n\nprint \"full name for dyer:\", get_name('survey.db', 'dyer')\n\nfull name for dyer: William Dyer\n\n\n함수의 첫번째 행에 문자열 결함을 사용해서 사용자가 넘겨준 사용자 ID를 포함하는 쿼리를 완성한다. 단순하게 보일지 모르지만, 만약 누군가 다음 문자열을 입력값으로 준다면 무슨일이 일어날까?\ndyer'; drop table Survey; select '\n프로젝트 이름 뒤에는 쓰레기(garbage)처럼 보이지만, 매우 주의깊게 고른 쓰레기다. 만약 이 문자열을 쿼리에 삽입하면, 결과는 다음과 같다.\nselect personal || ' ' || family from Person where ident='dyer'; drop table Survey; select '';\n만약 쿼리를 실행하게 된다면, 데이터베이스에 있는 테이블 중의 하나를 삭제한다.\n이것을 SQL 주입 공격(SQL injection attack)이라고 부른다. SQL 주입공격은 수년에 걸쳐서 수천개의 프로그램을 공격하는데 사용되었다. 특히, 많은 웹사이트가 먼저 사려깊게 입력값을 점검하지 않고 사용자에게서 데이터를 입력받는 값을 쿼리로 바로 입력한다.\n악의를 가진 사용자가 다양한 많은 방식으로 쿼리에 명령어를 몰래 밀어넣으려고 한다. 이러한 위협을 다루는 가장 안전한 방식은 인용부호 같은 문자를 대체 상응값으로 대체하는 것이다. 그렇게 해서 안전하게 문자열 내부에 사용자가 입력한 무엇이든지 넣을 수 있다. 문자열로 문장을 작성하는 대신에 준비된 문장(prepared statement)를 사용해서 작업할 수 있다. 만약에 준비된 문장을 사용한다면, 예제 프로그램은 다음과 같다.\ndef get_name(database_file, person_ident):\n    query = \"select personal || ' ' || family from Person where ident=?;\"\n\n    connection = sqlite3.connect(database_file)\n    cursor = connection.cursor()\n    cursor.execute(query, [person_ident])\n    results = cursor.fetchall()\n    cursor.close()\n    connection.close()\n\n    return results[0][0]\n\nprint \"full name for dyer:\", get_name('survey.db', 'dyer')\n\nfull name for dyer: William Dyer\n\n\n주요 변경사항은 쿼리 문자열과 execute 호출에 있다. 쿼리 자체 형식을 만드는 대신에 쿼리 템플릿에 값을 삽입하고자 하는 곳에 물음표를 넣는다. execute를 호출할 때, 쿼리의 물음표 숫자만큼의 값을 담고 있는 리스트를 제공한다. 라이브러리는 입력값을 순서대로 물음표와 매칭하고 특수 문자를 별도 상응값으로 번역해서 안전하게 사용하게 된다.\n\n도전 과제\n\n10.0 에서 25.0 사이의 100,000개 난수를 가지는 레코드를 가지고, reading으로 불리는 단일 필드를 가지고, Pressure라는 단일 테이블을 가지고, original.db이라는 이름을 가지는 신규 데이터베이스를 파일에 생성하는 파이썬 프로그램을 작성하세요.\noriginal.db과 동일한 구조를 가지는 backup.db으로 불리는 새로운 데이터베이스를 생성하는 파이썬 프로그램을 작성하세요. backup.db는 original.db에서 backup.db로 20.0보다 큰 모든 값을 복사한 값을 담고 있다. 어느 것이 더 빠른가요? 쿼리의 값을 필터링하는 것 혹은 주기억장치에 모든 것을 읽어드리고 파이썬에서 필터링하는 것 중에서 선택하세요.\n\n\n\n주요점\n\n일반적으로 범용 언어로 데이터베이스 응용프로그램을 작성하고 SQL 쿼리를 프로그램에 내장한다.\n데이터베이스에 접속하기 위해서 프로그램은 접속하려는 데이터베이스 관리자에 특정된 라이브러리를 사용해야 한다.\n프로그램은 하나 혹은 그 이상의 연결을 단일 데이터베이스에 열고, 각각에 대해서 활성화된 하나 혹은 그 이상의 커서를 가진다.\n프로그램은 쿼리 결과를 배치모드로 혹은 한번에 모두 읽어들인다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>데이터베이스로 프로그래밍</span>"
    ]
  },
  {
    "objectID": "21-application.html#dvd-insight-rental",
    "href": "21-application.html#dvd-insight-rental",
    "title": "15  DVD 대여 데이터베이스",
    "section": "15.1 DVD DB 인사이트",
    "text": "15.1 DVD DB 인사이트\nDVT 대여 데이터베이스를 설치했다면 다음 단계로 다양한 SQL 쿼리문을 던져 뭔가 가치 있는 정보를 추출해야만 한다. 데이터 과학: “postgreSQL - DVD 대여 데이터베이스”에서 데이터베이스 설치와 접속에 대한 사항은 확인한다.\n\n15.1.1 DB 접속 헬로월드 6\n먼저 DBI::dbConnect()를 통해 접속하고 SQL 쿼리 헬로월드를 던져보자.\n\nlibrary(RPostgres)\n\ncon &lt;- dbConnect(RPostgres::Postgres(), dbname=\"dvd\", \n                 host=\"localhost\",\n                 port=\"5432\", \n                 user=\"postgres\", \n                 password=\"1234\")\n\nactor &lt;- dbGetQuery(con, \"SELECT * FROM actor LIMIT 5\")\n\nactor\n\n  actor_id first_name    last_name         last_update\n1        1   Penelope      Guiness 2013-05-26 14:47:57\n2        2       Nick     Wahlberg 2013-05-26 14:47:57\n3        3         Ed        Chase 2013-05-26 14:47:57\n4        4   Jennifer        Davis 2013-05-26 14:47:57\n5        5     Johnny Lollobrigida 2013-05-26 14:47:57\n\n\n15.1.2 이탈/잔존고객 구매금액\ncustomer 테이블에는 active 칼럼을 통해 잔존고객과 이탈고객을 파악할 수 있다. 이를 통해서 잔존고객과 이탈고객이 몇명이고 구매금액을 파악할 수 있다. 먼저 datamodelr 팩키지를 통해 해당 테이블을 뽑아내서 이를 시각화해보자.\n\nlibrary(tidyverse)\nlibrary(datamodelr)\n\npayment &lt;- tbl(con, \"payment\") %&gt;% collect()\ncustomer &lt;- tbl(con, \"customer\") %&gt;% collect()\n\npayment_customer_model &lt;- dm_from_data_frames(payment, customer)\n\npayment_customer_model &lt;- dm_add_references(\n  payment_customer_model,\n  customer$customer_id ==  payment$customer_id\n)\n\npayment_customer_graph &lt;- dm_create_graph(payment_customer_model, rankdir = \"LR\", col_attr = c(\"column\", \"type\"))\ndm_render_graph(payment_customer_graph)\n\n\n\n\n테이블 구조 시각화 - 구매금액\n\n\ncon을 통해 DVD 대여 데이터베이스에 접속이 이루어진 상태다. 이탈고객과 잔존고객별로 구매금액에 대한 평균, 최소, 최대, 총합계를 구하려면 두 테이블을 INNER JOIN으로 customer_id를 키값으로 합치고 나서 기술통계를 산출한다.\n\nsql_query &lt;- \n\"SELECT active, \n       COUNT(*) AS num_active, \n       MIN(amount) AS min_amt, \n       AVG(amount) AS avg_amt,\n       MAX(amount) AS max_amt, \n       SUM(amount) AS total_amt\nFROM payment AS p\nINNER JOIN customer AS c\n  ON p.customer_id = c.customer_id\nGROUP BY c.active;\"\n\ndbGetQuery(con, sql_query)\n\n  active num_active min_amt  avg_amt max_amt total_amt\n1      0        369    0.99 4.092981   11.99   1510.31\n2      1      14227    0.00 4.203397   11.99  59801.73\n\n\n15.1.3 쟝르별 평균 대여평점\n앞서와 마찬가지로 쟝르별 평균 대여평점을 계산할 수 있는 테이블을 쭉 뽑아본다. 이를 통해서 3개 테이블, 즉 category, film_category, film을 뽑아놓고 각 해당 키값을 사용하여 결합시킨다.\n\ncategory &lt;- tbl(con, \"category\") %&gt;% collect()\nfilm_category &lt;- tbl(con, \"film_category\") %&gt;% collect()\nfilm &lt;- tbl(con, \"film\") %&gt;% collect()\n\nrental_rating_model &lt;- dm_from_data_frames(category, film_category, film)\n\nrental_rating_model &lt;- dm_add_references(\n  rental_rating_model,\n  category$category_id == film_category$category_id,\n  film_category$film_id == film$film_id\n)\n\nrental_rating_graph &lt;- dm_create_graph(rental_rating_model, rankdir = \"LR\", col_attr = c(\"column\", \"type\"))\ndm_render_graph(rental_rating_graph)\n\n\n\n\n테이블 구조 시각화 - 쟝르별 대여평점\n\n\n먼저 film_category와 category를 결합시켜 영화(film)가 속한 쟝르(category)를 파악한다.\n\nrate_qry &lt;- \n\"SELECT * \nFROM category AS c\nINNER JOIN film_category AS fc\n  ON c.category_id = fc.category_id\nLIMIT 5;\"\n\ndbGetQuery(con, rate_qry)\n\n  category_id        name         last_update film_id category_id..5      last_update..6\n1           6 Documentary 2006-02-15 09:46:27       1              6 2006-02-15 10:07:09\n2          11      Horror 2006-02-15 09:46:27       2             11 2006-02-15 10:07:09\n3           6 Documentary 2006-02-15 09:46:27       3              6 2006-02-15 10:07:09\n4          11      Horror 2006-02-15 09:46:27       4             11 2006-02-15 10:07:09\n5           8      Family 2006-02-15 09:46:27       5              8 2006-02-15 10:07:09\n다음으로 film 테이블을 조인하여 rental_rate를 결합하고 쟝르(category) 별로 평균평점을 구하고 이를 ORDER BY ... DESC를 사용해서 내림차순으로 정렬한다.\n\nrate_qry &lt;- \n\"SELECT c.name,\n        AVG(rental_rate) AS avg_rental_rate\nFROM category AS c\nINNER JOIN film_category AS fc\n  ON c.category_id = fc.category_id \nINNER JOIN film AS f\n  ON fc.film_id = f.film_id\nGROUP BY c.category_id\nORDER BY avg_rental_rate DESC;\"\n\ndbGetQuery(con, rate_qry)\n\n          name avg_rental_rate\n1        Games        3.252295\n2       Travel        3.235614\n3       Sci-Fi        3.219508\n4       Comedy        3.162414\n5       Sports        3.125135\n6          New        3.116984\n7      Foreign        3.099589\n8       Horror        3.025714\n9        Drama        3.022258\n10       Music        2.950784\n11    Children        2.890000\n12   Animation        2.808182\n13      Family        2.758116\n14    Classics        2.744386\n15 Documentary        2.666471\n16      Action        2.646250\n\n\n15.1.4 Top 10 DVD 영화\n가장 많이 대여된 Top 10 DVD 영화를 찾아내기 위해서 이에 해당되는 연관 테이블을 검색하여 찾아낸다. film, inventory, rental 테이블을 특정하고 서로 연결시킬 수 있는 키값을 찾아 연결시킨다.\n\nfilm &lt;- tbl(con, \"film\") %&gt;% collect()\ninventory &lt;- tbl(con, \"inventory\") %&gt;% collect()\nrental &lt;- tbl(con, \"rental\") %&gt;% collect()\n\ntop_10_model &lt;- dm_from_data_frames(film, inventory, rental)\n\ntop_10_model &lt;- dm_add_references(\n  top_10_model,\n  film$film_id == inventory$film_id,\n  inventory$inventory_id == rental$inventory_id\n)\n\ntop_10_graph &lt;- dm_create_graph(top_10_model, rankdir = \"LR\", col_attr = c(\"column\", \"type\"))\ndm_render_graph(top_10_graph)\n\n\n\n\n테이블 구조 시각화 - Top 10 DVD 영화\n\n\nfilm → inventory → rental 테이블을 순차적으로 film_id, inventory_id를 키값으로 삼아 결합시킨다. 그리고 나서 가장 많이 대여된 영화를 찾기 위해서 COUNT() 함수로 개수하고 나서 이를 내림차순 정리한다.\n\ntop_query &lt;- \n\"SELECT f.title AS movie_title, \n        COUNT(f.title) AS num_rentals\nFROM film AS f\nINNER JOIN inventory AS i\n  ON f.film_id = i.film_id\nINNER JOIN rental AS r\n  ON i.inventory_id = r.inventory_id\nGROUP BY f.title\nORDER BY num_rentals DESC;\"\n\ndbGetQuery(con, top_query) %&gt;% \n  slice_max(n=10, order_by = num_rentals)\n\n           movie_title num_rentals\n1   Bucket Brotherhood          34\n2     Rocketeer Mother          33\n3       Juggler Hardly          32\n4  Ridgemont Submarine          32\n5        Scalawag Duck          32\n6       Grit Clockwork          32\n7       Forward Temple          32\n8       Timberland Sky          31\n9            Zorro Ark          31\n10        Robbers Joon          31\n11        Hobbit Alien          31\n12        Network Peak          31\n13       Apache Divine          31\n14     Rush Goodfellas          31\n15           Wife Turn          31\n16   Goodfellas Salute          31",
    "crumbs": [
      "챗GPT SQL",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>DVD 대여 데이터베이스</span>"
    ]
  },
  {
    "objectID": "21-application.html#db-summary",
    "href": "21-application.html#db-summary",
    "title": "15  DVD 대여 데이터베이스",
    "section": "15.2 요약",
    "text": "15.2 요약\n이번 장은 파이썬에서 데이터베이스 사용 기본적인 개요에 대해 폭넓게 다루었다. 데이터를 저장하기 위해서 파이썬 딕셔너리나 일반적인 파일보다 데이터베이스를 사용하여 코드를 작성하는 것이 훨씬 복잡하다. 그래서, 만약 작성하는 응용프로그램이 실질적으로 데이터베이스 역량을 필요하지 않는다면 굳이 데이터베이스를 사용할 이유는 없다. 데이터베이스가 특히 유용한 상황은 (1) 큰 데이터셋에서 작은 임의적인 갱신이 많이 필요한 응용프로그램을 작성할 때 (2) 데이터가 너무 커서 딕셔너리에 담을 수 없고 반복적으로 정보를 검색할 때, (3) 한번 실행에서 다음 실행 때까지 데이터를 보관하고, 멈추고, 재시작하는데 매우 긴 실행 프로세스를 갖는 경우다.\n많은 응용프로그램 요구사항을 충족시키기 위해서 단일 테이블로 간단한 데이터베이스를 구축할 수 있다. 하지만, 대부분의 문제는 몇개의 테이블과 서로 다른 테이블간에 행이 연결된 관계를 요구한다. 테이블 사이 연결을 만들 때, 좀더 사려깊은 설계와 데이터베이스의 역량을 가장 잘 사용할 수 있는 데이터베이스 정규화 규칙을 따르는 것이 중요하다. 데이터베이스를 사용하는 주요 동기는 처리할 데이터의 양이 많기 때문에, 데이터를 효과적으로 모델링해서 프로그램이 가능하면 빠르게 실행되게 만드는 것이 중요하다.",
    "crumbs": [
      "챗GPT SQL",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>DVD 대여 데이터베이스</span>"
    ]
  },
  {
    "objectID": "join.html#데이터-위생",
    "href": "join.html#데이터-위생",
    "title": "9  조인(Join)",
    "section": "9.1 데이터 위생",
    "text": "9.1 데이터 위생\n데이터 위생(data hygiene)은 특히 데이터 분석, 데이터베이스 관리 및 데이터 처리에서 중요한 개념으로, 오류가 적고 정확한 데이터를 보장하기 위한 일련의 방법론을 의미한다. 지금까지 조인이 어떻게 동작하는지 살펴봤으니, 왜 관계형 모델이 그렇게 유용한지 그리고 어떻게 가장 잘 사용할 수 있는지 살펴보자. 이를 위해, 데이터베이스 설계자들이 데이터를 어떻게 구조화하는지 살펴보자.\n첫번째 규칙은 모든 값은 독립 요소로 분해될 수 없는 원자(atomic)적 속성을 지녀야 한다. 하나의 칼럼에 전체 이름을 넣는 대신에 별도로 구별되는 칼럼에 이름과 성을 저장해서 이름 컴포넌트를 뽑아내는 부분 문자열 연산(substring operation)을 사용할 필요가 없다. 좀더 중요하게는, 이름을 두 부분으로 저장한다. 왜냐하면, 공백으로 쪼개는 것은 신뢰성이 약하다. “Eloise St. Cyr” 혹은 “Jan Mikkel Steubart” 같은 이름을 생각하면 쉽게 알 수 있다.\n두번째 규칙은 모든 레코드는 유일한 기본키를 가져야한다. 내재적인 의미가 전혀없는 일련번호가 될 수도 있고, 레코드 값중의 하나 (Person 테이블의 ident 필드), 혹은 Survey 테이블에서 심지어 모든 측정값을 유일하게 식별하는 (taken, person, quant) 삼중값의 조합도 될 수 있다.\n세번째 규칙은 불필요한 정보가 없어야 한다. 예를 들어, Site테이블을 제거하고 다음과 같이 Visited 테이블을 다시 작성할 수 있다.\n\n\n\n619\n-49.85\n-128.57\n1927-02-08\n\n\n622\n-49.85\n-128.57\n1927-02-10\n\n\n734\n-47.15\n-126.72\n1939-01-07\n\n\n735\n-47.15\n-126.72\n1930-01-12\n\n\n751\n-47.15\n-126.72\n1930-02-26\n\n\n752\n-47.15\n-126.72\nnull\n\n\n837\n-48.87\n-123.40\n1932-01-14\n\n\n844\n-49.85\n-128.57\n1932-03-22\n\n\n\n사실, 스프레드쉬트와 마찬가지로 각 행에 각 측정값에 관한 모든 정보를 기록하는 하나의 테이블을 사용할 수도 있다. 문제는 이와 같은 방식으로 조직된 데이터를 일관성있게 관리하는 것은 매우 어렵다. 만약 특정한 사이트의 특정한 방문 날짜가 잘못된다면, 데이터베이스에 다수의 레코드를 변경해야한다. 더 안좋은 것은 다른 사이트도 그 날짜에 방문되었기 때문에 어느 레코드를 변경할지 추정해야하는 것이다.\n네번째 규칙은 모든 값의 단위는 명시적으로 저장되어야 한다. 예제 데이터베이스는 그렇지 못해서 문제다.\nRoerich의 염분치는 다른 사람의 측정치보다 수천배 크다. 하지만, 천단위 대신에 백만 단위를 사용하고 있는지 혹은 1932년에 측정된 값이 1939년에 측정된 값보다 1000배 큰지 알 수 없다. 그 사이트에 염분에 이상치가 실제로 있었는지 알지못한다.\n한걸음 물러나서 생각하자, 데이터와 저장하는데 사용되는 도구는 공생관계다. 테이블과 조인은 데이터가 특정 방식으로 잘 조직되었다면 매우 효과적이다. 하지만, 만약 특정 형태로 되어 있다면 효과적으로 다룰 수 있는 도구가 있기 때문에 데이터를 그와 같은 방식으로 조직하기도 한다. 인류학자가 말했듯이, 도구는 도구를 만드는 손을 만든다. (the tool shapes the hand that shapes the tool) 즉, 도구(기술, 방법론 등)가 사용자(인간, 조직 등)에게 영향을 미치며, 동시에 사용자가 그 도구를 개선하거나 변형시키는 과정을 의미한다. 결과적으로, 도구와 사용자는 서로 영향을 주고받으며 발전해 나간다는 개념을 내포하고 있다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>조인(Join)</span>"
    ]
  },
  {
    "objectID": "join.html#연습문제",
    "href": "join.html#연습문제",
    "title": "8  조인(Join)",
    "section": "8.1 연습문제",
    "text": "8.1 연습문제\n\n8.1.1 방사능 측정값 목록\nDR-1 사이트의 모든 방사선 측정치를 출력하는 쿼리를 작성하세요.\n\nSELECT\n   Survey.reading\nFROM\n   Site\n   JOIN\n      Visited\n  JOIN\n      Survey\n      ON Site.name = Visited.site\n      AND Visited.id = Survey.taken\nWHERE\n   Site.name = 'DR-1'\n   AND Survey.quant = 'rad';\n\n\n\nreading\n\n\n\n\n9.82\n\n\n7.8\n\n\n11.25\n\n\n\n\n\n8.1.2 프랭크 위치\n“Frank” 가 방문한 모든 사이트를 출력하는 쿼리를 작성하세요.\n\nSELECT\n  DISTINCT Site.name\nFROM\n  Site\n  JOIN Visited\n  JOIN Survey\n  JOIN Person ON Site.name = Visited.site\n  AND Visited.id = Survey.taken\n  AND Survey.person = Person.id\nWHERE\n  Person.personal = 'Frank';\n\n\n\nname\n\n\n\n\nDR-3\n\n\n\n\n\n8.1.3 쿼리 독해\n다음 쿼리가 무슨 결과를 산출하는지 말로 기술하세요.\nSELECT Site.name FROM Site JOIN Visited\nON Site.lat &lt; -49.0 AND Site.name = Visited.site AND Visited.dated &gt;= '1932-01-01';\n\n\n8.1.4 누가 어디에 방문했는가?\n각 사이트의 정확한 위치(위도, 경도)와 방문 날짜별로 정렬된 목록을 작성하고, 사이트를 방문한 사람의 개인 이름과 성, 그리고 측정 유형 및 측정값을 나타내는 쿼리를 작성한다. null 값은 모두 피한다. 힌트: 15개의 레코드와 8개의 필드를 얻어야 한다.\nSELECT Site.name, Site.lat, Site.long, Person.personal, Person.family, Survey.quant, Survey.reading, Visited.dated\nFROM\n   Site\n   JOIN\n      Visited\n   JOIN\n      Survey\n   JOIN\n      Person\n      ON Site.name = Visited.site\n      AND Visited.id = Survey.taken\n      AND Survey.person = Person.id\nWHERE\n   Survey.person IS NOT NULL\n   AND Visited.dated IS NOT NULL\nORDER BY\n   Visited.dated;\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nlat\nlong\npersonal\nfamily\nquant\nreading\ndated\n\n\n\n\nDR-1\n-49.85\n-128.57\nWilliam\nDyer\nrad\n9.82\n1927-02-08\n\n\nDR-1\n-49.85\n-128.57\nWilliam\nDyer\nsal\n0.13\n1927-02-08\n\n\nDR-1\n-49.85\n-128.57\nWilliam\nDyer\nrad\n7.8\n1927-02-10\n\n\nDR-1\n-49.85\n-128.57\nWilliam\nDyer\nsal\n0.09\n1927-02-10\n\n\nDR-3\n-47.15\n-126.72\nAnderson\nLake\nsal\n0.05\n1930-01-07\n\n\nDR-3\n-47.15\n-126.72\nFrank\nPabodie\nrad\n8.41\n1930-01-07\n\n\nDR-3\n-47.15\n-126.72\nFrank\nPabodie\ntemp\n-21.5\n1930-01-07\n\n\nDR-3\n-47.15\n-126.72\nFrank\nPabodie\nrad\n7.22\n1930-01-12\n\n\nDR-3\n-47.15\n-126.72\nAnderson\nLake\nsal\n0.1\n1930-02-26\n\n\nDR-3\n-47.15\n-126.72\nFrank\nPabodie\nrad\n4.35\n1930-02-26\n\n\nDR-3\n-47.15\n-126.72\nFrank\nPabodie\ntemp\n-18.5\n1930-02-26\n\n\nMSK-4\n-48.87\n-123.4\nAnderson\nLake\nrad\n1.46\n1932-01-14\n\n\nMSK-4\n-48.87\n-123.4\nAnderson\nLake\nsal\n0.21\n1932-01-14\n\n\nMSK-4\n-48.87\n-123.4\nValentina\nRoerich\nsal\n22.5\n1932-01-14\n\n\nDR-1\n-49.85\n-128.57\nValentina\nRoerich\nrad\n11.25\n1932-03-22",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>조인(Join)</span>"
    ]
  },
  {
    "objectID": "hygene.html#연습문제",
    "href": "hygene.html#연습문제",
    "title": "9  데이터 위생",
    "section": "9.2 연습문제",
    "text": "9.2 연습문제\n\n9.2.1 원자 값 식별하기\n다음 중 어떤 것이 원자 값인가? 어떤 것이 아닌가? 그 이유는 무엇인가?\n\n뉴질랜드 (New Zealand)\n87 튜링 애비뉴 (87 Turing Avenue)\n1971년 1월 25일 (January 25, 1971)\nXY 좌표 (0.5, 3.3)\n\n\n뉴질랜드는 명확한 원자 값이다.\n주소와 XY 좌표는 별도로 저장되야 하는 여러 정보를 포함하고 있다.\n\n주소, 거리명\nX 좌표, Y 좌표\n\n날짜 항목은 월, 일, 연도 요소를 포함하고 있어 덜 명확하다. 그러나 SQL에는 DATE 데이터 유형이 있으며, 날짜는 이 형식을 사용하여 저장되어야 한다. 월, 일 또는 연도를 별도로 작업해야 하는 경우, 데이터베이스 소프트웨어에서 사용 가능한 SQL 함수를 사용할 수 있다(예: SQLite EXTRACT 또는 STRFTIME).\n\n\n9.2.2 기본 키 식별하기\n다음 테이블에 기본 키는 무엇인가? 즉, 어떤 값 혹은 값들을 조합해야 레코드를 유일무이하게 식별해낼 수 있을까?\n\n\n\nlatitude\nlongitude\ndate\ntemperature\n\n\n\n\n57.3\n-22.5\n2015-01-09\n-14.2\n\n\n\n\n위도, 경도 및 날짜는 모두 온도 기록을 고유하게 식별하는 데 필요하다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>데이터 위생</span>"
    ]
  },
  {
    "objectID": "create.html",
    "href": "create.html",
    "title": "11  데이터 생성과 변형(Creating and Modifying Data)",
    "section": "",
    "text": "목표\n\n테이블을 생성하는 쿼리를 작성한다.\n레코드를 삽입, 변형, 삭제하는 쿼리를 작성한다.\n\n\n지금까지 어떻게 데이터베이스에서 정보를 추출하는지만 살펴봤다. 왜냐하면, 정보를 추가하는 것보다 정보를 조회하는 것이 더 자주 있는 일이기도 하고, 다른 연산자는 쿼리가 이해되어야만 의미가 통하기 때문이다. 만약 데이터를 생성하고 변형하고자 한다면, 다른 두짝의 명령어를 공부할 필요가 있다.\n첫번째 짝은 create table과 drop table이다. 두 단어로 작성되지만, 사실 하나의 단일 명령어다. 첫번째 명령어는 새로운 테이블을 생성한다. 인자는 테이블 칼럼의 이름과 형식이다. 예를 들어, 다음 문장은 survey 데이터베이스에 테이블 4개를 생성한다.\ncreate table Person(ident text, personal text, family text);\ncreate table Site(name text, lat real, long real);\ncreate table Visited(ident integer, site text, dated text);\ncreate table Survey(taken integer, person text, quant real, reading real);\n다음 명령어를 사용하여 테이블 중의 하나를 제거할 수도 있다.\ndrop table Survey;\n데이블을 제거할 때 매우 주의하라. 대부분의 데이터베이이스는 변경사항을 되돌리는 기능을 제공하지만, 이러한 기능에 의존하지 않는 것이 더 낫다.\n다른 데이터베이스 시스템은 테이블 칼럼의 다른 데이터 형식도 지원하지만, 대부분은 다음을 다음을 제공한다.\n\n\n\ninteger\n\n\n부호있는 정수형\n\n\n\n\nreal\n\n\n부동 소수점 실수\n\n\n\n\ntext\n\n\n문자열\n\n\n\n\nblob\n\n\n이미지 같은 “이진 대형 개체”\n\n\n\n대부분의 데이터베이스는 불(boolean)과 날짜/시간 값도 지원한다. SQLite는 불값을 정수 0 과 1 을 사용하고 날짜/시간은 앞선(earlier) 학습방식으로 표현한다. 점점 더 많은 데이터베이스가 위도와 경도 같은 지리정보 데이터 형식도 지원한다. 특정 시스템이 무슨 기능을 제공하고 제공하지 않는지 그리고 어떤 이름을 다른 데이터 형식에 부여하는지를 계속 파악하는 것은 끝없는 시스템 이식성에 대한 골치거리다.\n테이블을 생성할 때, 칼럼에 몇가지 제약사항을 지정할 수 있다. 예를 들어, Survey 테이블에 대한 좀더 좋은 정의는 다음과 같이 될 것이다.\ncreate table Survey(\n    taken   integer not null, -- where reading taken\n    person  text,             -- may not know who took it\n    quant   real not null,    -- the quantity measured\n    reading real not null,    -- the actual reading\n    primary key(taken, quant),\n    foreign key(taken) references Visited(ident),\n    foreign key(person) references Person(ident)\n);\n다시 한번, 정확하게 무슨 제약사항이 이용가능하고 어떻게 호출되는지는 어떤 데이터베이스 관리자를 사용하는야에 달려있다.\n테이블이 생성되자마자, 다른 명령어 짝 insert와 delete를 사용하여 레코드를 추가하고 제거할 수 있다. insert 문의 가장 간단한 형식은 순서대로 값을 목록으로 나열하는 것이다.\ninsert into Site values('DR-1', -49.85, -128.57);\ninsert into Site values('DR-3', -47.15, -126.72);\ninsert into Site values('MSK-4', -48.87, -123.40);\n또한, 다른 테이블에서 직접 값을 테이블에 삽입할 수도 있다.\ncreate table JustLatLong(lat text, long text);\ninsert into JustLatLong select lat, long from site;\n레코드를 삭제하는 것은 약간 난이도가 있다. 왜냐하면, 데이터베이스가 내부적으로 일관성을 보장할 필요가 있기 때문이다. 만약 하나의 단독 테이블만 관심을 둔다면, 삭제하고자 하는 레코드와 매칭되는 where절과 delete문을 함께 사용한다. 예를 들어, Frank Danforth가 어떤 측정도 하지 않았다는 것을 인지하자마자, 다음과 같이 Person 테이블에서 Frank Danforth를 제거할 수 있다.\ndelete from Person where ident = \"danforth\";\n하지만 대신에 Anderson Lake를 실수로 제거했다면 어떨까요? Survey 테이블은 Anderson Lake이 수행한 7개의 측정 레코드를 담고 있지만, 이것은 결코 일어나지 말아야 된다. Survey.person은 Person 테이블에 외래키이고, 모든 쿼리는 전자의 모든 값을 매칭하는 후자의 행이 있을 거라고 가정한다.\n이러한 문제를 참조 무결성(referential integrity)이라고 부른다. 테이블 사이의 모든 참조는 항상 제대로 해결될 수 있도록 확인할 필요가 있다. 참조 무결성을 보증하는 한 방법은 기본키로 사용하는 레코드를 삭제하기 전에 외래키로 'lake'를 사용하는 모든 레코드를 삭제하는 것이다. 만약 데이터베이스 관리자가 이 기능을 지원한다면, 연쇄적인 삭제(cascading delete)를 사용해서 자동화할 수 있다. 하지만, 이 기법은 여기서 다루는 학습 영역밖이다.\n\n모든 것을 데이터베이스에 저장하는 대신 많은 응용프로그램은 하이브리드 저장 모델을 사용한다. 천체 이미지 같은 실제 데이터는 파일에 저장되는 반면에, 파일 이름, 변경된 날짜, 커버하는 하늘의 영역, 스펙트럼 특성, 등등 정보는 데이터베이스에 저장한다. 대부분의 음악 재생기(MP3 플레이어) 소프트웨어가 작성되는 방식이기도 하다. 응용프로그램 내부 데이터베이스는 MP3 파일을 기억하고 있지만, MP3 파일 자체는 디스크에 있다.\n\n\n도전 과제\n\nSurvey.person의 null인 모든 사용자를 문자열 'unknown'으로 대체하는 SQL문을 작성하세요.\n동료중의 한명이 Robert Olmstead가 측정한 온도 측정치를 포함하는 다음과 같은 형식의 CSV 파일을 보내왔다.\nTaken,Temp\n619,-21.5\n622,-15.5\nsurvey 데이터베이스에 레코드로 추가하려고 CSV 파일을 읽고 SQL insert문을 출력하는 작은 파이썬 프로그램을 작성하세요. Person 테이블에 Olmstead 항목을 추가할 필요가 있을 것이다. 반복적으로 프로그램을 테스트하려면, SQL insert or replace 문을 자세히 살펴볼 필요도 있다.\nSQLite는 SQL 표준이 아닌 몇개 관리 명령어가 있다. 그중의 하나가 .dump로 데이터베이스를 다시 생성하는데 필요한 SQL 명령문을 출력한다. 또다른 것은 .load로 .dump에서 생성된 파일을 읽어서 데이터베이스를 복원한다. 여러분의 동료중의 한명이 텍스트인 dump 파일을 버젼 제어 시스템에 저장하는 것이 데이터베이스 변경사항을 추적하고 관리하는 좋은 방법이라고 생각한다. 이러한 접근법의 장점과 단점은 무엇일까요? (힌트: 레코드는 어느 특정한 순서로 저장되지 않는다.)\n\n\n\n주요점\n\n데이터베이스 테이블은 테이블 이름과 필드의 이름과 특성을 명시하는 쿼리를 사용해서 생성된다.\n쿼리를 사용해서 레코드는 삽입, 갱신, 삭제될 수 있다.\n모든 레코드가 유일한 기본키를 가질 때 데이터를 변경하는 것이 더 간단하고 안전하다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>데이터 생성과 변형(Creating and Modifying Data)</span>"
    ]
  },
  {
    "objectID": "prog.html#연습문제",
    "href": "prog.html#연습문제",
    "title": "11  데이터베이스 프로그래밍",
    "section": "11.1 연습문제",
    "text": "11.1 연습문제\n\n테이블 채우기 vs. 값 출력하기\nPressure라는 테이블 하나로 구성된 original.db라는 파일에 새로운 데이터베이스를 생성하는 파이썬 프로그램을 작성해보자. 테이블에는 reading이라는 단일 필드가 있으며, 10.0에서 25.0 사이의 100,000개의 무작위 숫자를 삽입한다. 이 프로그램을 실행하는 데 얼마나 걸리는가? 단순히 이 무작위 숫자를 파일에 쓰는 프로그램을 실행하는 데는 얼마나 걸리는가?\n이를 위해 먼저 sqlite3 모듈과 random 모듈을 사용할 수 있다. 데이터베이스와 테이블을 생성하고, 무작위 숫자를 생성하여 테이블에 삽입하는 코드를 작성한다. 그리고 이 프로세스가 얼마나 걸리는지 측정한다. 파일에 숫자를 쓰는 프로그램도 비슷한 방식으로 작성하고 실행 시간을 비교한다.\n\nimport sqlite3\n# import random number generator\nfrom numpy.random import uniform\n\nrandom_numbers = uniform(low=10.0, high=25.0, size=100000)\n\nconnection = sqlite3.connect(\"original.db\")\ncursor = connection.cursor()\ncursor.execute(\"CREATE TABLE Pressure (reading float not null)\")\nquery = \"INSERT INTO Pressure (reading) VALUES (?);\"\n\nfor number in random_numbers:\n    cursor.execute(query, [number])\n\ncursor.close()\n# save changes to file for next exercise\nconnection.commit()\nconnection.close()\n비교를 위해, 다음 프로그램은 무작위 숫자를 random_numbers.txt 파일에 저장한다.\nfrom numpy.random import uniform\n\nrandom_numbers = uniform(low=10.0, high=25.0, size=100000)\nwith open('random_numbers.txt', 'w') as outfile:\n    for number in random_numbers:\n        # need to add linebreak \\n\n        outfile.write(\"{}\\n\".format(number))\n\n\nSQL 필터링 vs. 파이썬 필터링\noriginal.db와 동일한 구조를 가진 새 데이터베이스 backup.db를 생성하는 파이썬 프로그램을 작성하고, original.db에서 20.0보다 큰 모든 값을 backup.db로 복사한다. 어느 것이 더 빠른가? 쿼리에서 값을 필터링하는 것, 아니면 모든 것을 메모리에 읽어 파이썬에서 필터링하는 것.\n\n첫 번째 예시는 모든 데이터를 메모리로 읽어들이고 파이썬의 if문을 사용하여 숫자를 필터링한다.\nimport sqlite3\n\nconnection_original = sqlite3.connect(\"original.db\")\ncursor_original = connection_original.cursor()\ncursor_original.execute(\"SELECT * FROM Pressure;\")\nresults = cursor_original.fetchall()\ncursor_original.close()\nconnection_original.close()\n\nconnection_backup = sqlite3.connect(\"backup.db\")\ncursor_backup = connection_backup.cursor()\ncursor_backup.execute(\"CREATE TABLE Pressure (reading float not null)\")\nquery = \"INSERT INTO Pressure (reading) VALUES (?);\"\n\nfor entry in results:\n    # number is saved in first column of the table\n    if entry[0] &gt; 20.0:\n        cursor_backup.execute(query, entry)\n\ncursor_backup.close()\nconnection_backup.commit()\nconnection_backup.close()\n반대로 다음 예제는 조건부 SELECT 문을 사용하여 SQL에서 숫자를 필터링한다. 변경된 부분은 오직 5번째 줄에서 original.db에서 값을 가져오는 부분과 15번째 줄에서 시작하는 backup.db에 숫자를 삽입하는 for 루프다. 이 버전에서는 파이썬의 if문이 필요하지 않다는 점에 주목하자.\nimport sqlite3\n\n# original.db에서 20.0보다 큰 데이터 읽기\nconn_orig = sqlite3.connect('original.db')\ncursor_orig = conn_orig.cursor()\ncursor_orig.execute('SELECT reading FROM Pressure WHERE reading &gt; 20.\n\n```python\nimport sqlite3\n\nconnection_original = sqlite3.connect(\"original.db\")\ncursor_original = connection_original.cursor()\ncursor_original.execute(\"SELECT * FROM Pressure WHERE reading &gt; 20.0;\")\nresults = cursor_original.fetchall()\ncursor_original.close()\nconnection_original.close()\n\nconnection_backup = sqlite3.connect(\"backup.db\")\ncursor_backup = connection_backup.cursor()\ncursor_backup.execute(\"CREATE TABLE Pressure (reading float not null)\")\nquery = \"INSERT INTO Pressure (reading) VALUES (?);\"\n\nfor entry in results:\n    cursor_backup.execute(query, entry)\n\ncursor_backup.close()\nconnection_backup.commit()\nconnection_backup.close()\n\n\n11.1.1 삽입문 생성\n동료중의 한명이 Robert Olmstead가 측정한 온도 측정치를 포함하는 다음과 같은 형식의 CSV 파일을 보내왔다.\nTaken,Temp\n619,-21.5\n622,-15.5\nsurvey 데이터베이스에 레코드로 추가하려고 CSV 파일을 읽고 SQL insert문을 출력하는 작은 파이썬 프로그램을 작성하세요. Person 테이블에 Olmstead 항목을 추가할 필요가 있을 것이다. 반복적으로 프로그램을 테스트하려면, SQL INSERT or REPLACE 문을 자세히 살펴볼 필요도 있다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>데이터베이스 프로그래밍</span>"
    ]
  },
  {
    "objectID": "create.html#삽입",
    "href": "create.html#삽입",
    "title": "11  데이터 생성과 변형",
    "section": "11.1 삽입",
    "text": "11.1 삽입\n테이블이 생성되면, INSERT, UPDATE, DELETE와 같은 다른 명령집합을 사용하여 레코드를 추가, 변경 및 제거할 수 있다.\n다음은 Site 테이블에 행을 삽입하는 예시다.\nINSERT INTO Site (name, lat, long) VALUES ('DR-1', -49.85, -128.57);\nINSERT INTO Site (name, lat, long) VALUES ('DR-3', -47.15, -126.72);\nINSERT INTO Site (name, lat, long) VALUES ('MSK-4', -48.87, -123.40);\n또한, 다른 테이블에서 직접 값을 테이블에 삽입할 수도 있다.\nCREATE TABLE JustLatLong(lat real, long real);\nINSERT INTO JustLatLong SELECT lat, long FROM Site;",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>데이터 생성과 변형(Creating and Modifying Data)</span>"
    ]
  },
  {
    "objectID": "create.html#갱신",
    "href": "create.html#갱신",
    "title": "11  데이터 생성과 변형",
    "section": "11.2 갱신",
    "text": "11.2 갱신\n기존 레코드를 수정하는 것은 UPDATE 문을 사용하여 수행된다. 이 작업을 수행하기 위해 데이터베이스에 어떤 테이블을 업데이트할 것인지, 필드의 값들을 어떻게 변경할 것인지, 어떤 조건에서 값들을 업데이트할 것인지를 지정해줘야 한다.\n예를 들어, 앞서 마지막 INSERT 문에서 위도와 경도 값을 잘못 입력했다면, 업데이트를 통해 이를 수정할 수 있다.\nUPDATE Site SET lat = -47.87, long = -122.40 WHERE name = 'MSK-4';\nWHERE 절을 잊지 않도록 주의하라. 그렇지 않으면 업데이트 문이 Site 테이블 모든 레코드를 수정하게 된다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>데이터 생성과 변형(Creating and Modifying Data)</span>"
    ]
  },
  {
    "objectID": "create.html#삭제",
    "href": "create.html#삭제",
    "title": "11  데이터 생성과 변형",
    "section": "11.3 삭제",
    "text": "11.3 삭제\n레코드를 삭제하는 것은 데이터베이스를 내부적으로 일관성 있게 유지해야 하기 때문에 좀 더 복잡하다. 테이블이 하나로 단순하다면, 제거하고자 하는 레코드와 일치하는 WHERE 절과 함께 DELETE 명령을 한다. 예를 들어, 프랭크 댄포스(Frank Danforth)가 어떠한 조사측정 업무도 수행하지 않았다는 것을 확인하고 반영한다면, 다음과 같이 Person 테이블에서 프랭크 댄포스를 제거한다.\nDELETE FROM Person WHERE id = 'danforth';\n그러나 앤더슨 레이크(Anderson Lake)를 대신 제거한다면 어떨까? Survey 테이블은 그가 수행한 측정의 7개 레코드를 여전히 포함할 것이다. 그러나 이러한 일은 절대 일어나서는 안 되는 일이다. Survey.person은 Person 테이블로 외래 키로, 작성된 모든 쿼리는 전자의 모든 값이 매칭되는 후자의 행이 있을 거라고 가정한다.\n이 문제를 참조 무결성(referential integrity)이라고 부른다. 테이블 간 모든 참조가 항상 올바르게 해결될 수 있도록 해야 한다. 이를 해결하는 한 가지 방법은 기본 키로 사용되는 레코드를 삭제하기 전에 외래 키로 lake를 사용하는 모든 레코드를 삭제하는 것이다. 데이터베이스 관리자가 지원한다면, 계단식 삭제(cascading delete)를 자동화할 수 있다. 하지만, 이 기법은 여기서 다루는 SQL 기본영역 밖이다.\n\n\n\n\n\n\n하이브리드 저장 모델\n\n\n\n많은 응용 프로그램들이 모든 것을 데이터베이스에 저장하는 대신 하이브리드 저장 모델을 사용한다. 실제 데이터(예: 천문학적 이미지)는 파일로 저장되며, 데이터베이스는 파일의 이름, 수정 날짜, 하늘의 어느 지역을 커버하는지, 그들의 분광 특성 등을 저장한다. 대부분의 음악 재생기(MP3 플레이어) 소프트웨어가 작성되는 방식이기도 하다. 응용프로그램 내부 데이터베이스는 MP3 파일을 기억하고 있지만, MP3 파일 자체는 디스크에 있다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>데이터 생성과 변형(Creating and Modifying Data)</span>"
    ]
  },
  {
    "objectID": "create.html#연습문제",
    "href": "create.html#연습문제",
    "title": "11  데이터 생성과 변형",
    "section": "11.4 연습문제",
    "text": "11.4 연습문제\n\n11.4.1 NULL 치환\nSurvey.person의 null인 모든 사용자를 문자열 'unknown'으로 대체하는 SQL문을 작성하세요.\n\nUPDATE Survey SET person = 'unknown' WHERE person IS NULL;\n\n\n11.4.2 SQL 백업\nSQLite는 SQL 표준에서 벗어난 몇가지 관리 명령어을 가지고 있다. 그 중 하나는 .dump로, 데이터베이스를 다시 생성하는 데 필요한 SQL 명령을 출력한다. 또 다른 하나는 .read로, .dump에 의해 생성된 파일을 읽고 데이터베이스를 복원한다. 당신의 동료는 덤프 파일(텍스트 형식)을 버전 관리에 저장하는 것이 데이터베이스의 변경을 추적하고 관리하는 좋은 방법이라고 생각한다. 이 접근 방식의 장단점은 무엇인가? (힌트: 레코드는 특정한 순서로 저장되지 않는다.)\n\n\n장점\n\n버전 관리 시스템은 덤프 파일 버전 간의 차이를 보여줄 수 있다. 데이터베이스와 같은 이진 파일의 경우에는 이것이 불가능하다\n버전 관리 시스템(VCS)은 각 버전의 전체 복사본이 아닌 버전 간의 변경 사항만 저장한다(디스크 공간 절약)\n버전 관리 로그는 데이터베이스의 각 버전에 대한 변경 이유를 설명한다\n\n단점\n\n레코드에 고정된 순서가 없기 때문에 커밋 사이에 인위적인 차이가 발생할 수 있다",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>데이터 생성과 변형(Creating and Modifying Data)</span>"
    ]
  },
  {
    "objectID": "spreadsheet.html#스프레드시트",
    "href": "spreadsheet.html#스프레드시트",
    "title": "14  엑셀에서 데이터베이스로",
    "section": "14.1 스프레드시트",
    "text": "14.1 스프레드시트\n스프레드시트는 행과 열로 구성된 데이터 시트로, 데이터를 정리하고 계산작업에 적합한 컴퓨터 응용프로그램이다. 마이크로소프트 엑셀은 가장 잘 알려진 스프레드시트 프로그램 중 하나로, 다양한 기능과 도구를 제공하여 데이터 분석, 그래프 작성, 자동화 등을 수행하여 사무자동화의 핵심 소프트웨어로 자리잡고 있다. 스프레드시트 프로그램은 시간이 지남에 따라 다양한 형태로 진화했다.\n\n비지칼크(VisiCalc): 1979년 출시된 VisiCalc은 최초의 상업적으로 성공한 스프레드시트 프로그램으로 개인 컴퓨터 사용에 혁명을 일으켰고, 스프레드시트 기본 개념을 대중에게 소개했다.\n로터스(Lotus) 1-2-3: 1983년 출시된 Lotus 1-2-3은 VisiCalc을 대체하며 스프레드시트 시장을 장악했다. 그래픽 인터페이스와 향상된 기능을 제공하며 많은 사용자들에게 사랑받았다.\n엑셀: 1985년에 매킨토시용으로 처음 출시된 후, 1987년 윈도우즈용 버전이 나왔다. Excel은 사용자 친화적 인터페이스와 다양한 기능으로 인기를 얻었다. 지속적인 업데이트와 혁신으로 오늘날 가장 널리 사용되는 스프레드시트 프로그램이 되었다.\n구글 시트(Google Sheets): 구글 시트는 클라우드 기반 스프레드시트 프로그램으로, 여러 사용자의 실시간 협업을 가능하게 한다. 2006년에 처음 출시된 이후, 접근성과 공유 기능으로 인기를 끌었다.\n캘크(Calc): 오픈 소스 스프레드시트 프로그램들은 각각 Apache OpenOffice와 LibreOffice 스위트의 일부로 엑셀과 유사한 기능을 제공하며, 무료로 사용할 수 있는 대안으로 많이 사용된다.",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>엑셀에서 데이터베이스로</span>"
    ]
  },
  {
    "objectID": "spreadsheet.html#section",
    "href": "spreadsheet.html#section",
    "title": "14  엑셀에서 데이터베이스로",
    "section": "14.2 ",
    "text": "14.2 \n\n\n\n\n\n\n바흐라이(Bahlai) 법칙\n\n\n\n\n“다른 사람의 데이터는 항상 일관성이 없고 잘못된 형식으로 되어 있다. (”Other people’s data is always inconsistent and in the wrong format.”)\n\n\n\n다음 간단한 예제를 통해서 데이터(스프레드쉬트에 내장된 참고문헌정보)를 어떻게 받아서 유용한 것으로 변경할지 살펴보자.\n출발점은 다음과 같은 2,937행을 갖는 bibliography.csv 라는 스프레드쉬트(엑셀) 파일이다.\n\n\n\n\n\n\n\n\n\n\n\nkey\ntype\nyear\nauthors\ntitle\njournal\n\n\n\n\n8SW85SQM\njournalArticle\n2013\nMcClelland, James L\nIncorporating Rapid Neocortical Learning of New Schema-Consistent Information Into Complementary Learning Systems Theory.\nJ Exp Psychol Gen\n\n\n85QV9X5F\njournalArticle\n1995\nMcClelland, J. L.; McNaughton, B. L.; O’Reilly, R. C.\nWhy There are Complementary Learning Systems in the Hippocampus and Neocortex: Insights from the Successes and Failures of Connectionist Models of Learning and Memory\nPsychological Review\n\n\nZ4X6DT6N\njournalArticle\n1990\nRatcliff, R.\nConnectionist models of recognition memory: constraints imposed by learning and forgetting functions.\nPsychological review\n\n\n\n다음을 알고자 한다:\n\n사람 각각이 얼마나 많은 논문을 기여했는가?\n누가 누구와 협업을 하는가?\n\n만약 저자 한명만 관심있다면, 첫번째 질문에 답하는데 스프레드쉬트에서 저자명을 검색할 수 있다. 그리고 나서, 저자가 포함된 행을 선택하고 수작업으로 두번째 질문에 답하는데 공동저자를 계수하면 된다. 하지만, 모든 저자에 대해 하나씩 이런 작업을 수행하는 것은 몇일이 소요된다. 거의 확실히 실수도 할 것이다. 그리고 나면, 누군가 거의 확실히 또다른 더 큰 스프레드쉬트를 건네줄 것이고, 다시 작업을 반복해서 시작해야만 된다.\n대안으로, 우리가 하려는 것이 다음에 나와있다:\n\n모든 논문에 모든 기여자에 대한 (키값, 저자명) 짝을 출력하는 작은 파이썬 프로그램을 작성한다. 예를 들어, 작성한 프로그램이 스프레드쉬트 첫 세줄을 다음과 같이 변환한다:\n8SW85SQM McClelland, James L\n85QV9X5F McClelland, J. L.\n85QV9X5F McNaughton, B. L.\n85QV9X5F O'Reilly, R. C.\nZ4X6DT6N Ratcliff, R.\n프로그램을 변경해서 데이터베이스에 키값과 저자를 삽입하는 SQL insert 문장을 생성한다.\nSQL 쿼리를 사용해서 최초 질문에 답한다.\n\n이렇게 프로그램을 작성하는 것이 질문 두개에 대한 답을 구하는데 상당한 작업처럼 보인다. 하지만, 6줄 이상되는 어떤 스프레드쉬트에 대해서도, 상당한 시간을 절약해 준다:\n\n데이터가 데이터베이스에 있으면, 다양하게 많은 질문에 묻고 답하기 쉽다.\n다음번에 주어지는 스프레드쉬트에 작성한 도구를 재사용할 수 있다.\n작업한 것에 대한 기록이 있다. (스프레드쉬트를 클릭하면 기록이 없다.)\n더 정확할 것이다.",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>엑셀에서 데이터베이스로</span>"
    ]
  },
  {
    "objectID": "spreadsheet.html#연습문제",
    "href": "spreadsheet.html#연습문제",
    "title": "14  엑셀에서 데이터베이스로",
    "section": "연습문제",
    "text": "연습문제\n\n작업을 올바른 방식으로 수행하기\nprint 문장 대신에, sqlite3 라이브러리를 사용해서, 데이터베이스를 생성하도록 파이썬 프로그램을 다시 작성하시오.\n\n\n고유한 쌍\na.author &gt; b.author 을 사용하게 되면 왜 완전히 다른 저자명 짝이 한번만 나타나게 되는지 설명하시오.\n\n\n데이터 정제\n입력값으로 저자명 두명을 받아서 만약 아마도 동일인이면 True를 반환하고 만약 동일인이 아니라면 False를 반환하는 함수를 작성하시오. 작성한 함수를 옆사람과 비교하고, 두명이 불일치하는 사례를 찾을 수 있는가?\n\n\n데이터 정제 (계속)\n지금까지 작성한 함수를 재활용하여 저자명을 정규화하시오. 작업 결과를 옆사람과 비교하시오. 정확하게 저자명과 동일한 목록을 만들어 냈는지 확인하시고, 만약 그렇지 못하다면, 상응하는 목록을 만들어 냈는지 확인하세요.",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>엑셀에서 데이터베이스로</span>"
    ]
  },
  {
    "objectID": "spreadsheet.html#파이썬-프로그래밍",
    "href": "spreadsheet.html#파이썬-프로그래밍",
    "title": "14  엑셀에서 데이터베이스로",
    "section": "14.3 파이썬 프로그래밍",
    "text": "14.3 파이썬 프로그래밍\n첫번째 단계는 스프레드쉬트 행을 (키값, 저자명) 짝으로 변환하는 것이다. 파이썬이 올바르게 스프레드쉬트를 읽어들이도록 확인하고서 시작한다:\n```{python}\n# count-lines.py\n# 스프레드쉬트에 얼마나 많은 줄이 있는지 계수한다.\n\n# -*- coding: utf-8 -*-\n\nimport sys\n\nfilename = sys.argv[1]\nreader = open(filename, 'r', encoding='UTF8')\ncount = 0\nfor line in reader:\n    count += 1\nreader.close()\n\nprint(count)\n```\n상기 코드가 이제는 칙숙해보여야 된다: 파일명이 첫번째 명령라인 인자(sys.argv[1])로 주어졌다. 따라서, 파일을 열고, for 루프를 사용해서 한줄씩 읽어들인다. 매번 루프가 실행될 때, 1을 count 변수에 더한다; 루프가 종류될 때, 파일을 닫고 계수 결과를 출력한다.\n상기 프로그램을 다음과 같이 실행한다:\n$ python code/count-lines.py data/bibliography.csv\n물론, 결과는 다음과 같다:\n2937\n그래서, 파이썬이 모든 행을 읽어들인 것을 알게된다.\n다음 단계는 각 줄을 필드로 쪼개서 각 항목에 대한 키값과 저자명을 얻게된다. 필드는 콤마로 구분된다. 그래서 str.split 사용해서 시도해볼 수 있다. 하지만, 동작하지는 않는데 이유는 저자명에도 콤마가 포함되어서 그렇다(“성, 이름”같은 형식으로 되어 있어서 그렇다).\n대신에 취할 수 있는 조치는 선호하는 검색엔진에 도움을 청한다. 물론, “python csv”에 대한 검색결과는 csv 라이브러리가 나오고, 표준 파이썬 배포판의 일부이기도 하다. 라이브러리 문서에 일부 예제가 포함되어 있다. 몇번 실험을 한 뒤에, 다음과 같은 결과가 나오게 된다:\n```{python}\n# read-fields.py\n# CSV 파일에서 필드값을 제대로 읽어 오는지 확인한다.\n\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nraw = open(sys.argv[1], 'r', encoding='utf-8')\nreader = csv.reader(raw);\n\nfor line in reader:\n    print(line)\n    \nraw.close()\n```\n작성한 프로그램은 참고문헌 파일을 열어서 시작한다(다시 한번, 첫번째 명령-라인 인자로 파일명을 넘긴다) 그리고 나서, csv.reader 메쏘드를 호출해서 파일주위에 래퍼를 생성한다. open으로 생성된 기본 파일 객체가 한번에 한줄씩 읽어올 때, csv.reader에 의해서 생성된 래퍼가 해당 라인을 올바른 지점에서 필드로 쪼갠다. csv.reader는 해당 필드에 내장된 콤마, 특수문자, 신경쓰지 않아도 되는 다른 엄청난 것에 대해 어떻게 처리하는지 알고 있다.\n올바르게 동작하는지 점검하려면, csv.reader에 의한 처리가 끝난 후에 각 줄을 출력하면 된다. 출력결과 중 첫 몇줄이 다음에 나와 있다:\n$ python code/read-fields.py data/bibliography.csv | head -5\n\n['8SW85SQM', 'journalArticle', '2013', 'McClelland, James L', 'Incorporating Rapid Neocortical Learning of New Schema-Consistent Information Into Complementary Learning Systems Theory.', 'J Exp Psychol Gen', '', '1939-2222', '', 'http://www.biomedsearch.com/nih/Incorporating-Rapid-Neocortical-Learning-New/23978185.html', '', '', '', '', '', '', '', '', '']\n['85QV9X5F', 'journalArticle', '1995', \"McClelland, J. L.; McNaughton, B. L.; O'Reilly, R. C.\", 'Why There are Complementary Learning Systems in the Hippocampus and Neocortex: Insights from the Successes and Failures of Connectionist Models of Learning and Memory', 'Psychological Review', '', '', '', '', '', '', '', '', '', '', '', '', '']\n['Z4X6DT6N', 'journalArticle', '1990', 'Ratcliff, R.', 'Connectionist models of recognition memory: constraints imposed by learning and forgetting functions.', 'Psychological review', '', '0033-295X', '', 'http://view.ncbi.nlm.nih.gov/pubmed/2186426', '', '', '', '', '', '', '', '', '']\n['F5DGU3Q4', 'bookSection', '1989', 'McCloskey, M.; Cohen, N. J.', 'Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem', 'The Psychology of Learning and Motivation, Vol. 24', '', '', '', '', '', '', '', '', '', '', '', '', '']\n['PNGQMCP5', 'conferencePaper', '2006', 'Bucilu\\xc7\\x8e, Cristian; Caruana, Rich; Niculescu-Mizil, Alexandru', 'Model compression', 'Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining', '', '', '', '', '', '', '', '', '', '', '', '', '']\n(프로그램 출력결과를 head 명령어로 실행해서 출력결과를 스크롤해서 다시 위로 올라가기 보다 첫 몇줄만 화면에 출력함에 주목한다.) 상기 결과는 정확하게 필요한 결과다: 키값이 각 리스트 첫번째 구성요소로 있고, 저자는 모두 네번째에 몰려있따. 프로그램을 변경해서, 단지 두 필드만 출력하게 변경하자:\n```{python}\n# display-fields.py\n# 키값과 저자 모두를 화면에 출력한다.\n\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nraw = open(sys.argv[1], 'r', encoding='utf-8')\nreader = csv.reader(raw);\n\nfor line in reader:\n    print (line[0], line[3])\n\nraw.close()\n    \n```\n출력결과는 다음과 같다:\n8SW85SQM McClelland, James L\n85QV9X5F McClelland, J. L.; McNaughton, B. L.; O'Reilly, R. C.\nZ4X6DT6N Ratcliff, R.\nF5DGU3Q4 McCloskey, M.; Cohen, N. J.\nPNGQMCP5 Buciluǎ, Cristian; Caruana, Rich; Niculescu-Mizil, Alexandru\n마지막 단계는 저자 다수를 갖는 행을 복수개 행으로 단일저자가 한줄에 나타나도록 변경한다. 이번이 str.split 메쏘드를 사용할 때다: 저자명이 세미콜론으로 구분되어 있어서, 저자 목록을 각 저자별로 나눌 수 있다. 또다른 루프를 사용해서 하나씩 결과를 화면에 출력한다:\n$ python code/display-authors-1.py data/bibliography.csv | head -10\n\n8SW85SQM McClelland, James L\n85QV9X5F McClelland, J. L.\n85QV9X5F McNaughton, B. L.\n85QV9X5F O'Reilly, R. C.\nZ4X6DT6N Ratcliff, R.\nF5DGU3Q4 McCloskey, M.\nF5DGU3Q4 Cohen, N. J.\nPNGQMCP5 Buciluǎ, Cristian\nPNGQMCP5 Caruana, Rich\nPNGQMCP5 Niculescu-Mizil, Alexandru\n이제 원하는 바에 가까워졌다. 하지만, 꼭 그렇지는 않다; 저자명은 실제로 세미콜론과 공백으로 구분되는데 세미콜론만으로 구분했기 때문에, 각 줄마다 두번째와 이어진 명칭에 원치않는 공백이 앞에 온다. 세미콜론과 공백으로 쪼개면 어떻게 될까?\n```{python}\n\n# display-authors-2.py\n# (키값, 저자명) 짝을 화면에 출력한다.\n\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nraw = open(sys.argv[1], 'r', encoding='utf-8')\nreader = csv.reader(raw);\n\ntry:\n    for line in reader:\n      key, authors = line[0], line[3]\n      for auth in authors.split('; '): # 세미콜론 대신에, 세미콜론과 공백 사용\n          print (key, auth)\nexcept BrokenPipeError:\n  sys.stderr.close()\n          \nraw.close()\n```\n8SW85SQM McClelland, James L\n85QV9X5F McClelland, J. L.\n85QV9X5F McNaughton, B. L.\n85QV9X5F O'Reilly, R. C.\nZ4X6DT6N Ratcliff, R.\nF5DGU3Q4 McCloskey, M.\nF5DGU3Q4 Cohen, N. J.\nPNGQMCP5 Buciluǎ, Cristian\nPNGQMCP5 Caruana, Rich\nPNGQMCP5 Niculescu-Mizil, Alexandru\n그리고나면 작업완료: 데이터 추출 첫번째 작업 완료. 뭔가 유용한 것을 얻었기 때문에, 후세를 위해서 저장한다.\n$ git init .\n\nInitialized empty Git repository in /Users/aturing/lessons/capstone-novice-spreadsheet-biblio/.git\n\n$ git add -A\n$ git status\n\nOn branch master\n\nInitial commit\n\nChanges to be committed:\n  (use \"git rm --cached &lt;file&gt;...\" to unstage)\n\n  new file:   code/count-lines.py\n  new file:   code/display-authors-1.py\n  new file:   code/display-authors-2.py\n  new file:   code/display-fields.py\n  new file:   code/read-fields.py\n  new file:   data/bibliography.csv\n\n$ git commit -m \"Extracting (key, author) pairs from bibliography\"\n\n[master (root-commit) 9db78ed] Extracting (key, author) pairsfrom bibliography\n 6 files changed, 2996 insertions(+)\n create mode 100644 code/count-lines.py\n create mode 100644 code/display-authors-1.py\n create mode 100644 code/display-authors-2.py\n create mode 100644 code/display-fields.py\n create mode 100644 code/read-fields.py\n create mode 100644 data/bibliography.csv",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>엑셀에서 데이터베이스로</span>"
    ]
  },
  {
    "objectID": "spreadsheet.html#db-쿼리",
    "href": "spreadsheet.html#db-쿼리",
    "title": "14  엑셀에서 데이터베이스로",
    "section": "14.4 DB 쿼리",
    "text": "14.4 DB 쿼리\n이제 (키값, 저자명) 짝 데이터를 갖게 되었다. 다음 단계는 관계형 데이터베이스에 데이터를 집어넣는 것이다. 그렇게 하면 질의 응답을 할 수 있다. 시작점이 이전 학습과정에서 나온 최종 스크립트는 다음과 같다:\n```{python}\n# display-authors-2.py\n# (키값, 저자명) 짝을 화면에 출력한다.\n\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nraw = open(sys.argv[1], 'r', encoding='utf-8')\nreader = csv.reader(raw);\n\ntry:\n    for line in reader:\n      key, authors = line[0], line[3]\n      for auth in authors.split('; '): # 세미콜론 대신에, 세미콜론과 공백 사용\n          print (key, auth)\nexcept BrokenPipeError:\n  sys.stderr.close()\n          \nraw.close()\n```\n상기 프로그램 실행결과는 다음과 같다:\n8SW85SQM McClelland, James L\n85QV9X5F McClelland, J. L.\n85QV9X5F McNaughton, B. L.\n85QV9X5F O'Reilly, R. C.\nZ4X6DT6N Ratcliff, R.\nF5DGU3Q4 McCloskey, M.\nF5DGU3Q4 Cohen, N. J.\nPNGQMCP5 Buciluǎ, Cristian\nPNGQMCP5 Caruana, Rich\nPNGQMCP5 Niculescu-Mizil, Alexandru\n이제 원하는 바는 일련의 SQL insert 문장을 삽입하는 것이다:\ninsert into data values('8SW85SQM', 'McClelland, James L');\ninsert into data values('85QV9X5F', 'McClelland, J. L.');\ninsert into data values('85QV9X5F', 'McNaughton, B. L.');\n그래서, 대신에 상기 데이터를 출력하도록 프로그램을 변경하자:\n```{python}\n# convert-1.py\n# 데이터베이스에 (키값, 저자명) 짝을 집어넣는 SQL 문장을 생성한다.\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nINSERT = \"insert into data values('{0}', '{1}');\"\n\nraw = open(sys.argv[1], 'r', encoding='utf-8')\n\nreader = csv.reader(raw);\n\nfor line in reader:\n  key, authors = line[0], line[3]\n  for auth in authors.split('; '): # 세미콜론 대신에, 세미콜론과 공백 사용\n    print(INSERT.format(key, auth))\n        \nraw.close()\n```\n첫번째 변경사항이 INSERT 정의로, 삽입 문장에 대한 형식 문자열(format string)이 된다. 두번째 변경사항은 키값과 저자명을 직접적으로 출력하는 대신에, 데이터 값을 str.format 을 사용하는 INSERT` 안으로 삽입하는 것이다.\n\n\n\n\n\n\n절차 생략(Cutting Corners)\n\n\n\n파이썬과 다른 언어는 데이터베이스와 상호작용하는 라이브러리가 있다. 그런데, 왜 insert 문장을 SQLite 안으로 흘려보내지 않는가? 대답은 지금까지 소개한 모든 도구를 사용하는 단순한 해답이 있기 때문이다. 만약 데이터로 좀더 복잡한 어떤 것을 해야한다면, 거의 확실히 import sqlite3 사용해서 올바른 방식으로 수행할 것이다.\n\n\n잘 동작한다, 하지만 “동작한다”라는 말은 단지 “분명한 오류없이 작업완료가 되도록 동작한다”라는 의미다. 더 가까이 검사하면, 문제가 두가지가 보인다:\n\n실제로 어떤 누구도 데이터를 삽입하는데 데이터베이스를 생성해주지는 않는다.\n저자명에 단일 인용부호를 포함할 수 있다.\n\n첫번째 문제는 풀기 쉽다 – 프로그램 시작부분에 다음 코드를 추가한다.\n```{python}\nCREATE = 'create table data(key text not null, author text not null);'\n```\n어떤 insert 문장을 출력하기 전에 출력한다. 두번째 문제는 더 까다롭다: 만약 “O’Mear, Fiona” 같은 저자명을 INSERT해서 끼워넣으려면, 결과가 다음과 같이 된다:\n```{python}\n\"insert into data values('RJS8QDC4', 'O'Mear, Fiona');\"\n```\n상기 방식은 적법한 파이썬 방법이 아니다. 문제 해결방식은 단일 인용부호 대신에 문자열 주위를 이중 인용부호를 사용하는 것이다. 왜냐하면 사람 이름에 이중 인용부호는 포함될 수 없기 때문이다. 변경사항을 마치고 나면, 전체 프로그램은 다음과 같다:\n```{python}\n# convert-2.py\n# 키값과 저자명에 대한 데이터베이스 생성.\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nCREATE = 'create table data(key text not null, author text not null);'\nINSERT = 'insert into data values(\"{0}\", \"{1}\");'\n\nprint(CREATE)\n\nraw = open(sys.argv[1], 'r')\nreader = csv.reader(raw);\nfor line in reader:\n    key, authors = line[0], line[3]\n    for auth in authors.split('; '): # 세미콜론 대신에, 세미콜론과 공백 사용\n        print INSERT.format(key, auth)\nraw.close()\n```\n프로그램을 실행해보자:\n$ python code/convert-2.py data/bibliography.csv | head -5\ncreate table data(key text not null, author text not null);\ninsert into data values(\"8SW85SQM\", \"McClelland, James L\");\ninsert into data values(\"85QV9X5F\", \"McClelland, J. L.\");\ninsert into data values(\"85QV9X5F\", \"McNaughton, B. L.\");\ninsert into data values(\"85QV9X5F\", \"O'Reilly, R. C.\");\n결과가 상당히 좋아 보인다. 그래서, 실제 데이터베이스를 생성하는데 이것을 사용하기로 한다:\n$ python code/convert-2.py data/bibliography.csv | sqlite3 bibliography.db\n상기 파이프라인 작업은 저자 컴퓨터에서 실행하는데 약 4초 걸렸고, 205 킬로바이트 bibliography.db 파일을 생성했다. 데이터베이스가 담고 있는 것을 살펴보자:\n$ sqlite3 bibliography.db\nSQLite version 3.8.5 2014-08-15 22:37:57\nEnter \".help\" for usage hints.\n\nsqlite&gt; .schema\nCREATE TABLE data(key text not null, author text not null);\n\nsqlite&gt; select * from data limit 10;\n8SW85SQM|McClelland, James L\n85QV9X5F|McClelland, J. L.\n85QV9X5F|McNaughton, B. L.\n85QV9X5F|O'Reilly, R. C.\nZ4X6DT6N|Ratcliff, R.\nF5DGU3Q4|McCloskey, M.\nF5DGU3Q4|Cohen, N. J.\nPNGQMCP5|Buciluǎ, Cristian\nPNGQMCP5|Caruana, Rich\nPNGQMCP5|Niculescu-Mizil, Alexandru\n결과가 좋아보인다. 그래서, 질의를 던져보자:\nselect author, count(*) from data group by author order by count(*) desc limit 10;\n\nBengio, Yoshua|122\nBengio, Y.|111\nHinton, Geoffrey E.|78\nLeCun, Yann|56\nHinton, G. E.|45\nSalakhutdinov, Ruslan|34\nLeCun, Y.|31\nVincent, Pascal|29\nJordan, M. I.|27\nFrasconi, P.|25\n첫번째로 보이는 것은 프로그램 작업이 성과를 내고 있다는 것이다: 누가 가장 다작하는 저자인지 명령문 하나로 이제는 알아낼 수 있다. 두번째로 보이는 것이 아직 작업을 완수한 것은 아니라는 것이다: “Bengio, Yoshua”와 “Bengio, Y.”는 거의 확실히 동일한 사람이다. 마찬가지로 “LeCun, Yann”와 “LeCun, Y.”도 동일인이다. 정말로 누가 가장 많은 논문을 썼는지 알아내려고 한다면, 동일인에 대한 다른 이름을 맞출 필요가 있다.\n\n14.5 역정규화(Denormalization)는 많은 악의 뿌리가 된다.\n데이터가 표준을 따르고, 어떤 군더더기도 없다면 정규화된 것이다. 예제 데이터는 역정규화(denormalized)됐는데, 이유는 특정 저자명이 몇가지 다른 방식으로 표현되었다. 경험적(heuristics, 휴리스틱)으로 데이터를 정규화할 수 있다. 예를 들어, “만약 성과 다른 이름의 첫부분이 매칭되면, 동일인으로 간주한다.”와 같은 방식이다. 하지만, 오류가 항상 끼어들 여지가 있다: 예제 데이터에서, “Albar, M.”이 Mohammd Albar 혹은 Michael Albar인지 어느 것이 맞는지 알 수가 없다. 따라서, 경헙적으로 정규화된 데이터에 기초한 대답은 항상 현실에 대한 근사다. 이런 경우에 사용한 경험적 방법과 직접적으로 수행한 변환에 대해 기록하는 것이 매우 중요하다. 그렇게 해서 다른 사람(미래의 본인 자신을 포함해서)이 작업한 결과물을 상호검사할 수 있게 한다.\n\n저자명을 정규화하는 대신에, 대답할 수 있는 다른 질문을 살펴보자. 누가 누구와 공동으로 논문을 썼을까?\nselect a.author, b.author from data a join data b on a.key=b.key and a.author &gt; b.author limit 10;\n\nMcNaughton, B. L.|McClelland, J. L.\nO'Reilly, R. C.|McClelland, J. L.\nO'Reilly, R. C.|McNaughton, B. L.\nMcCloskey, M.|Cohen, N. J.\nCaruana, Rich|Buciluǎ, Cristian\nNiculescu-Mizil, Alexandru|Buciluǎ, Cristian\nNiculescu-Mizil, Alexandru|Caruana, Rich\nRigamonti, Roberto|Fua, Pascal\nRigamonti, Roberto|Lepetit, Vincent\nSironi, Amos|Fua, Pascal\n(a.author &gt; b.author 을 사용하게 되면, 완전히 다른 저자명 짝이 한번만 나오게 한다.) 다른 저자 짝이 얼마나 자주 함께 논문을 작성했는지 알고자 한다면 어떨까?\nselect a.author, b.author, count(*)\nfrom data a join data b\non a.key=b.key and a.author &gt; b.author\ngroup by a.author, b.author\norder by count(*) desc\nlimit 10;\n\nVincent, Pascal|Bengio, Yoshua|27\nRoux, Nicolas Le|Bengio, Yoshua|20\nDelalleau, Olivier|Bengio, Yoshua|19\nBengio, Y.|Bengio, S.|18\nLarochelle, Hugo|Bengio, Yoshua|15\nRoux, Nicolas Le|Delalleau, Olivier|15\nVincent, P.|Bengio, Y.|15\nChapados, N.|Bengio, Y.|14\nGori, M.|Frasconi, P.|14\nSalakhutdinov, Ruslan|Hinton, Geoffrey E.|14\n다시, 데이터 정규화 문제가 있다: “Vincent, Pascal” 와 “Bengio, Yoshua” 짝은 거의 확실히 “Bengio, Y.” 와 “Bengio, S.” 짝과 같다. 하지만, 해당 문제는 수작업으로 이 데이터를 분석할 때도 있는 것이다. 데이터를 데이터베이스에 넣게 되면, 새로운 질의를 쉽게 할 수 있어, 그렇지 않다면 다룰 수 없었던 연구주제를 다룰 수 있게 한다. 마지막 단계는 작업한 스크립트를 Git에 커밋하고 커피 한잔 하면서 자축할 시간만 남았다.\n\n14.6 작업을 올바른 방식으로 수행하기\nprint 문장 대신에, sqlite3 라이브러리를 사용해서, 데이터베이스를 생성하도록 파이썬 프로그램을 다시 작성하시오.\n\n\n14.7 Distinct Pairs\na.author &gt; b.author 을 사용하게 되면 왜 완전히 다른 저자명 짝이 한번만 나타나게 되는지 설명하시오.\n\n\n14.8 정규화\n입력값으로 저자명 두명을 받아서 만약 아마도 동일인이면 True를 반환하고 만약 동일인이 아니라면 False를 반환하는 함수를 작성하라. 작성한 함수를 옆사람과 비교하시오: 두명이 불일치하는 사례를 찾을 수 있는가?\n\n\n14.9 정규화 (계속)\n이전 도전과제에서 작성한 함수를 사용해서 저자명을 정규화하시오. 작업 결과를 옆사람과 비교하시오: 정확하게 저자명과 동일한 목록을 만들어 냈나요? 만약 그렇지 못하다면, 상응하는 목록을 만들어 냈나요?",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>엑셀에서 데이터베이스로</span>"
    ]
  },
  {
    "objectID": "setup.html#db-브라우저",
    "href": "setup.html#db-브라우저",
    "title": "1  SQLite3",
    "section": "1.3 DB 브라우저",
    "text": "1.3 DB 브라우저\n\n1.3.1 SQLite DB 브라우저\nSQLite용 DB 브라우저를 여러분의 운영 체제에 맞게 https://sqlitebrowser.org/dl/ 에서 다운로드한다. SQLite용 DB 브라우저는 SQLite 데이터베이스를 생성, 편집 및 쿼리하는 시각적 도구다. SQLite는 SQLite용 DB 브라우저에 포함되어 있으므로 별도로 설치할 필요가 없습니다.\nWindows를 위한 몇 가지 옵션이 있지만, 대부분의 현대 컴퓨터는 64비트 Windows 버전을 위한 표준 설치 프로그램을 사용할 수 있다. .zip(설치 프로그램 없음) 버전은 zip 파일의 내용을 추출한 후 폴더에서 직접 실행할 수 있지만 이렇게 설치할 경우 시작 메뉴에 표시되지 않는다.\nSQLite용 DB 브라우저를 실행하여 설치가 완료되었는지 확인한다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>SQLite3</span>"
    ]
  },
  {
    "objectID": "prog-r.html#연습문제",
    "href": "prog-r.html#연습문제",
    "title": "12  데이터베이스 프로그래밍",
    "section": "연습문제",
    "text": "연습문제\n\n테이블 채우기 vs. 값 출력하기\nPressure라는 테이블 하나로 구성된 original.db라는 파일에 새로운 데이터베이스를 생성하는 R 프로그램을 작성해보자. 테이블에는 reading이라는 단일 필드가 있으며, 10.0에서 25.0 사이의 100,000개의 무작위 숫자를 삽입한다. 이 프로그램을 실행하는 데 얼마나 걸리는가? 단순히 이 무작위 숫자를 파일에 쓰는 프로그램을 실행하는 데는 얼마나 걸리는가?\n\n\nSQL 필터링 vs. R 필터링\noriginal.db와 동일한 구조를 가진 새 데이터베이스 backup.db를 생성하는 R 프로그램을 작성하고, original.db에서 20.0보다 큰 모든 값을 backup.db로 복사한다. 어느 것이 더 빠른가? 쿼리에서 값을 필터링하는 것, 아니면 모든 것을 메모리에 읽어 R에서 필터링하는 것.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>데이터베이스 프로그래밍</span>"
    ]
  },
  {
    "objectID": "spreadsheet.html#r-프로그래밍",
    "href": "spreadsheet.html#r-프로그래밍",
    "title": "14  엑셀에서 데이터베이스로",
    "section": "14.8 R 프로그래밍",
    "text": "14.8 R 프로그래밍\n난이도가 있는 복잡한 데이터의 경우 ETL 과정을 통해 데이터베이스에 넣고 SQL 쿼리를 사용하여 원하는 정보를 추출하는 것도 가능하지만 R 프로그래밍을 사용하여 동일한 작업을 수행하는 것도 가능하다. tidyverse 라이브러리를 사용하여 bibliography.csv 데이터를 읽고 처리하는 방식은 다음과 같다. 먼저, read_csv 함수로 파일을 불러오고, janitor::clean_names()로 칼럼명을 정리한 후, select와 set_names로 원하는 칼럼을 선택하고 칼럼명을 지정한다. 그런 다음 mutate와 str_split로 저자 이름을 분할하고, unnest로 이를 펼친 후, count로 각 key와 author 조합의 빈도를 계산하고 필요없는 열을 제거한다. 이후 inner_join을 사용하여 같은 데이터 프레임을 자기 자신과 조인하고, filter로 특정 조건을 만족하는 행을 필터링한다. group_by와 summarise로 그룹별로 집계하고, ungroup, arrange, top_n을 통해 결과를 정렬하고 상위 10개의 결과를 추출한다. 작성된 코드를 통해 저자들 간의 공동 작업 빈도를 분석하여 가장 자주 협업한 저자 쌍을 찾을 수 있다.\n\nlibrary(tidyverse)\n\nbiblio &lt;-  read_csv(\"data/bibliography.csv\", col_names = FALSE )\n\nbiblio_tbl &lt;- biblio |&gt; \n  janitor::clean_names() |&gt; \n  select(x1:x5) |&gt; \n  set_names(c(\"key\", \"jounral\", \"year\", \"author\", \"affiliation\"))\n\nkey_author &lt;- biblio_tbl |&gt; \n  mutate(author = str_split(author, \"; \")) |&gt; \n  unnest(author) |&gt; \n  count(key, author) |&gt; \n  select(-n)\n\nkey_author %&gt;%\n  inner_join(key_author, by = \"key\", suffix = c(\".a\", \".b\")) %&gt;%\n  filter(author.a &gt; author.b) %&gt;%\n  group_by(author.a, author.b) %&gt;%\n  summarise(count = n()) %&gt;%\n  ungroup() %&gt;%\n  arrange(desc(count)) %&gt;%\n  top_n(10, count)\n\n# A tibble: 10 × 3\n   author.a              author.b            count\n   &lt;chr&gt;                 &lt;chr&gt;               &lt;int&gt;\n 1 Vincent, Pascal       Bengio, Yoshua         27\n 2 Roux, Nicolas Le      Bengio, Yoshua         20\n 3 Delalleau, Olivier    Bengio, Yoshua         19\n 4 Bengio, Y.            Bengio, S.             18\n 5 Larochelle, Hugo      Bengio, Yoshua         15\n 6 Roux, Nicolas Le      Delalleau, Olivier     15\n 7 Vincent, P.           Bengio, Y.             15\n 8 Chapados, N.          Bengio, Y.             14\n 9 Gori, M.              Frasconi, P.           14\n10 Salakhutdinov, Ruslan Hinton, Geoffrey E.    14",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>엑셀에서 데이터베이스로</span>"
    ]
  },
  {
    "objectID": "spreadsheet.html#데이터베이스-도입",
    "href": "spreadsheet.html#데이터베이스-도입",
    "title": "13  엑셀에서 데이터베이스로",
    "section": "13.4 데이터베이스 도입",
    "text": "13.4 데이터베이스 도입\n데이터 복잡성이 일반적으로 처리할 수 있는 것을 넘어서면 “추출(Extract), 변환(Transform), 로드(Load)”라고 하는 과정을 수행해야 한다. 예를 들어 서지학 데이터에서 다음과 같은 질문에 답을 하고자 한다고 가정해 보자.\n\n각 사람이 기여한 논문의 수는 얼마인가?\n누가 누구와 협업하는가?\n\n불행히도, “다중 값 필드(multi-valued field)”가 있는 필드 때문에 바로 스프레드시트/CSV 형식 서지학 데이터를 데이터베이스에 넣을 수 없다.\n저자 한명에만 관심이 있다면, 첫번째 질문에 답하기 위해 스프레드시트에서 저자명을 검색한 다음, 그 행을 선택하고 수동으로 그녀의 공동 저자를 집계하여 두 번째 질문에 답할 수 있다. 그러나 모든 저자에 대해서 동일한 작업을 한땀한땀 수행하는 데는 며칠이 걸릴 것이며, 거의 확실하게 실수(휴먼 에러)가 있을 것이며, 그러면 누군가가 또 다른 더 큰 스프레드시트를 건네주고 처음부터 다시 시작해야 할 것이다. 하지만, 모든 저자에 대해 하나씩 이런 작업을 수행하는 것은 몇일이 소요된다. 거의 확실히 실수도 할 것이다.\n두가지 질문에 답하기 위해 많은 작업처럼 보일 수 있지만, 수십줄 이상되는 데이터에 대해서는 많은 시간을 절약할 수 있다.\n\n데이터가 데이터베이스에 존재한다면 다른 질문들도 묻고 답하기 쉬워진다.\n향후 또다른 형태 스프레드시트에 개발한 도구를 재사용할 수 있다.\n지금까지 수행한 일에 대한 기록을 가질 수 있다(스프레드시트에서 클릭하는 것으로는 얻을 수 없는 것).\n정확할 가능성이 훨씬 더 높고 빠르다.\n\n이 접근 방식을 통해 데이터를 보다 체계적이고 효율적으로 관리할 수 있으며, 데이터 분석을 위한 기반을 마련할 수 있다. 데이터베이스에 데이터를 저장함으로써, 데이터의 일관성을 유지하고, 복잡한 쿼리를 쉽게 실행할 수 있으며, 나중에 데이터를 검토하거나 업데이트할 때 시간과 노력을 절약할 수 있다. 전체적인 작업흐름은 다음과 같다.\n\n모든 논문에 모든 기여자에 대한 (키값, 저자명) 짝을 출력하는 작은 파이썬 프로그램을 작성한다. 예를 들어, 작성한 프로그램이 스프레드쉬트 첫 세줄을 다음과 같이 변환한다:\n\n8SW85SQM McClelland, James L\n85QV9X5F McClelland, J. L.\n85QV9X5F McNaughton, B. L.\n85QV9X5F O'Reilly, R. C.\nZ4X6DT6N Ratcliff, R.\n\n프로그램을 변경해서 데이터베이스에 키값과 저자를 삽입하는 SQL insert 문장을 생성한다.\nSQL 쿼리를 사용해서 최초 질문에 답한다.\n\n\n\n\n\n\n\n바흐라이(Bahlai) 법칙\n\n\n\n“다른 사람의 데이터는 항상 일관성이 없고 잘못된 형식으로 되어 있다. (”Other people’s data is always inconsistent and in the wrong format.”)",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>엑셀에서 데이터베이스로</span>"
    ]
  },
  {
    "objectID": "spreadsheet.html#데이터셋",
    "href": "spreadsheet.html#데이터셋",
    "title": "13  엑셀에서 데이터베이스로",
    "section": "13.5 데이터셋",
    "text": "13.5 데이터셋\n다음 간단한 예제를 통해서 데이터(스프레드쉬트에 내장된 참고문헌정보)를 어떻게 받아서 유용한 것으로 변경할지 살펴보자. 출발점은 다음과 같은 2,937행을 갖는 bibliography.csv 라는 스프레드쉬트(엑셀) 파일이다.\n\n\n\n\n\n\n\n\n\n\n\nkey\ntype\nyear\nauthors\ntitle\njournal\n\n\n\n\n8SW85SQM\njournalArticle\n2013\nMcClelland, James L\nIncorporating Rapid Neocortical Learning of New Schema-Consistent Information Into Complementary Learning Systems Theory.\nJ Exp Psychol Gen\n\n\n85QV9X5F\njournalArticle\n1995\nMcClelland, J. L.; McNaughton, B. L.; O’Reilly, R. C.\nWhy There are Complementary Learning Systems in the Hippocampus and Neocortex: Insights from the Successes and Failures of Connectionist Models of Learning and Memory\nPsychological Review\n\n\nZ4X6DT6N\njournalArticle\n1990\nRatcliff, R.\nConnectionist models of recognition memory: constraints imposed by learning and forgetting functions.\nPsychological review\n\n\n\n본격적인 개발에 들어가기 전에 프로그램을 개발하는 것이 시간을 얼마나 절약할 수 있고 정확도를 높이는지 살펴보자.\n\n13.5.1 확률이 얼마나 될까?\n스프레드쉬트는 2,937행을 담고 있다. 전체 분석작업의 99%를 틀리지 않게 하는데, 손으로하는 전사작업은 얼마나 정확성이 있을까? 즉, 행당 오류율이 얼마나 되어야 전체 작업을 올바르게 완수하는데 0.99 확률이 될까?\n\n\n# 전체 행의 수\ntotal_rows &lt;- 2937\n\n# 전체 작업의 99%가 정확해야 함\ndesired_accuracy &lt;- 0.99\n\n# 행당 오류율을 찾기\n# 정확도 = (1 - 오류율) ^ 전체 행의 수\n# 따라서 오류율 = 1 - (정확도의 1/전체 행의 수제곱)\nrow_error_rate &lt;- 1 - (desired_accuracy ^ (1/total_rows))\nscales::percent(row_error_rate, accuracy = 0.000001)\n#&gt; [1] \"0.000342%\"\n\n\"0.000342%\"\n\n\n13.5.2 손익분기점\n수작업으로 5분만 소요되는 작업을 (전산화해서) 10분 걸려 프로그램 작성한다면, 해당 작업을 두번 이상 수행한다면, 프로그램으로 작성할 가치가 있다. 유사하게, 특정한 저자와 공저자가 누구인지만 알아내려고 하고, 다른 질문은 전혀 없을 것이거나, 반복작업을 할 필요가 없다면, 수작업으로 스프레드쉬트를 검색하는 것이 데이터를 데이터베이스로 옮기는 프로그램을 작성하는 것보다 아마도 더 빠를 것이다.\n현재 수작업으로 하고 있는 작업을 선택하라. 매번 얼마의 시간이 소요되고, 얼마나 자주 수행하는지 추정하고, 대신에 작업을 프로그램으로 만드는데 얼마나 소요되는지 추정하라. 프로그래밍이 실질적으로 얼마나 시간을 절약해줄까? 얼마나 확신이 되나요?\n\n이 문제를 해결하기 위해, 현재 수작업으로 진행 중인 작업을 선정하고, 그 작업에 대한 다음 정보들을 추정해야 한다.\n\n작업에 소요되는 시간: 각 작업 수행에 걸리는 평균 시간을 추정한다.\n작업의 빈도: 이 작업이 얼마나 자주 수행되는지 추정한다. 예를 들어, 일주일에 몇 번 또는 한 달에 몇번 등이 된다.\n프로그램 작성에 소요되는 시간: 동일한 작업을 자동화하는 프로그램을 작성하는 데 필요한 시간을 추정한다.\n\n상기 정보를 바탕으로 프로그래밍이 실질적으로 시간을 절약해주는지를 평가할 수 있다. 시간 절약의 계산은 다음과 같은 간단한 공식으로 이루어집니다:\n\n총 절약시간 = (수작업 시간 * 작업 빈도 * 기간) - 프로그램 작성 시간\n\n여기서, “기간”은 프로그램이 사용될 예상 기간이 된다.\n예를 들어, 매주 2시간 걸리는 작업이 있고, 이를 자동화하는 프로그램을 작성하는 데 10시간이 걸린다고 가정해 보자. 프로그램이 1년 동안 사용될 것이라고 가정하면, 총 절약 시간은 다음과 같습니다:\n\n총 절약시간 = (2시간/주 * 52주) - 10시간 = 94시간\n\n프로그램 작성에 들인 시간을 고려하더라도 연간 94시간을 절약할 수 있음을 의미한다.\n유념할 점은 이러한 추정은 작업의 복잡성, 작업 빈도 및 프로그래밍 능력에 따라 달라질 수 있으므로, 여러가지 요소들을 고려하여 신중하게 추정해야 한다.\n\n\n\n\nHermans, Felienne, 와/과 Emerson Murphy-Hill. 2015. “Enron’s Spreadsheets and Related Emails: A Dataset and Analysis”. In 37th International Conference on Software Engineering, ICSE ’15.",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>엑셀에서 데이터베이스로</span>"
    ]
  },
  {
    "objectID": "spreadsheet.html#자료-추출",
    "href": "spreadsheet.html#자료-추출",
    "title": "14  엑셀에서 데이터베이스로",
    "section": "14.3 자료 추출",
    "text": "14.3 자료 추출\n첫번째 단계는 스프레드쉬트 행을 (키값, 저자명) 짝으로 추출(extract)하는 것이다. 파이썬이 올바르게 스프레드쉬트를 읽어들이는지 확인하는 것부터 시작된다. 윈도우에서 파이썬으로 CSV 파일을 읽어드리게 되면 인코딩 오류가 발생하는 경우가 있다. 이를 방지하기 위해 인코딩을 UTF-8으로 설정한다.\n```{python}\n# count-lines.py\n# 스프레드쉬트에 얼마나 많은 줄이 있는지 계수한다.\n\n# -*- coding: utf-8 -*-\n\nimport sys\n\nfilename = sys.argv[1]\nreader = open(filename, 'r', encoding='UTF-8')\ncount = 0\nfor line in reader:\n    count += 1\nreader.close()\n\nprint(count)\n```\n상기 코드가 이제는 칙숙해보여야 된다: 파일명이 첫번째 명령라인 인자(sys.argv[1])로 주어졌다. 따라서, 파일을 열고, for 루프를 사용해서 한줄씩 읽어들인다. 매번 루프가 실행될 때, 1을 count 변수에 더한다; 루프가 종류될 때, 파일을 닫고 계수 결과를 출력한다.\n상기 프로그램을 다음과 같이 실행한다:\n$ python code/count-lines.py data/bibliography.csv\n물론, 결과는 다음과 같다:\n2937\n그래서, 파이썬이 모든 행을 읽어들인 것을 알게된다.\n다음 단계는 각 줄을 필드로 쪼개서 각 항목에 대한 키값과 저자명을 얻게된다. 필드는 콤마로 구분된다. 그래서 str.split 사용해서 시도해볼 수 있다. 하지만, 동작하지는 않는데 이유는 저자명에도 콤마가 포함되어서 그렇다(“성, 이름”같은 형식으로 되어 있어서 그렇다).\n대신에 취할 수 있는 조치는 선호하는 검색엔진에 도움을 청한다. 물론, “python csv”에 대한 검색결과는 csv 라이브러리가 나오고, 표준 파이썬 배포판의 일부이기도 하다. 라이브러리 문서에 일부 예제가 포함되어 있다. 몇번 실험을 한 뒤에, 다음과 같은 결과가 나오게 된다:\n```{python}\n# read-fields.py\n# CSV 파일에서 필드값을 제대로 읽어 오는지 확인한다.\n\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nraw = open(sys.argv[1], 'r', encoding='utf-8')\nreader = csv.reader(raw);\n\nfor line in reader:\n    print(line)\n    \nraw.close()\n```\n작성한 프로그램은 참고문헌 파일을 열어서 시작한다(다시 한번, 첫번째 명령-라인 인자로 파일명을 넘긴다) 그리고 나서, csv.reader 메쏘드를 호출해서 파일주위에 래퍼를 생성한다. open으로 생성된 기본 파일 객체가 한번에 한줄씩 읽어올 때, csv.reader에 의해서 생성된 래퍼가 해당 라인을 올바른 지점에서 필드로 쪼갠다. csv.reader는 해당 필드에 내장된 콤마, 특수문자, 신경쓰지 않아도 되는 다른 엄청난 것에 대해 어떻게 처리하는지 알고 있다.\n올바르게 동작하는지 점검하려면, csv.reader에 의한 처리가 끝난 후에 각 줄을 출력하면 된다. 출력결과 중 첫 몇줄이 다음에 나와 있다:\n$ python code/read-fields.py data/bibliography.csv | head -5\n\n['8SW85SQM', 'journalArticle', '2013', 'McClelland, James L', 'Incorporating Rapid Neocortical Learning of New Schema-Consistent Information Into Complementary Learning Systems Theory.', 'J Exp Psychol Gen', '', '1939-2222', '', 'http://www.biomedsearch.com/nih/Incorporating-Rapid-Neocortical-Learning-New/23978185.html', '', '', '', '', '', '', '', '', '']\n['85QV9X5F', 'journalArticle', '1995', \"McClelland, J. L.; McNaughton, B. L.; O'Reilly, R. C.\", 'Why There are Complementary Learning Systems in the Hippocampus and Neocortex: Insights from the Successes and Failures of Connectionist Models of Learning and Memory', 'Psychological Review', '', '', '', '', '', '', '', '', '', '', '', '', '']\n['Z4X6DT6N', 'journalArticle', '1990', 'Ratcliff, R.', 'Connectionist models of recognition memory: constraints imposed by learning and forgetting functions.', 'Psychological review', '', '0033-295X', '', 'http://view.ncbi.nlm.nih.gov/pubmed/2186426', '', '', '', '', '', '', '', '', '']\n['F5DGU3Q4', 'bookSection', '1989', 'McCloskey, M.; Cohen, N. J.', 'Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem', 'The Psychology of Learning and Motivation, Vol. 24', '', '', '', '', '', '', '', '', '', '', '', '', '']\n['PNGQMCP5', 'conferencePaper', '2006', 'Bucilu\\xc7\\x8e, Cristian; Caruana, Rich; Niculescu-Mizil, Alexandru', 'Model compression', 'Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining', '', '', '', '', '', '', '', '', '', '', '', '', '']\n(프로그램 출력결과를 head 명령어로 실행해서 출력결과를 스크롤해서 다시 위로 올라가기 보다 첫 몇줄만 화면에 출력함에 주목한다.) 상기 결과는 정확하게 필요한 결과다: 키값이 각 리스트 첫번째 구성요소로 있고, 저자는 모두 네번째에 몰려있따. 프로그램을 변경해서, 단지 두 필드만 출력하게 변경하자:\n```{python}\n# display-fields.py\n# 키값과 저자 모두를 화면에 출력한다.\n\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nraw = open(sys.argv[1], 'r', encoding='utf-8')\nreader = csv.reader(raw);\n\nfor line in reader:\n    print (line[0], line[3])\n\nraw.close()\n    \n```\n출력결과는 다음과 같다:\n8SW85SQM McClelland, James L\n85QV9X5F McClelland, J. L.; McNaughton, B. L.; O'Reilly, R. C.\nZ4X6DT6N Ratcliff, R.\nF5DGU3Q4 McCloskey, M.; Cohen, N. J.\nPNGQMCP5 Buciluǎ, Cristian; Caruana, Rich; Niculescu-Mizil, Alexandru\n마지막 단계는 저자 다수를 갖는 행을 복수개 행으로 단일저자가 한줄에 나타나도록 변경한다. 이번이 str.split 메쏘드를 사용할 때다: 저자명이 세미콜론으로 구분되어 있어서, 저자 목록을 각 저자별로 나눌 수 있다. 또다른 루프를 사용해서 하나씩 결과를 화면에 출력한다:\n$ python code/display-authors-1.py data/bibliography.csv | head -10\n\n8SW85SQM McClelland, James L\n85QV9X5F McClelland, J. L.\n85QV9X5F McNaughton, B. L.\n85QV9X5F O'Reilly, R. C.\nZ4X6DT6N Ratcliff, R.\nF5DGU3Q4 McCloskey, M.\nF5DGU3Q4 Cohen, N. J.\nPNGQMCP5 Buciluǎ, Cristian\nPNGQMCP5 Caruana, Rich\nPNGQMCP5 Niculescu-Mizil, Alexandru\n이제 원하는 바에 가까워졌다. 하지만, 꼭 그렇지는 않다; 저자명은 실제로 세미콜론과 공백으로 구분되는데 세미콜론만으로 구분했기 때문에, 각 줄마다 두번째와 이어진 명칭에 원치않는 공백이 앞에 온다. 세미콜론과 공백으로 쪼개면 어떻게 될까?\n```{python}\n# display-authors-2.py\n# (키값, 저자명) 짝을 화면에 출력한다.\n\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nraw = open(sys.argv[1], 'r', encoding='utf-8')\nreader = csv.reader(raw);\n\ntry:\n    for line in reader:\n      key, authors = line[0], line[3]\n      for auth in authors.split('; '): # 세미콜론 대신에, 세미콜론과 공백 사용\n          print (key, auth)\nexcept BrokenPipeError:\n  sys.stderr.close()\n          \nraw.close()\n```\n8SW85SQM McClelland, James L\n85QV9X5F McClelland, J. L.\n85QV9X5F McNaughton, B. L.\n85QV9X5F O'Reilly, R. C.\nZ4X6DT6N Ratcliff, R.\nF5DGU3Q4 McCloskey, M.\nF5DGU3Q4 Cohen, N. J.\nPNGQMCP5 Buciluǎ, Cristian\nPNGQMCP5 Caruana, Rich\nPNGQMCP5 Niculescu-Mizil, Alexandru\n\n14.3.1 버전 관리\n이로써 데이터 추출의 첫 번째 단계가 완료되어, 재사용 가능한 유용한 코드를 얻었기 때문에, 후속 작업을 위해서 저장한다. 깃(Git) 버전 제어는 데이터 처리 및 분석의 복잡성과 변화에 대응하는 데 있어 핵심적인 역할을 한다. ETL 과정은 데이터의 추출, 변환 및 로드 과정에서 수많은 쿼리와 스크립트를 포함하며, 이러한 작업들은 지속적으로 수정 및 개선이 필요하다. Git을 사용하면 이러한 변경사항을 효과적으로 추적하고 관리할 수 있다. 오류 발생시 이전 버전으로 쉽게 되돌릴 수 있게 해주며, 팀원 간의 협업에서도 변경 사항을 쉽게 공유하고 통합할 수 있게 한다. 또한, Git은 작업의 히스토리를 기록하여 프로젝트의 진행 상황을 명확하게 파악할 수 있도록 해주어 프로젝트 관리에도 큰 도움이 된다.\ngit init . 명령어를 사용하여 현재 디렉토리에서 새로운 Git 저장소를 초기화하는데 .git 폴더를 생성하여 Git 관련 데이터를 저장할 수 있는 토대를 만든다. 다음 단계로 git add -A 명령어는 작업 디렉토리의 모든 변경사항(새로운 파일, 수정된 파일 등)을 Git 스테이징 영역에 추가하여 커밋할 파일을 준비한다. git status 명령어는 현재 Git 저장소의 상태를 보여주는데 스테이징 영역에 추가된 변경사항, 커밋되지 않은 변경사항 등이 포함된 것이 확인된다. git commit -m \"메시지\" 명령어는 스테이징 영역에 추가된 변경사항을 저장소의 이력에 기록한다. -m 옵션 뒤에는 커밋에 대한 설명을 추가한다. 예시로 “Extracting (key, author) pairs from bibliography”라는 메시지와 함께 커밋이 이루어졌으며, 6개의 파일이 변경되었고 2996개의 추가되었다.\n$ git init .\n\nInitialized empty Git repository in /Users/aturing/lessons/capstone-novice-spreadsheet-biblio/.git\n\n$ git add -A\n$ git status\n\nOn branch master\n\nInitial commit\n\nChanges to be committed:\n  (use \"git rm --cached &lt;file&gt;...\" to unstage)\n\n  new file:   code/count-lines.py\n  new file:   code/display-authors-1.py\n  new file:   code/display-authors-2.py\n  new file:   code/display-fields.py\n  new file:   code/read-fields.py\n  new file:   data/bibliography.csv\n\n$ git commit -m \"Extracting (key, author) pairs from bibliography\"\n\n[master (root-commit) 9db78ed] Extracting (key, author) pairsfrom bibliography\n 6 files changed, 2996 insertions(+)\n create mode 100644 code/count-lines.py\n create mode 100644 code/display-authors-1.py\n create mode 100644 code/display-authors-2.py\n create mode 100644 code/display-fields.py\n create mode 100644 code/read-fields.py\n create mode 100644 data/bibliography.csv",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>엑셀에서 데이터베이스로</span>"
    ]
  },
  {
    "objectID": "spreadsheet.html#버전-관리",
    "href": "spreadsheet.html#버전-관리",
    "title": "14  엑셀에서 데이터베이스로",
    "section": "14.4 버전 관리",
    "text": "14.4 버전 관리\n이로써 데이터 추출의 첫 번째 단계가 완료되어, 재사용 가능한 유용한 코드를 얻었기 때문에, 후속 작업을 위해서 저장한다. 깃(Git) 버전 제어는 데이터 처리 및 분석의 복잡성과 변화에 대응하는 데 있어 핵심적인 역할을 한다. ETL 과정은 데이터의 추출, 변환 및 로드 과정에서 수많은 쿼리와 스크립트를 포함하며, 이러한 작업들은 지속적으로 수정 및 개선이 필요하다. Git을 사용하면 이러한 변경사항을 효과적으로 추적하고 관리할 수 있다. 오류 발생시 이전 버전으로 쉽게 되돌릴 수 있게 해주며, 팀원 간의 협업에서도 변경 사항을 쉽게 공유하고 통합할 수 있게 한다. 또한, Git은 작업의 히스토리를 기록하여 프로젝트의 진행 상황을 명확하게 파악할 수 있도록 해주어 프로젝트 관리에도 큰 도움이 된다.\ngit init . 명령어를 사용하여 현재 디렉토리에서 새로운 Git 저장소를 초기화하는데 .git 폴더를 생성하여 Git 관련 데이터를 저장할 수 있는 토대를 만든다. 다음 단계로 git add -A 명령어는 작업 디렉토리의 모든 변경사항(새로운 파일, 수정된 파일 등)을 Git 스테이징 영역에 추가하여 커밋할 파일을 준비한다. git status 명령어는 현재 Git 저장소의 상태를 보여주는데 스테이징 영역에 추가된 변경사항, 커밋되지 않은 변경사항 등이 포함된 것이 확인된다. git commit -m \"메시지\" 명령어는 스테이징 영역에 추가된 변경사항을 저장소의 이력에 기록한다. -m 옵션 뒤에는 커밋에 대한 설명을 추가한다. 예시로 “Extracting (key, author) pairs from bibliography”라는 메시지와 함께 커밋이 이루어졌으며, 6개의 파일이 변경되었고 2996개의 추가되었다.\n$ git init .\n\nInitialized empty Git repository in /Users/aturing/lessons/capstone-novice-spreadsheet-biblio/.git\n\n$ git add -A\n$ git status\n\nOn branch master\n\nInitial commit\n\nChanges to be committed:\n  (use \"git rm --cached &lt;file&gt;...\" to unstage)\n\n  new file:   code/count-lines.py\n  new file:   code/display-authors-1.py\n  new file:   code/display-authors-2.py\n  new file:   code/display-fields.py\n  new file:   code/read-fields.py\n  new file:   data/bibliography.csv\n\n$ git commit -m \"Extracting (key, author) pairs from bibliography\"\n\n[master (root-commit) 9db78ed] Extracting (key, author) pairsfrom bibliography\n 6 files changed, 2996 insertions(+)\n create mode 100644 code/count-lines.py\n create mode 100644 code/display-authors-1.py\n create mode 100644 code/display-authors-2.py\n create mode 100644 code/display-fields.py\n create mode 100644 code/read-fields.py\n create mode 100644 data/bibliography.csv",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>엑셀에서 데이터베이스로</span>"
    ]
  },
  {
    "objectID": "spreadsheet.html#자료-변환",
    "href": "spreadsheet.html#자료-변환",
    "title": "14  엑셀에서 데이터베이스로",
    "section": "14.4 자료 변환",
    "text": "14.4 자료 변환\n정규화(normalization)는 데이터를 여러 테이블로 분할하는 과정으로 전체 데이터셋을 여러 테이블로 분할하는 것으로 이해하면 된다. 다만, 기억해야 할 몇 가지 규칙이 있다.\n\n다중 값 속성은 사용하지 않는다!\n모든 행은 그 행을 고유하게 식별하는 “키”를 가져야 한다.\n모든 속성은 오직 키와만 관련되어야 한다.\n\n시간이 있다면 서지학 데이터에 대한 정규화 방법을 면밀히 검토할 수 있지만 빠르고 간단한 해결책에 집중해보자.\n앞선 데이터 추출 작업으로 짝(키값, 저자명) 데이터를 갖게 되었다. 다음 단계는 관계형 데이터베이스에 데이터를 삽입하는 것이다. 데이터가 데이터베이스에 입력되면, 쿼리를 전송해서 질의 응답을 할 수 있다. 시작점으로 이전 학습과정에서 나온 최종 스크립트를 바탕으로 시작해보자.\n```{python}\n# display-authors-2.py\n# (키값, 저자명) 짝을 화면에 출력한다.\n\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nraw = open(sys.argv[1], 'r', encoding='utf-8')\nreader = csv.reader(raw);\n\ntry:\n    for line in reader:\n      key, authors = line[0], line[3]\n      for auth in authors.split('; '): # 세미콜론 대신에, 세미콜론과 공백 사용\n          print (key, auth)\nexcept BrokenPipeError:\n  sys.stderr.close()\n          \nraw.close()\n```\n상기 프로그램 실행결과는 다음과 같다:\n8SW85SQM McClelland, James L\n85QV9X5F McClelland, J. L.\n85QV9X5F McNaughton, B. L.\n85QV9X5F O'Reilly, R. C.\nZ4X6DT6N Ratcliff, R.\nF5DGU3Q4 McCloskey, M.\nF5DGU3Q4 Cohen, N. J.\nPNGQMCP5 Buciluǎ, Cristian\nPNGQMCP5 Caruana, Rich\nPNGQMCP5 Niculescu-Mizil, Alexandru\n데이터베이스에 넣을 수 있는 CSV 파일을 생성해보자.\n```{python}\n# convert-1.py\n# 데이터베이스에 로드할 수 있는 CSV로 출력결과 전송\n\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\noutput_rows=[]\n\nwith open(sys.argv[1], 'r') as raw:\n    reader = csv.reader(raw);\n    for line in reader:\n        key, authors = line[0], line[3]\n        for auth in authors.split('; '): # 세미콜론 대신에, 세미콜론과 공백 사용\n            output_rows.append([key, auth])\n\n# 출력 파일에 대해 두 번째 인수가 필요\nwith open(sys.argv[2], 'w') as csvout:\n    writer = csv.writer(csvout) # 두 번째 인수로 csv 파일 생성\n    writer.writerow([\"Key\", \"Author\"]) # 칼럼명 헤더 생성\n    writer.writerows(output_rows) # output_rows를 파일에 쓰기\n\nprint(len(output_rows)) # rows output_rows 행수를 알아야 데이터베이스에 확실하게 적재되었는지 확인 가능.\n```\n상기 프로그램을 실행하면, 다음과 같은 결과를 얻게 된다. 6,587개 키-저자 쌍이 존재함을 확인하고 데이터베이스에 적재할 준비가 되었다.\n$ python code/convert-db-1.py data/bibliography.csv data/key_author.csv\n6587\n$ head key_author.csv\nKey,Author\n8SW85SQM,\"McClelland, James L\"\n85QV9X5F,\"McClelland, J. L.\"\n85QV9X5F,\"McNaughton, B. L.\"\n85QV9X5F,\"O'Reilly, R. C.\"\nZ4X6DT6N,\"Ratcliff, R.\"\nF5DGU3Q4,\"McCloskey, M.\"\nF5DGU3Q4,\"Cohen, N. J.\"\nPNGQMCP5,\"Buciluǎ, Cristian\"\nPNGQMCP5,\"Caruana, Rich\"\n\n\n\n\n\n\n절차 생략(Cutting Corners)\n\n\n\n파이썬과 다른 언어들은 데이터베이스와 상호작용하기 위한 라이브러리를 가지고 있음에도 불구하고, 왜 이렇게 대량으로 데이터를 로드하는 방식을 사용하는 것일까? 그런데, 왜 INSERT 문장을 SQLite 안으로 흘려보내지 않는가? 대답은 지금까지 소개한 모든 도구를 사용하는 단순한 해답이 있기 때문이다. 만약 데이터로 좀더 복잡한 어떤 것을 해야한다면, 거의 확실히 import sqlite3 사용해서 작업을 수행하게 된다.",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>엑셀에서 데이터베이스로</span>"
    ]
  },
  {
    "objectID": "spreadsheet.html#적재-load",
    "href": "spreadsheet.html#적재-load",
    "title": "14  엑셀에서 데이터베이스로",
    "section": "14.5 적재 (Load)",
    "text": "14.5 적재 (Load)\n이제 데이터를 적재하기 위해 스크립트를 만들어 load_bibliography.sql 파일을 호출한다. key_author.csv 파일이 현재 작업디렉토리 아래 data 폴더 아래 저장되어 있기 대문에 다음과 같이 SQL 코드를 작성한다.\n```{sql}\n# load_bibliography.sql\n.mode csv\n.import key_author.csv key_author\n\n.header on\n.mode column\n\nSELECT *\n  FROM key_author\n LIMIT 10;\n\nSELECT count(*)\n  FROM key_author;\n```\nload_bibliography.sql 파일을 실행하게 되면 다음 결과를 얻게 된다.\n$ sqlite3\nSQLite version 3.34.1 2021-01-20 14:10:07\nEnter \".help\" for usage hints.\nConnected to a transient in-memory database.\nUse \".open FILENAME\" to reopen on a persistent database.\n\nsqlite&gt; .read code/load_bibliography.sql\nKey       Author\n--------  --------------------------\n8SW85SQM  McClelland, James L\n85QV9X5F  McClelland, J. L.\n85QV9X5F  McNaughton, B. L.\n85QV9X5F  O'Reilly, R. C.\nZ4X6DT6N  Ratcliff, R.\nF5DGU3Q4  McCloskey, M.\nF5DGU3Q4  Cohen, N. J.\nPNGQMCP5  Buciluǎ, Cristian\nPNGQMCP5  Caruana, Rich\nPNGQMCP5  Niculescu-Mizil, Alexandru\ncount(*)\n--------\n6587\nsqlite&gt; .quit",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>엑셀에서 데이터베이스로</span>"
    ]
  },
  {
    "objectID": "spreadsheet.html#쿼리-작성",
    "href": "spreadsheet.html#쿼리-작성",
    "title": "14  엑셀에서 데이터베이스로",
    "section": "14.6 쿼리 작성",
    "text": "14.6 쿼리 작성\n\n14.6.1 다작 저자\n가장 활발히 논문을 저술한 저자를 찾아보자. SQL 쿼리문을 작성해서 가장 빈도수가 높은 저자를 찾아 상위 10명을 추려보자.\n```{sql}\nsqlite&gt; SELECT author, count(*)\n   ...&gt; FROM key_author\n   ...&gt; GROUP BY author\n   ...&gt; ORDER BY count(*) desc\n   ...&gt; LIMIT 10;\n```\n그동안 노력이 결실을 맺은 첫번째 결과로, 단 하나의 명령으로 가장 많이 저술한 저자들을 알아낼 수 있다는 것이다. 두번째로 알게 된 것은 작업이 아직 끝나지 않았다는 점이다. “Bengio, Yoshua”와 “Bengio, Y.”는 거의 확실히 동일 인물이며, “LeCun, Yann”과 “LeCun, Y.”도 마찬가지다. 정말로 누가 가장 많은 논문을 썼는지 알고 싶다면, 동일 인물에 대한 식별작업을 별도로 수행해야 한다.\nAuthor                 count(*)\n---------------------  --------\nBengio, Yoshua         122\nBengio, Y.             111\nHinton, Geoffrey E.    78\nLeCun, Yann            56\nHinton, G. E.          45\nSalakhutdinov, Ruslan  34\nLeCun, Y.              31\nVincent, Pascal        29\nJordan, M. I.          27\nFrasconi, P.           25\n\n\n\n\n\n\n비정규화(Denormalization)는 많은 악의 뿌리가 된다.\n\n\n\n데이터가 표준을 따르고, 어떤 군더더기도 없다면 정규화된 것이다. 예제 데이터는 비정규화(denormalized) 적절한 사례다. 이유는 특정 저자명이 몇가지 다른 방식으로 표현되었다. 경험적(heuristics, 휴리스틱)으로 데이터를 정규화할 수 있다. 예를 들어, “만약 성과 다른 이름의 첫부분이 매칭되면, 동일인으로 간주한다.”와 같은 방식이다. 하지만, 오류가 항상 끼어들 여지가 있다. 예제 데이터에서, “Albar, M.”이 Mohammd Albar 혹은 Michael Albar인지 어느 것이 맞는지 알 수가 없다. 따라서, 경헙적으로 정규화된 데이터에 기초한 대답은 항상 현실에 대한 근사다. 이런 경우에 사용한 경험적 방법과 직접적으로 수행한 변환에 대해 기록하는 것이 매우 중요하다. 그렇게 해서 다른 사람(미래의 본인 자신을 포함해서)이 작업한 결과물을 상호검사할 수 있게 한다.\n\n\n\n\n14.6.2 공저자\n파이썬 데이터 전처리 단계의 일부로 이름을 정규화하고 데이터를 정제하는 작업은 별도로 하지 않고, 다른 질문에 답할 수 있는지 살펴봅시다. 먼저, 공저자로 가장 많이 참여한 저자를 찾아보자.\n```{sql}\nSELECT a.author, b.author \n  FROM key_author a \n  JOIN key_author b USING(key) \n WHERE a.author &gt; b.author\n LIMIT 10;\n```\nAuthor             Author           \n-----------------  -----------------\nMcNaughton, B. L.  McClelland, J. L.\nO'Reilly, R. C.    McClelland, J. L.\nO'Reilly, R. C.    McNaughton, B. L.\nMcCloskey, M.      Cohen, N. J.     \nCaruana, Rich      Buciluǎ, Cristian\nNiculescu-Mizil,   Buciluǎ, Cristian\nNiculescu-Mizil,   Caruana, Rich    \nRigamonti, Robert  Fua, Pascal      \nRigamonti, Robert  Lepetit, Vincent \nSironi, Amos       Fua, Pascal \n(a.author &gt; b.author를 사용하여 각기 다른 저자 쌍이 한 번만 나타나도록 한다.) 만약 다른 저자들이 얼마나 자주 함께 작업했는지 알고 싶다면 어떻게 해야 할까?\n```{sql}\nSELECT a.author, b.author, count(*)\n  FROM key_author a \n  JOIN key_author b USING(key) \n WHERE a.author &gt; b.author\n GROUP BY a.author, b.author\n ORDER BY count(*) desc\nlimit 10;\n```\nAuthor           Author          count(*)  \n---------------  --------------  ----------\nVincent, Pascal  Bengio, Yoshua  27        \nRoux, Nicolas L  Bengio, Yoshua  20        \nDelalleau, Oliv  Bengio, Yoshua  19        \nBengio, Y.       Bengio, S.      18        \nLarochelle, Hug  Bengio, Yoshua  15        \nRoux, Nicolas L  Delalleau, Oli  15        \nVincent, P.      Bengio, Y.      15        \nChapados, N.     Bengio, Y.      14        \nGori, M.         Frasconi, P.    14        \nSalakhutdinov,   Hinton, Geoffr  14  \n다시 한번, 우리는 데이터 정규화 문제에 직면하고 있다: “Vincent, Pascal”과 “Bengio, Yoshua” 쌍은 거의 확실히 “Vincent, P.”와 “Bengio, S.” 쌍과 동일할 것이다. 하지만 이 문제는 수작업으로 데이터를 분석할 때에도 존재했으며, 데이터베이스에 데이터를 넣음으로써 새로운 질문들을 쉽게 물어볼 수 있게 되어, 그렇지 않았다면 다룰 수 없었을 연구를 진행할 수 있게 되었다. 마지막 단계는 작업한 스크립트를 Git에 커밋하고 커피 한잔 하면서 자축할 시간만 남았다.",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>엑셀에서 데이터베이스로</span>"
    ]
  },
  {
    "objectID": "spreadsheet.html#자동화",
    "href": "spreadsheet.html#자동화",
    "title": "14  엑셀에서 데이터베이스로",
    "section": "14.8 자동화",
    "text": "14.8 자동화\n이제 원하는 바는 일련의 SQL insert 문장을 삽입하는 것이다:\ninsert into data values('8SW85SQM', 'McClelland, James L');\ninsert into data values('85QV9X5F', 'McClelland, J. L.');\ninsert into data values('85QV9X5F', 'McNaughton, B. L.');\n그래서, 대신에 상기 데이터를 출력하도록 프로그램을 변경하자:\n```{python}\n# convert-1.py\n# 데이터베이스에 (키값, 저자명) 짝을 집어넣는 SQL 문장을 생성한다.\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nINSERT = \"insert into data values('{0}', '{1}');\"\n\nraw = open(sys.argv[1], 'r', encoding='utf-8')\n\nreader = csv.reader(raw);\n\nfor line in reader:\n  key, authors = line[0], line[3]\n  for auth in authors.split('; '): # 세미콜론 대신에, 세미콜론과 공백 사용\n    print(INSERT.format(key, auth))\n        \nraw.close()\n```\n첫번째 변경사항이 INSERT 정의로, 삽입 문장에 대한 형식 문자열(format string)이 된다. 두번째 변경사항은 키값과 저자명을 직접적으로 출력하는 대신에, 데이터 값을 str.format 을 사용하는 INSERT 안으로 삽입하는 것이다.\n잘 동작한다, 하지만 “동작한다”라는 말은 단지 “분명한 오류없이 작업완료가 되도록 동작한다”라는 의미다. 더 가까이 검사하면, 문제가 두가지가 보인다:\n\n실제로 어떤 누구도 데이터를 삽입하는데 데이터베이스를 생성해주지는 않는다.\n저자명에 단일 인용부호를 포함할 수 있다.\n\n첫번째 문제는 풀기 쉽다 – 프로그램 시작부분에 다음 코드를 추가한다.\n```{python}\nCREATE = 'create table data(key text not null, author text not null);'\n```\n어떤 insert 문장을 출력하기 전에 출력한다. 두번째 문제는 더 까다롭다: 만약 “O’Mear, Fiona” 같은 저자명을 INSERT해서 끼워넣으려면, 결과가 다음과 같이 된다:\n```{python}\n\"insert into data values('RJS8QDC4', 'O'Mear, Fiona');\"\n```\n상기 방식은 적법한 파이썬 방법이 아니다. 문제 해결방식은 단일 인용부호 대신에 문자열 주위를 이중 인용부호를 사용하는 것이다. 왜냐하면 사람 이름에 이중 인용부호는 포함될 수 없기 때문이다. 변경사항을 마치고 나면, 전체 프로그램은 다음과 같다:\n```{python}\n# convert-2.py\n# 키값과 저자명에 대한 데이터베이스 생성.\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nCREATE = 'create table data(key text not null, author text not null);'\nINSERT = 'insert into data values(\"{0}\", \"{1}\");'\n\nprint(CREATE)\n\nraw = open(sys.argv[1], 'r')\nreader = csv.reader(raw);\nfor line in reader:\n    key, authors = line[0], line[3]\n    for auth in authors.split('; '): # 세미콜론 대신에, 세미콜론과 공백 사용\n        print INSERT.format(key, auth)\nraw.close()\n```\n프로그램을 실행해보자:\n$ python code/convert-2.py data/bibliography.csv | head -5\ncreate table data(key text not null, author text not null);\ninsert into data values(\"8SW85SQM\", \"McClelland, James L\");\ninsert into data values(\"85QV9X5F\", \"McClelland, J. L.\");\ninsert into data values(\"85QV9X5F\", \"McNaughton, B. L.\");\ninsert into data values(\"85QV9X5F\", \"O'Reilly, R. C.\");\n결과가 상당히 좋아 보인다. 그래서, 실제 데이터베이스를 생성하는데 이것을 사용하기로 한다:\n$ python code/convert-2.py data/bibliography.csv | sqlite3 bibliography.db\n상기 파이프라인 작업은 저자 컴퓨터에서 실행하는데 약 4초 걸렸고, 205 킬로바이트 bibliography.db 파일을 생성했다. 데이터베이스가 담고 있는 것을 살펴보자:\n$ sqlite3 bibliography.db\nSQLite version 3.8.5 2014-08-15 22:37:57\nEnter \".help\" for usage hints.\n\nsqlite&gt; .schema\nCREATE TABLE data(key text not null, author text not null);\n\nsqlite&gt; select * from data limit 10;\n8SW85SQM|McClelland, James L\n85QV9X5F|McClelland, J. L.\n85QV9X5F|McNaughton, B. L.\n85QV9X5F|O'Reilly, R. C.\nZ4X6DT6N|Ratcliff, R.\nF5DGU3Q4|McCloskey, M.\nF5DGU3Q4|Cohen, N. J.\nPNGQMCP5|Buciluǎ, Cristian\nPNGQMCP5|Caruana, Rich\nPNGQMCP5|Niculescu-Mizil, Alexandru\n결과가 좋아보인다. 그래서, 질의를 던져보자:\nselect author, count(*) from data group by author order by count(*) desc limit 10;\n\nBengio, Yoshua|122\nBengio, Y.|111\nHinton, Geoffrey E.|78\nLeCun, Yann|56\nHinton, G. E.|45\nSalakhutdinov, Ruslan|34\nLeCun, Y.|31\nVincent, Pascal|29\nJordan, M. I.|27\nFrasconi, P.|25\n첫번째로 보이는 것은 프로그램 작업이 성과를 내고 있다는 것이다: 누가 가장 다작하는 저자인지 명령문 하나로 이제는 알아낼 수 있다. 두번째로 보이는 것이 아직 작업을 완수한 것은 아니라는 것이다: “Bengio, Yoshua”와 “Bengio, Y.”는 거의 확실히 동일한 사람이다. 마찬가지로 “LeCun, Yann”와 “LeCun, Y.”도 동일인이다. 정말로 누가 가장 많은 논문을 썼는지 알아내려고 한다면, 동일인에 대한 다른 이름을 맞출 필요가 있다.\n저자명을 정규화하는 대신에, 대답할 수 있는 다른 질문을 살펴보자. 누가 누구와 공동으로 논문을 썼을까?\nselect a.author, b.author from data a join data b on a.key=b.key and a.author &gt; b.author limit 10;\n\nMcNaughton, B. L.|McClelland, J. L.\nO'Reilly, R. C.|McClelland, J. L.\nO'Reilly, R. C.|McNaughton, B. L.\nMcCloskey, M.|Cohen, N. J.\nCaruana, Rich|Buciluǎ, Cristian\nNiculescu-Mizil, Alexandru|Buciluǎ, Cristian\nNiculescu-Mizil, Alexandru|Caruana, Rich\nRigamonti, Roberto|Fua, Pascal\nRigamonti, Roberto|Lepetit, Vincent\nSironi, Amos|Fua, Pascal\n(a.author &gt; b.author 을 사용하게 되면, 완전히 다른 저자명 짝이 한번만 나오게 한다.) 다른 저자 짝이 얼마나 자주 함께 논문을 작성했는지 알고자 한다면 어떨까?\nselect a.author, b.author, count(*)\nfrom data a join data b\non a.key=b.key and a.author &gt; b.author\ngroup by a.author, b.author\norder by count(*) desc\nlimit 10;\n\nVincent, Pascal|Bengio, Yoshua|27\nRoux, Nicolas Le|Bengio, Yoshua|20\nDelalleau, Olivier|Bengio, Yoshua|19\nBengio, Y.|Bengio, S.|18\nLarochelle, Hugo|Bengio, Yoshua|15\nRoux, Nicolas Le|Delalleau, Olivier|15\nVincent, P.|Bengio, Y.|15\nChapados, N.|Bengio, Y.|14\nGori, M.|Frasconi, P.|14\nSalakhutdinov, Ruslan|Hinton, Geoffrey E.|14",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>엑셀에서 데이터베이스로</span>"
    ]
  },
  {
    "objectID": "spreadsheet.html#쉘기반-프로그래밍",
    "href": "spreadsheet.html#쉘기반-프로그래밍",
    "title": "14  엑셀에서 데이터베이스로",
    "section": "14.9 쉘기반 프로그래밍",
    "text": "14.9 쉘기반 프로그래밍\n쉘 기반 파이썬 프로그래밍으로 SQL 데이터베이스를 제작하는 방식은 명령줄 인터페이스(CLI)를 통해 파이썬 스크립트를 실행하여 데이터베이스와 테이블을 생성하고 데이터를 조작하는 것이다. 파이썬 sqlite3 라이브러리를 사용하여 데이터베이스 파일을 생성하고 연결을 설정한다. 연결 객체를 사용하여 커서 객체를 생성하고, SQL 명령어를 커서를 통해 실행하여 데이터베이스 테이블을 생성하고 데이터를 삽입한다. 예를 들어, CREATE TABLE SQL 명령어로 테이블을 생성하고, INSERT INTO 명령어로 데이터를 삽입한다. 모든 작업이 끝나면 데이터베이스 연결을 커밋하고 닫아서 변경사항을 저장한다. 이러한 방식을 통해 쉘 환경에서 파이썬 스크립트를 실행하여 데이터베이스를 제어하고 데이터를 처리함으로써, 데이터베이스 작업을 자동화하고 프로그래밍적으로 접근할 수 있는 장점을 제공한다.\nCSV 파일에서 행을 데이터베이스 레코드로 SQL INSERT 문장 통해 삽입한다. 먼저, SQL INSERT 코드를 다음과 같이 작성한다.\nINSERT INTO data VALUES ('8SW85SQM', 'McClelland, James L');\nINSERT INTO data VALUES ('85QV9X5F', 'McClelland, J. L.');\nINSERT INTO data VALUES ('85QV9X5F', 'McNaughton, B. L.');\n그래서, 대신에 상기 데이터를 출력하도록 프로그램을 변경하자:\n```{python}\n# convert-1.py\n# 데이터베이스에 (키값, 저자명) 짝을 집어넣는 SQL 문장을 생성한다.\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nINSERT = \"INSERT INTO data VALUES('{0}', '{1}');\"\n\nraw = open(sys.argv[1], 'r', encoding='utf-8')\n\nreader = csv.reader(raw);\n\nfor line in reader:\n  key, authors = line[0], line[3]\n  for auth in authors.split('; '): # 세미콜론 대신에, 세미콜론과 공백 사용\n    print(INSERT.format(key, auth))\n        \nraw.close()\n```\n첫번째 변경사항이 INSERT 정의로, 삽입 문장에 대한 형식 문자열(format string)이 된다. 두번째 변경사항은 키값과 저자명을 직접적으로 출력하는 대신에, 데이터 값을 str.format 을 사용하는 INSERT 안으로 삽입하는 것이다.\n잘 동작한다, 하지만 “동작한다”라는 말은 단지 “분명한 오류없이 작업완료가 되도록 동작한다”라는 의미다. 더 가까이 검사하면, 문제가 두가지가 보인다:\n\n실제로 어떤 누구도 데이터를 삽입하는데 데이터베이스를 생성해주지는 않는다.\n저자명에 단일 인용부호를 포함할 수 있다.\n\n첫번째 문제는 풀기 쉽다. 프로그램 시작부분에 다음 코드를 추가한다.\nCREATE = 'CREATE TABLE data(key text not null, author text not null);'\n어떤 insert 문장을 출력하기 전에 출력한다. 두번째 문제는 더 까다롭다: 만약 “O’Mear, Fiona” 같은 저자명을 INSERT해서 끼워넣으려면, 결과가 다음과 같이 된다:\n\"INSERT INTO data VALUES('RJS8QDC4', 'O'Mear, Fiona');\"\n상기 방식은 적법한 파이썬 방법이 아니다. 문제 해결방식은 단일 인용부호 대신에 문자열 주위를 이중 인용부호를 사용하는 것이다. 왜냐하면 사람 이름에 이중 인용부호는 포함될 수 없기 때문이다. 변경사항을 마치고 나면, 전체 프로그램은 다음과 같다:\n```{python}\n# convert-2.py\n# 키값과 저자명에 대한 데이터베이스 생성.\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nCREATE = 'CREATE TABLE data(key text not null, author text not null);'\nINSERT = 'INSERT INTO data VALUES(\"{0}\", \"{1}\");'\n\nprint(CREATE)\n\nraw = open(sys.argv[1], 'r')\nreader = csv.reader(raw);\nfor line in reader:\n    key, authors = line[0], line[3]\n    for auth in authors.split('; '): # 세미콜론 대신에, 세미콜론과 공백 사용\n        print INSERT.format(key, auth)\nraw.close()\n```\n프로그램을 실행해보자:\n$ python code/convert-2.py data/bibliography.csv | head -5\nCREATE TABLE data(key text not null, author text not null);\nINSERT INTO data VALUES(\"8SW85SQM\", \"McClelland, James L\");\nINSERT INTO data VALUES(\"85QV9X5F\", \"McClelland, J. L.\");\nINSERT INTO data VALUES(\"85QV9X5F\", \"McNaughton, B. L.\");\nINSERT INTO data VALUES(\"85QV9X5F\", \"O'Reilly, R. C.\");\n결과가 상당히 좋아 보인다. 그래서, 실제 데이터베이스를 생성하는데 이것을 사용하기로 한다:\n$ python code/convert-2.py data/bibliography.csv | sqlite3 bibliography.db\n상기 파이프라인 작업은 저자 컴퓨터에서 실행하는데 약 4초 걸렸고, 205 킬로바이트 bibliography.db 파일을 생성했다. 데이터베이스가 담고 있는 것을 살펴보자:\n$ sqlite3 bibliography.db\nSQLite version 3.8.5 2014-08-15 22:37:57\nEnter \".help\" for usage hints.\n\nsqlite&gt; .schema\nCREATE TABLE data(key text not null, author text not null);\n\nsqlite&gt; SELECT * FROM data LIMIT 10;\n8SW85SQM|McClelland, James L\n85QV9X5F|McClelland, J. L.\n85QV9X5F|McNaughton, B. L.\n85QV9X5F|O'Reilly, R. C.\nZ4X6DT6N|Ratcliff, R.\nF5DGU3Q4|McCloskey, M.\nF5DGU3Q4|Cohen, N. J.\nPNGQMCP5|Buciluǎ, Cristian\nPNGQMCP5|Caruana, Rich\nPNGQMCP5|Niculescu-Mizil, Alexandru\n결과가 좋아보인다. 그래서, 질의를 던져보자:\nSELECT author, COUNT(*)\nFROM data\nGROUP BY author\nORDER BY COUNT(*) DESC\nLIMIT 10;\n\nBengio, Yoshua|122\nBengio, Y.|111\nHinton, Geoffrey E.|78\nLeCun, Yann|56\nHinton, G. E.|45\nSalakhutdinov, Ruslan|34\nLeCun, Y.|31\nVincent, Pascal|29\nJordan, M. I.|27\nFrasconi, P.|25\n첫번째로 보이는 것은 프로그램 작업이 성과를 내고 있다는 것이다: 누가 가장 다작하는 저자인지 명령문 하나로 이제는 알아낼 수 있다. 두번째로 보이는 것이 아직 작업을 완수한 것은 아니라는 것이다: “Bengio, Yoshua”와 “Bengio, Y.”는 거의 확실히 동일한 사람이다. 마찬가지로 “LeCun, Yann”와 “LeCun, Y.”도 동일인이다. 정말로 누가 가장 많은 논문을 썼는지 알아내려고 한다면, 동일인에 대한 다른 이름을 맞출 필요가 있다.\n저자명을 정규화하는 대신에, 대답할 수 있는 다른 질문을 살펴보자. 누가 누구와 공동으로 논문을 썼을까?\nSELECT a.author, b.author\nFROM data a\nJOIN data b ON a.key = b.key AND a.author &gt; b.author\nLIMIT 10;\n\n\nMcNaughton, B. L.|McClelland, J. L.\nO'Reilly, R. C.|McClelland, J. L.\nO'Reilly, R. C.|McNaughton, B. L.\nMcCloskey, M.|Cohen, N. J.\nCaruana, Rich|Buciluǎ, Cristian\nNiculescu-Mizil, Alexandru|Buciluǎ, Cristian\nNiculescu-Mizil, Alexandru|Caruana, Rich\nRigamonti, Roberto|Fua, Pascal\nRigamonti, Roberto|Lepetit, Vincent\nSironi, Amos|Fua, Pascal\n(a.author &gt; b.author 을 사용하게 되면, 완전히 다른 저자명 짝이 한번만 나오게 한다.) 다른 저자 짝이 얼마나 자주 함께 논문을 작성했는지 알고자 한다면 어떨까?\nselect a.author, b.author, count(*)\nfrom data a join data b\non a.key=b.key and a.author &gt; b.author\ngroup by a.author, b.author\norder by count(*) desc\nlimit 10;\n\nVincent, Pascal|Bengio, Yoshua|27\nRoux, Nicolas Le|Bengio, Yoshua|20\nDelalleau, Olivier|Bengio, Yoshua|19\nBengio, Y.|Bengio, S.|18\nLarochelle, Hugo|Bengio, Yoshua|15\nRoux, Nicolas Le|Delalleau, Olivier|15\nVincent, P.|Bengio, Y.|15\nChapados, N.|Bengio, Y.|14\nGori, M.|Frasconi, P.|14\nSalakhutdinov, Ruslan|Hinton, Geoffrey E.|14",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>엑셀에서 데이터베이스로</span>"
    ]
  },
  {
    "objectID": "spreadsheet.html#다른-접근방법",
    "href": "spreadsheet.html#다른-접근방법",
    "title": "14  엑셀에서 데이터베이스로",
    "section": "14.7 다른 접근방법",
    "text": "14.7 다른 접근방법\n\n14.7.1 R 프로그래밍\n난이도가 있는 복잡한 데이터의 경우 ETL 과정을 통해 데이터베이스에 넣고 SQL 쿼리를 사용하여 원하는 정보를 추출하는 것도 가능하지만 R 프로그래밍을 사용하여 동일한 작업을 수행하는 것도 가능하다. tidyverse 라이브러리를 사용하여 bibliography.csv 데이터를 읽고 처리하는 방식은 다음과 같다. 먼저, read_csv 함수로 파일을 불러오고, janitor::clean_names()로 칼럼명을 정리한 후, select와 set_names로 원하는 칼럼을 선택하고 칼럼명을 지정한다. 그런 다음 mutate와 str_split로 저자 이름을 분할하고, unnest로 이를 펼친 후, count로 각 key와 author 조합의 빈도를 계산하고 필요없는 열을 제거한다. 이후 inner_join을 사용하여 같은 데이터 프레임을 자기 자신과 조인하고, filter로 특정 조건을 만족하는 행을 필터링한다. group_by와 summarise로 그룹별로 집계하고, ungroup, arrange, top_n을 통해 결과를 정렬하고 상위 10개의 결과를 추출한다. 작성된 코드를 통해 저자들 간의 공동 작업 빈도를 분석하여 가장 자주 협업한 저자 쌍을 찾을 수 있다.\n\nlibrary(tidyverse)\n\nbiblio &lt;-  read_csv(\"data/bibliography.csv\", col_names = FALSE )\n\nbiblio_tbl &lt;- biblio |&gt; \n  janitor::clean_names() |&gt; \n  select(x1:x5) |&gt; \n  set_names(c(\"key\", \"jounral\", \"year\", \"author\", \"affiliation\"))\n\nkey_author &lt;- biblio_tbl |&gt; \n  mutate(author = str_split(author, \"; \")) |&gt; \n  unnest(author) |&gt; \n  count(key, author) |&gt; \n  select(-n)\n\nkey_author %&gt;%\n  inner_join(key_author, by = \"key\", suffix = c(\".a\", \".b\")) %&gt;%\n  filter(author.a &gt; author.b) %&gt;%\n  group_by(author.a, author.b) %&gt;%\n  summarise(count = n()) %&gt;%\n  ungroup() %&gt;%\n  arrange(desc(count)) %&gt;%\n  top_n(10, count)\n\n# A tibble: 10 × 3\n   author.a              author.b            count\n   &lt;chr&gt;                 &lt;chr&gt;               &lt;int&gt;\n 1 Vincent, Pascal       Bengio, Yoshua         27\n 2 Roux, Nicolas Le      Bengio, Yoshua         20\n 3 Delalleau, Olivier    Bengio, Yoshua         19\n 4 Bengio, Y.            Bengio, S.             18\n 5 Larochelle, Hugo      Bengio, Yoshua         15\n 6 Roux, Nicolas Le      Delalleau, Olivier     15\n 7 Vincent, P.           Bengio, Y.             15\n 8 Chapados, N.          Bengio, Y.             14\n 9 Gori, M.              Frasconi, P.           14\n10 Salakhutdinov, Ruslan Hinton, Geoffrey E.    14\n\n\n14.7.2 쉘 프로그래밍\n쉘 기반 파이썬 프로그래밍으로 SQL 데이터베이스를 제작하는 방식은 명령줄 인터페이스(CLI)를 통해 파이썬 스크립트를 실행하여 데이터베이스와 테이블을 생성하고 데이터를 조작하는 것이다. 파이썬 sqlite3 라이브러리를 사용하여 데이터베이스 파일을 생성하고 연결을 설정한다. 연결 객체를 사용하여 커서 객체를 생성하고, SQL 명령어를 커서를 통해 실행하여 데이터베이스 테이블을 생성하고 데이터를 삽입한다. 예를 들어, CREATE TABLE SQL 명령어로 테이블을 생성하고, INSERT INTO 명령어로 데이터를 삽입한다. 모든 작업이 끝나면 데이터베이스 연결을 커밋하고 닫아서 변경사항을 저장한다. 이러한 방식을 통해 쉘 환경에서 파이썬 스크립트를 실행하여 데이터베이스를 제어하고 데이터를 처리함으로써, 데이터베이스 작업을 자동화하고 프로그래밍적으로 접근할 수 있는 장점을 제공한다.\nCSV 파일에서 행을 데이터베이스 레코드로 SQL INSERT 문장 통해 삽입한다. 먼저, SQL INSERT 코드를 다음과 같이 작성한다.\nINSERT INTO data VALUES ('8SW85SQM', 'McClelland, James L');\nINSERT INTO data VALUES ('85QV9X5F', 'McClelland, J. L.');\nINSERT INTO data VALUES ('85QV9X5F', 'McNaughton, B. L.');\n그래서, 대신에 상기 데이터를 출력하도록 프로그램을 변경하자:\n```{python}\n# convert-1.py\n# 데이터베이스에 (키값, 저자명) 짝을 집어넣는 SQL 문장을 생성한다.\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nINSERT = \"INSERT INTO data VALUES('{0}', '{1}');\"\n\nraw = open(sys.argv[1], 'r', encoding='utf-8')\n\nreader = csv.reader(raw);\n\nfor line in reader:\n  key, authors = line[0], line[3]\n  for auth in authors.split('; '): # 세미콜론 대신에, 세미콜론과 공백 사용\n    print(INSERT.format(key, auth))\n        \nraw.close()\n```\n첫번째 변경사항이 INSERT 정의로, 삽입 문장에 대한 형식 문자열(format string)이 된다. 두번째 변경사항은 키값과 저자명을 직접적으로 출력하는 대신에, 데이터 값을 str.format 을 사용하는 INSERT 안으로 삽입하는 것이다.\n잘 동작한다, 하지만 “동작한다”라는 말은 단지 “분명한 오류없이 작업완료가 되도록 동작한다”라는 의미다. 더 가까이 검사하면, 문제가 두가지가 보인다:\n\n실제로 어떤 누구도 데이터를 삽입하는데 데이터베이스를 생성해주지는 않는다.\n저자명에 단일 인용부호를 포함할 수 있다.\n\n첫번째 문제는 풀기 쉽다. 프로그램 시작부분에 다음 코드를 추가한다.\nCREATE = 'CREATE TABLE data(key text not null, author text not null);'\n어떤 insert 문장을 출력하기 전에 출력한다. 두번째 문제는 더 까다롭다: 만약 “O’Mear, Fiona” 같은 저자명을 INSERT해서 끼워넣으려면, 결과가 다음과 같이 된다:\n\"INSERT INTO data VALUES('RJS8QDC4', 'O'Mear, Fiona');\"\n상기 방식은 적법한 파이썬 방법이 아니다. 문제 해결방식은 단일 인용부호 대신에 문자열 주위를 이중 인용부호를 사용하는 것이다. 왜냐하면 사람 이름에 이중 인용부호는 포함될 수 없기 때문이다. 변경사항을 마치고 나면, 전체 프로그램은 다음과 같다:\n```{python}\n# convert-2.py\n# 키값과 저자명에 대한 데이터베이스 생성.\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nCREATE = 'CREATE TABLE data(key text not null, author text not null);'\nINSERT = 'INSERT INTO data VALUES(\"{0}\", \"{1}\");'\n\nprint(CREATE)\n\nraw = open(sys.argv[1], 'r')\nreader = csv.reader(raw);\nfor line in reader:\n    key, authors = line[0], line[3]\n    for auth in authors.split('; '): # 세미콜론 대신에, 세미콜론과 공백 사용\n        print INSERT.format(key, auth)\nraw.close()\n```\n프로그램을 실행해보자:\n$ python code/convert-2.py data/bibliography.csv | head -5\nCREATE TABLE data(key text not null, author text not null);\nINSERT INTO data VALUES(\"8SW85SQM\", \"McClelland, James L\");\nINSERT INTO data VALUES(\"85QV9X5F\", \"McClelland, J. L.\");\nINSERT INTO data VALUES(\"85QV9X5F\", \"McNaughton, B. L.\");\nINSERT INTO data VALUES(\"85QV9X5F\", \"O'Reilly, R. C.\");\n결과가 상당히 좋아 보인다. 그래서, 실제 데이터베이스를 생성하는데 이것을 사용하기로 한다:\n$ python code/convert-2.py data/bibliography.csv | sqlite3 bibliography.db\n상기 파이프라인 작업은 저자 컴퓨터에서 실행하는데 약 4초 걸렸고, 205 킬로바이트 bibliography.db 파일을 생성했다. 데이터베이스가 담고 있는 것을 살펴보자:\n$ sqlite3 bibliography.db\nSQLite version 3.8.5 2014-08-15 22:37:57\nEnter \".help\" for usage hints.\n\nsqlite&gt; .schema\nCREATE TABLE data(key text not null, author text not null);\n\nsqlite&gt; SELECT * FROM data LIMIT 10;\n8SW85SQM|McClelland, James L\n85QV9X5F|McClelland, J. L.\n85QV9X5F|McNaughton, B. L.\n85QV9X5F|O'Reilly, R. C.\nZ4X6DT6N|Ratcliff, R.\nF5DGU3Q4|McCloskey, M.\nF5DGU3Q4|Cohen, N. J.\nPNGQMCP5|Buciluǎ, Cristian\nPNGQMCP5|Caruana, Rich\nPNGQMCP5|Niculescu-Mizil, Alexandru\n결과가 좋아보인다. 그래서, 질의를 던져보자:\nSELECT author, COUNT(*)\nFROM data\nGROUP BY author\nORDER BY COUNT(*) DESC\nLIMIT 10;\n\nBengio, Yoshua|122\nBengio, Y.|111\nHinton, Geoffrey E.|78\nLeCun, Yann|56\nHinton, G. E.|45\nSalakhutdinov, Ruslan|34\nLeCun, Y.|31\nVincent, Pascal|29\nJordan, M. I.|27\nFrasconi, P.|25\n첫번째로 보이는 것은 프로그램 작업이 성과를 내고 있다는 것이다: 누가 가장 다작하는 저자인지 명령문 하나로 이제는 알아낼 수 있다. 두번째로 보이는 것이 아직 작업을 완수한 것은 아니라는 것이다: “Bengio, Yoshua”와 “Bengio, Y.”는 거의 확실히 동일한 사람이다. 마찬가지로 “LeCun, Yann”와 “LeCun, Y.”도 동일인이다. 정말로 누가 가장 많은 논문을 썼는지 알아내려고 한다면, 동일인에 대한 다른 이름을 맞출 필요가 있다.\n저자명을 정규화하는 대신에, 대답할 수 있는 다른 질문을 살펴보자. 누가 누구와 공동으로 논문을 썼을까?\nSELECT a.author, b.author\nFROM data a\nJOIN data b ON a.key = b.key AND a.author &gt; b.author\nLIMIT 10;\n\n\nMcNaughton, B. L.|McClelland, J. L.\nO'Reilly, R. C.|McClelland, J. L.\nO'Reilly, R. C.|McNaughton, B. L.\nMcCloskey, M.|Cohen, N. J.\nCaruana, Rich|Buciluǎ, Cristian\nNiculescu-Mizil, Alexandru|Buciluǎ, Cristian\nNiculescu-Mizil, Alexandru|Caruana, Rich\nRigamonti, Roberto|Fua, Pascal\nRigamonti, Roberto|Lepetit, Vincent\nSironi, Amos|Fua, Pascal\n(a.author &gt; b.author 을 사용하게 되면, 완전히 다른 저자명 짝이 한번만 나오게 한다.) 다른 저자 짝이 얼마나 자주 함께 논문을 작성했는지 알고자 한다면 어떨까?\nselect a.author, b.author, count(*)\nfrom data a join data b\non a.key=b.key and a.author &gt; b.author\ngroup by a.author, b.author\norder by count(*) desc\nlimit 10;\n\nVincent, Pascal|Bengio, Yoshua|27\nRoux, Nicolas Le|Bengio, Yoshua|20\nDelalleau, Olivier|Bengio, Yoshua|19\nBengio, Y.|Bengio, S.|18\nLarochelle, Hugo|Bengio, Yoshua|15\nRoux, Nicolas Le|Delalleau, Olivier|15\nVincent, P.|Bengio, Y.|15\nChapados, N.|Bengio, Y.|14\nGori, M.|Frasconi, P.|14\nSalakhutdinov, Ruslan|Hinton, Geoffrey E.|14",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>엑셀에서 데이터베이스로</span>"
    ]
  },
  {
    "objectID": "etl.html#데이터베이스-도입",
    "href": "etl.html#데이터베이스-도입",
    "title": "14  ETL 데이터베이스",
    "section": "14.1 데이터베이스 도입",
    "text": "14.1 데이터베이스 도입\n데이터 복잡성이 일반적으로 처리할 수 있는 것을 넘어서면 “추출(Extract), 변환(Transform), 로드(Load)”라고 하는 과정을 수행해야 한다. 예를 들어 서지학 데이터에서 다음과 같은 질문에 답을 하고자 한다고 가정해 보자.\n\n각 사람이 기여한 논문의 수는 얼마인가?\n누가 누구와 협업하는가?\n\n불행히도, “다중 값 필드(multi-valued field)”가 있는 필드 때문에 바로 스프레드시트/CSV 형식 서지학 데이터를 데이터베이스에 넣을 수 없다.\n저자 한명에만 관심이 있다면, 첫번째 질문에 답하기 위해 스프레드시트에서 저자명을 검색한 다음, 그 행을 선택하고 수동으로 그녀의 공동 저자를 집계하여 두 번째 질문에 답할 수 있다. 그러나 모든 저자에 대해서 동일한 작업을 한땀한땀 수행하는 데는 며칠이 걸릴 것이며, 거의 확실하게 실수(휴먼 에러)가 있을 것이며, 그러면 누군가가 또 다른 더 큰 스프레드시트를 건네주고 처음부터 다시 시작해야 할 것이다. 하지만, 모든 저자에 대해 하나씩 이런 작업을 수행하는 것은 몇일이 소요된다. 거의 확실히 실수도 할 것이다.\n두가지 질문에 답하기 위해 많은 작업처럼 보일 수 있지만, 수십줄 이상되는 데이터에 대해서는 많은 시간을 절약할 수 있다.\n\n데이터가 데이터베이스에 존재한다면 다른 질문들도 묻고 답하기 쉬워진다.\n향후 또다른 형태 스프레드시트에 개발한 도구를 재사용할 수 있다.\n지금까지 수행한 일에 대한 기록을 가질 수 있다(스프레드시트에서 클릭하는 것으로는 얻을 수 없는 것).\n정확할 가능성이 훨씬 더 높고 빠르다.\n\n이 접근 방식을 통해 데이터를 보다 체계적이고 효율적으로 관리할 수 있으며, 데이터 분석을 위한 기반을 마련할 수 있다. 데이터베이스에 데이터를 저장함으로써, 데이터의 일관성을 유지하고, 복잡한 쿼리를 쉽게 실행할 수 있으며, 나중에 데이터를 검토하거나 업데이트할 때 시간과 노력을 절약할 수 있다. 전체적인 작업흐름은 다음과 같다.\n\n모든 논문에 모든 기여자에 대한 (키값, 저자명) 짝을 출력하는 작은 파이썬 프로그램을 작성한다. 예를 들어, 작성한 프로그램이 스프레드쉬트 첫 세줄을 다음과 같이 변환한다:\n\n8SW85SQM McClelland, James L\n85QV9X5F McClelland, J. L.\n85QV9X5F McNaughton, B. L.\n85QV9X5F O'Reilly, R. C.\nZ4X6DT6N Ratcliff, R.\n\n프로그램을 변경해서 데이터베이스에 키값과 저자를 삽입하는 SQL insert 문장을 생성한다.\nSQL 쿼리를 사용해서 최초 질문에 답한다.\n\n\n\n\n\n\n\n바흐라이(Bahlai) 법칙\n\n\n\n“다른 사람의 데이터는 항상 일관성이 없고 잘못된 형식으로 되어 있다. (”Other people’s data is always inconsistent and in the wrong format.”)",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>ETL 데이터베이스</span>"
    ]
  },
  {
    "objectID": "etl.html#데이터셋",
    "href": "etl.html#데이터셋",
    "title": "14  ETL 데이터베이스",
    "section": "14.2 데이터셋",
    "text": "14.2 데이터셋\n다음 간단한 예제를 통해서 데이터(스프레드쉬트에 내장된 참고문헌정보)를 어떻게 받아서 유용한 것으로 변경할지 살펴보자. 출발점은 다음과 같은 2,937행을 갖는 bibliography.csv 라는 스프레드쉬트(엑셀) 파일이다.\n\n\n\n\n\n\n\n\n\n\n\nkey\ntype\nyear\nauthors\ntitle\njournal\n\n\n\n\n8SW85SQM\njournalArticle\n2013\nMcClelland, James L\nIncorporating Rapid Neocortical Learning of New Schema-Consistent Information Into Complementary Learning Systems Theory.\nJ Exp Psychol Gen\n\n\n85QV9X5F\njournalArticle\n1995\nMcClelland, J. L.; McNaughton, B. L.; O’Reilly, R. C.\nWhy There are Complementary Learning Systems in the Hippocampus and Neocortex: Insights from the Successes and Failures of Connectionist Models of Learning and Memory\nPsychological Review\n\n\nZ4X6DT6N\njournalArticle\n1990\nRatcliff, R.\nConnectionist models of recognition memory: constraints imposed by learning and forgetting functions.\nPsychological review\n\n\n\n본격적인 개발에 들어가기 전에 프로그램을 개발하는 것이 시간을 얼마나 절약할 수 있고 정확도를 높이는지 살펴보자.\n\n14.2.1 확률이 얼마나 될까?\n스프레드쉬트는 2,937행을 담고 있다. 전체 분석작업의 99%를 틀리지 않게 하는데, 손으로하는 전사작업은 얼마나 정확성이 있을까? 즉, 행당 오류율이 얼마나 되어야 전체 작업을 올바르게 완수하는데 0.99 확률이 될까?\n\n\n# 전체 행의 수\ntotal_rows &lt;- 2937\n\n# 전체 작업의 99%가 정확해야 함\ndesired_accuracy &lt;- 0.99\n\n# 행당 오류율을 찾기\n# 정확도 = (1 - 오류율) ^ 전체 행의 수\n# 따라서 오류율 = 1 - (정확도의 1/전체 행의 수제곱)\nrow_error_rate &lt;- 1 - (desired_accuracy ^ (1/total_rows))\nscales::percent(row_error_rate, accuracy = 0.000001)\n#&gt; [1] \"0.000342%\"\n\n\"0.000342%\"\n\n\n14.2.2 손익분기점\n수작업으로 5분만 소요되는 작업을 (전산화해서) 10분 걸려 프로그램 작성한다면, 해당 작업을 두번 이상 수행한다면, 프로그램으로 작성할 가치가 있다. 유사하게, 특정한 저자와 공저자가 누구인지만 알아내려고 하고, 다른 질문은 전혀 없을 것이거나, 반복작업을 할 필요가 없다면, 수작업으로 스프레드쉬트를 검색하는 것이 데이터를 데이터베이스로 옮기는 프로그램을 작성하는 것보다 아마도 더 빠를 것이다.\n현재 수작업으로 하고 있는 작업을 선택하라. 매번 얼마의 시간이 소요되고, 얼마나 자주 수행하는지 추정하고, 대신에 작업을 프로그램으로 만드는데 얼마나 소요되는지 추정하라. 프로그래밍이 실질적으로 얼마나 시간을 절약해줄까? 얼마나 확신이 되나요?\n\n이 문제를 해결하기 위해, 현재 수작업으로 진행 중인 작업을 선정하고, 그 작업에 대한 다음 정보들을 추정해야 한다.\n\n작업에 소요되는 시간: 각 작업 수행에 걸리는 평균 시간을 추정한다.\n작업의 빈도: 이 작업이 얼마나 자주 수행되는지 추정한다. 예를 들어, 일주일에 몇 번 또는 한 달에 몇번 등이 된다.\n프로그램 작성에 소요되는 시간: 동일한 작업을 자동화하는 프로그램을 작성하는 데 필요한 시간을 추정한다.\n\n상기 정보를 바탕으로 프로그래밍이 실질적으로 시간을 절약해주는지를 평가할 수 있다. 시간 절약의 계산은 다음과 같은 간단한 공식으로 이루어집니다:\n\n총 절약시간 = (수작업 시간 * 작업 빈도 * 기간) - 프로그램 작성 시간\n\n여기서, “기간”은 프로그램이 사용될 예상 기간이 된다.\n예를 들어, 매주 2시간 걸리는 작업이 있고, 이를 자동화하는 프로그램을 작성하는 데 10시간이 걸린다고 가정해 보자. 프로그램이 1년 동안 사용될 것이라고 가정하면, 총 절약 시간은 다음과 같습니다:\n\n총 절약시간 = (2시간/주 * 52주) - 10시간 = 94시간\n\n프로그램 작성에 들인 시간을 고려하더라도 연간 94시간을 절약할 수 있음을 의미한다.\n유념할 점은 이러한 추정은 작업의 복잡성, 작업 빈도 및 프로그래밍 능력에 따라 달라질 수 있으므로, 여러가지 요소들을 고려하여 신중하게 추정해야 한다.\n\n\n\n\n\n\n데이터 모델링\n\n\n\n관계형 데이터베이스의 진정한 힘은 다중 테이블과 테이블 사이의 관계를 생성할 때 생긴다. 응용프로그램 데이터를 쪼개서 다중 테이블과 두 테이블 간에 관계를 설정하는 것을 데이터 모델링(data modeling)이라고 한다. 테이블 정보와 테이블 관계를 표현하는 설계 문서를 데이터 모델(data model)이라고 한다.\n데이터 모델링(data modeling)은 상대적으로 고급 기술이여서 이번 장에서는 관계형 데이터 모델링의 가장 기본적인 개념만을 소개한다. 데이터 모델링에 대한 좀더 자세한 사항은 다음 링크에서 시작해 볼 수 있다.\n문자열 데이터 중복은 데이터베이스 정규화(database normalization) 모범 사례(best practice)를 위반하게 만든다. 기본적으로 데이터베이스 정규화는 데이터베이스에 결코 한번 이상 동일한 문자열을 저장하지 않는다. 만약 한번 이상 데이터가 필요하다면, 그 특정 데이터에 대한 숫자 키(key)를 생성하고, 그 키를 사용하여 실제 데이터를 참조한다.\n실무에서, 문자열이 컴퓨터 주기억장치나 디스크에 저장되는 정수형 자료보다 훨씬 많은 공간을 차지하고 더 많은 처리시간이 비교나 정렬에 소요된다. 항목이 단지 수백개라면, 저장소나 처리 시간이 그다지 문제되지 않는다. 하지만, 데이터베이스에 수백만명의 사람 정보와 1억건 이상의 링크가 있다면, 가능한 빨리 데이터를 스캔하는 것이 정말 중요하다.",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>ETL 데이터베이스</span>"
    ]
  },
  {
    "objectID": "etl.html#자료-추출",
    "href": "etl.html#자료-추출",
    "title": "14  ETL 데이터베이스",
    "section": "14.3 자료 추출",
    "text": "14.3 자료 추출\n첫번째 단계는 스프레드쉬트 행을 (키값, 저자명) 짝으로 추출(extract)하는 것이다. 파이썬이 올바르게 스프레드쉬트를 읽어들이는지 확인하는 것부터 시작된다. 윈도우에서 파이썬으로 CSV 파일을 읽어드리게 되면 인코딩 오류가 발생하는 경우가 있다. 이를 방지하기 위해 인코딩을 UTF-8으로 설정한다.\n```{python}\n# count-lines.py\n# 스프레드쉬트에 얼마나 많은 줄이 있는지 계수한다.\n\n# -*- coding: utf-8 -*-\n\nimport sys\n\nfilename = sys.argv[1]\nreader = open(filename, 'r', encoding='UTF-8')\ncount = 0\nfor line in reader:\n    count += 1\nreader.close()\n\nprint(count)\n```\n상기 코드가 이제는 칙숙해보여야 된다: 파일명이 첫번째 명령라인 인자(sys.argv[1])로 주어졌다. 따라서, 파일을 열고, for 루프를 사용해서 한줄씩 읽어들인다. 매번 루프가 실행될 때, 1을 count 변수에 더한다; 루프가 종류될 때, 파일을 닫고 계수 결과를 출력한다.\n상기 프로그램을 다음과 같이 실행한다:\n$ python code/count-lines.py data/bibliography.csv\n물론, 결과는 다음과 같다:\n2937\n그래서, 파이썬이 모든 행을 읽어들인 것을 알게된다.\n다음 단계는 각 줄을 필드로 쪼개서 각 항목에 대한 키값과 저자명을 얻게된다. 필드는 콤마로 구분된다. 그래서 str.split 사용해서 시도해볼 수 있다. 하지만, 동작하지는 않는데 이유는 저자명에도 콤마가 포함되어서 그렇다(“성, 이름”같은 형식으로 되어 있어서 그렇다).\n대신에 취할 수 있는 조치는 선호하는 검색엔진에 도움을 청한다. 물론, “python csv”에 대한 검색결과는 csv 라이브러리가 나오고, 표준 파이썬 배포판의 일부이기도 하다. 라이브러리 문서에 일부 예제가 포함되어 있다. 몇번 실험을 한 뒤에, 다음과 같은 결과가 나오게 된다:\n```{python}\n# read-fields.py\n# CSV 파일에서 필드값을 제대로 읽어 오는지 확인한다.\n\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nraw = open(sys.argv[1], 'r', encoding='utf-8')\nreader = csv.reader(raw);\n\nfor line in reader:\n    print(line)\n    \nraw.close()\n```\n작성한 프로그램은 참고문헌 파일을 열어서 시작한다(다시 한번, 첫번째 명령-라인 인자로 파일명을 넘긴다) 그리고 나서, csv.reader 메쏘드를 호출해서 파일주위에 래퍼를 생성한다. open으로 생성된 기본 파일 객체가 한번에 한줄씩 읽어올 때, csv.reader에 의해서 생성된 래퍼가 해당 라인을 올바른 지점에서 필드로 쪼갠다. csv.reader는 해당 필드에 내장된 콤마, 특수문자, 신경쓰지 않아도 되는 다른 엄청난 것에 대해 어떻게 처리하는지 알고 있다.\n올바르게 동작하는지 점검하려면, csv.reader에 의한 처리가 끝난 후에 각 줄을 출력하면 된다. 출력결과 중 첫 몇줄이 다음에 나와 있다:\n$ python code/read-fields.py data/bibliography.csv | head -5\n\n['8SW85SQM', 'journalArticle', '2013', 'McClelland, James L', 'Incorporating Rapid Neocortical Learning of New Schema-Consistent Information Into Complementary Learning Systems Theory.', 'J Exp Psychol Gen', '', '1939-2222', '', 'http://www.biomedsearch.com/nih/Incorporating-Rapid-Neocortical-Learning-New/23978185.html', '', '', '', '', '', '', '', '', '']\n['85QV9X5F', 'journalArticle', '1995', \"McClelland, J. L.; McNaughton, B. L.; O'Reilly, R. C.\", 'Why There are Complementary Learning Systems in the Hippocampus and Neocortex: Insights from the Successes and Failures of Connectionist Models of Learning and Memory', 'Psychological Review', '', '', '', '', '', '', '', '', '', '', '', '', '']\n['Z4X6DT6N', 'journalArticle', '1990', 'Ratcliff, R.', 'Connectionist models of recognition memory: constraints imposed by learning and forgetting functions.', 'Psychological review', '', '0033-295X', '', 'http://view.ncbi.nlm.nih.gov/pubmed/2186426', '', '', '', '', '', '', '', '', '']\n['F5DGU3Q4', 'bookSection', '1989', 'McCloskey, M.; Cohen, N. J.', 'Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem', 'The Psychology of Learning and Motivation, Vol. 24', '', '', '', '', '', '', '', '', '', '', '', '', '']\n['PNGQMCP5', 'conferencePaper', '2006', 'Bucilu\\xc7\\x8e, Cristian; Caruana, Rich; Niculescu-Mizil, Alexandru', 'Model compression', 'Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining', '', '', '', '', '', '', '', '', '', '', '', '', '']\n(프로그램 출력결과를 head 명령어로 실행해서 출력결과를 스크롤해서 다시 위로 올라가기 보다 첫 몇줄만 화면에 출력함에 주목한다.) 상기 결과는 정확하게 필요한 결과다: 키값이 각 리스트 첫번째 구성요소로 있고, 저자는 모두 네번째에 몰려있따. 프로그램을 변경해서, 단지 두 필드만 출력하게 변경하자:\n```{python}\n# display-fields.py\n# 키값과 저자 모두를 화면에 출력한다.\n\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nraw = open(sys.argv[1], 'r', encoding='utf-8')\nreader = csv.reader(raw);\n\nfor line in reader:\n    print (line[0], line[3])\n\nraw.close()\n    \n```\n출력결과는 다음과 같다:\n8SW85SQM McClelland, James L\n85QV9X5F McClelland, J. L.; McNaughton, B. L.; O'Reilly, R. C.\nZ4X6DT6N Ratcliff, R.\nF5DGU3Q4 McCloskey, M.; Cohen, N. J.\nPNGQMCP5 Buciluǎ, Cristian; Caruana, Rich; Niculescu-Mizil, Alexandru\n마지막 단계는 저자 다수를 갖는 행을 복수개 행으로 단일저자가 한줄에 나타나도록 변경한다. 이번이 str.split 메쏘드를 사용할 때다: 저자명이 세미콜론으로 구분되어 있어서, 저자 목록을 각 저자별로 나눌 수 있다. 또다른 루프를 사용해서 하나씩 결과를 화면에 출력한다:\n$ python code/display-authors-1.py data/bibliography.csv | head -10\n\n8SW85SQM McClelland, James L\n85QV9X5F McClelland, J. L.\n85QV9X5F McNaughton, B. L.\n85QV9X5F O'Reilly, R. C.\nZ4X6DT6N Ratcliff, R.\nF5DGU3Q4 McCloskey, M.\nF5DGU3Q4 Cohen, N. J.\nPNGQMCP5 Buciluǎ, Cristian\nPNGQMCP5 Caruana, Rich\nPNGQMCP5 Niculescu-Mizil, Alexandru\n이제 원하는 바에 가까워졌다. 하지만, 꼭 그렇지는 않다; 저자명은 실제로 세미콜론과 공백으로 구분되는데 세미콜론만으로 구분했기 때문에, 각 줄마다 두번째와 이어진 명칭에 원치않는 공백이 앞에 온다. 세미콜론과 공백으로 쪼개면 어떻게 될까?\n```{python}\n# display-authors-2.py\n# (키값, 저자명) 짝을 화면에 출력한다.\n\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nraw = open(sys.argv[1], 'r', encoding='utf-8')\nreader = csv.reader(raw);\n\ntry:\n    for line in reader:\n      key, authors = line[0], line[3]\n      for auth in authors.split('; '): # 세미콜론 대신에, 세미콜론과 공백 사용\n          print (key, auth)\nexcept BrokenPipeError:\n  sys.stderr.close()\n          \nraw.close()\n```\n8SW85SQM McClelland, James L\n85QV9X5F McClelland, J. L.\n85QV9X5F McNaughton, B. L.\n85QV9X5F O'Reilly, R. C.\nZ4X6DT6N Ratcliff, R.\nF5DGU3Q4 McCloskey, M.\nF5DGU3Q4 Cohen, N. J.\nPNGQMCP5 Buciluǎ, Cristian\nPNGQMCP5 Caruana, Rich\nPNGQMCP5 Niculescu-Mizil, Alexandru\n\n14.3.1 버전 관리\n이로써 데이터 추출의 첫 번째 단계가 완료되어, 재사용 가능한 유용한 코드를 얻었기 때문에, 후속 작업을 위해서 저장한다. 깃(Git) 버전 제어는 데이터 처리 및 분석의 복잡성과 변화에 대응하는 데 있어 핵심적인 역할을 한다. ETL 과정은 데이터의 추출, 변환 및 로드 과정에서 수많은 쿼리와 스크립트를 포함하며, 이러한 작업들은 지속적으로 수정 및 개선이 필요하다. Git을 사용하면 이러한 변경사항을 효과적으로 추적하고 관리할 수 있다. 오류 발생시 이전 버전으로 쉽게 되돌릴 수 있게 해주며, 팀원 간의 협업에서도 변경 사항을 쉽게 공유하고 통합할 수 있게 한다. 또한, Git은 작업의 히스토리를 기록하여 프로젝트의 진행 상황을 명확하게 파악할 수 있도록 해주어 프로젝트 관리에도 큰 도움이 된다.\ngit init . 명령어를 사용하여 현재 디렉토리에서 새로운 Git 저장소를 초기화하는데 .git 폴더를 생성하여 Git 관련 데이터를 저장할 수 있는 토대를 만든다. 다음 단계로 git add -A 명령어는 작업 디렉토리의 모든 변경사항(새로운 파일, 수정된 파일 등)을 Git 스테이징 영역에 추가하여 커밋할 파일을 준비한다. git status 명령어는 현재 Git 저장소의 상태를 보여주는데 스테이징 영역에 추가된 변경사항, 커밋되지 않은 변경사항 등이 포함된 것이 확인된다. git commit -m \"메시지\" 명령어는 스테이징 영역에 추가된 변경사항을 저장소의 이력에 기록한다. -m 옵션 뒤에는 커밋에 대한 설명을 추가한다. 예시로 “Extracting (key, author) pairs from bibliography”라는 메시지와 함께 커밋이 이루어졌으며, 6개의 파일이 변경되었고 2996개의 추가되었다.\n$ git init .\n\nInitialized empty Git repository in /Users/aturing/lessons/capstone-novice-spreadsheet-biblio/.git\n\n$ git add -A\n$ git status\n\nOn branch master\n\nInitial commit\n\nChanges to be committed:\n  (use \"git rm --cached &lt;file&gt;...\" to unstage)\n\n  new file:   code/count-lines.py\n  new file:   code/display-authors-1.py\n  new file:   code/display-authors-2.py\n  new file:   code/display-fields.py\n  new file:   code/read-fields.py\n  new file:   data/bibliography.csv\n\n$ git commit -m \"Extracting (key, author) pairs from bibliography\"\n\n[master (root-commit) 9db78ed] Extracting (key, author) pairsfrom bibliography\n 6 files changed, 2996 insertions(+)\n create mode 100644 code/count-lines.py\n create mode 100644 code/display-authors-1.py\n create mode 100644 code/display-authors-2.py\n create mode 100644 code/display-fields.py\n create mode 100644 code/read-fields.py\n create mode 100644 data/bibliography.csv",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>ETL 데이터베이스</span>"
    ]
  },
  {
    "objectID": "etl.html#자료-변환",
    "href": "etl.html#자료-변환",
    "title": "14  ETL 데이터베이스",
    "section": "14.4 자료 변환",
    "text": "14.4 자료 변환\n정규화(normalization)는 데이터를 여러 테이블로 분할하는 과정으로 전체 데이터셋을 여러 테이블로 분할하는 것으로 이해하면 된다. 다만, 기억해야 할 몇 가지 규칙이 있다.\n\n다중 값 속성은 사용하지 않는다!\n모든 행은 그 행을 고유하게 식별하는 “키”를 가져야 한다.\n모든 속성은 오직 키와만 관련되어야 한다.\n\n시간이 있다면 서지학 데이터에 대한 정규화 방법을 면밀히 검토할 수 있지만 빠르고 간단한 해결책에 집중해보자.\n앞선 데이터 추출 작업으로 짝(키값, 저자명) 데이터를 갖게 되었다. 다음 단계는 관계형 데이터베이스에 데이터를 삽입하는 것이다. 데이터가 데이터베이스에 입력되면, 쿼리를 전송해서 질의 응답을 할 수 있다. 시작점으로 이전 학습과정에서 나온 최종 스크립트를 바탕으로 시작해보자.\n```{python}\n# display-authors-2.py\n# (키값, 저자명) 짝을 화면에 출력한다.\n\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nraw = open(sys.argv[1], 'r', encoding='utf-8')\nreader = csv.reader(raw);\n\ntry:\n    for line in reader:\n      key, authors = line[0], line[3]\n      for auth in authors.split('; '): # 세미콜론 대신에, 세미콜론과 공백 사용\n          print (key, auth)\nexcept BrokenPipeError:\n  sys.stderr.close()\n          \nraw.close()\n```\n상기 프로그램 실행결과는 다음과 같다:\n8SW85SQM McClelland, James L\n85QV9X5F McClelland, J. L.\n85QV9X5F McNaughton, B. L.\n85QV9X5F O'Reilly, R. C.\nZ4X6DT6N Ratcliff, R.\nF5DGU3Q4 McCloskey, M.\nF5DGU3Q4 Cohen, N. J.\nPNGQMCP5 Buciluǎ, Cristian\nPNGQMCP5 Caruana, Rich\nPNGQMCP5 Niculescu-Mizil, Alexandru\n데이터베이스에 넣을 수 있는 CSV 파일을 생성해보자.\n```{python}\n# convert-1.py\n# 데이터베이스에 로드할 수 있는 CSV로 출력결과 전송\n\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\noutput_rows=[]\n\nwith open(sys.argv[1], 'r') as raw:\n    reader = csv.reader(raw);\n    for line in reader:\n        key, authors = line[0], line[3]\n        for auth in authors.split('; '): # 세미콜론 대신에, 세미콜론과 공백 사용\n            output_rows.append([key, auth])\n\n# 출력 파일에 대해 두 번째 인수가 필요\nwith open(sys.argv[2], 'w') as csvout:\n    writer = csv.writer(csvout) # 두 번째 인수로 csv 파일 생성\n    writer.writerow([\"Key\", \"Author\"]) # 칼럼명 헤더 생성\n    writer.writerows(output_rows) # output_rows를 파일에 쓰기\n\nprint(len(output_rows)) # rows output_rows 행수를 알아야 데이터베이스에 확실하게 적재되었는지 확인 가능.\n```\n상기 프로그램을 실행하면, 다음과 같은 결과를 얻게 된다. 6,587개 키-저자 쌍이 존재함을 확인하고 데이터베이스에 적재할 준비가 되었다.\n$ python code/convert-db-1.py data/bibliography.csv data/key_author.csv\n6587\n$ head key_author.csv\nKey,Author\n8SW85SQM,\"McClelland, James L\"\n85QV9X5F,\"McClelland, J. L.\"\n85QV9X5F,\"McNaughton, B. L.\"\n85QV9X5F,\"O'Reilly, R. C.\"\nZ4X6DT6N,\"Ratcliff, R.\"\nF5DGU3Q4,\"McCloskey, M.\"\nF5DGU3Q4,\"Cohen, N. J.\"\nPNGQMCP5,\"Buciluǎ, Cristian\"\nPNGQMCP5,\"Caruana, Rich\"\n\n\n\n\n\n\n절차 생략(Cutting Corners)\n\n\n\n파이썬과 다른 언어들은 데이터베이스와 상호작용하기 위한 라이브러리를 가지고 있음에도 불구하고, 왜 이렇게 대량으로 데이터를 로드하는 방식을 사용하는 것일까? 그런데, 왜 INSERT 문장을 SQLite 안으로 흘려보내지 않는가? 대답은 지금까지 소개한 모든 도구를 사용하는 단순한 해답이 있기 때문이다. 만약 데이터로 좀더 복잡한 어떤 것을 해야한다면, 거의 확실히 import sqlite3 사용해서 작업을 수행하게 된다.",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>ETL 데이터베이스</span>"
    ]
  },
  {
    "objectID": "etl.html#적재-load",
    "href": "etl.html#적재-load",
    "title": "14  ETL 데이터베이스",
    "section": "14.5 적재 (Load)",
    "text": "14.5 적재 (Load)\n이제 데이터를 적재하기 위해 스크립트를 만들어 load_bibliography.sql 파일을 호출한다. key_author.csv 파일이 현재 작업디렉토리 아래 data 폴더 아래 저장되어 있기 대문에 다음과 같이 SQL 코드를 작성한다.\n```{sql}\n# load_bibliography.sql\n.mode csv\n.import key_author.csv key_author\n\n.header on\n.mode column\n\nSELECT *\n  FROM key_author\n LIMIT 10;\n\nSELECT count(*)\n  FROM key_author;\n```\nload_bibliography.sql 파일을 실행하게 되면 다음 결과를 얻게 된다.\n$ sqlite3\nSQLite version 3.34.1 2021-01-20 14:10:07\nEnter \".help\" for usage hints.\nConnected to a transient in-memory database.\nUse \".open FILENAME\" to reopen on a persistent database.\n\nsqlite&gt; .read code/load_bibliography.sql\nKey       Author\n--------  --------------------------\n8SW85SQM  McClelland, James L\n85QV9X5F  McClelland, J. L.\n85QV9X5F  McNaughton, B. L.\n85QV9X5F  O'Reilly, R. C.\nZ4X6DT6N  Ratcliff, R.\nF5DGU3Q4  McCloskey, M.\nF5DGU3Q4  Cohen, N. J.\nPNGQMCP5  Buciluǎ, Cristian\nPNGQMCP5  Caruana, Rich\nPNGQMCP5  Niculescu-Mizil, Alexandru\ncount(*)\n--------\n6587\nsqlite&gt; .quit",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>ETL 데이터베이스</span>"
    ]
  },
  {
    "objectID": "etl.html#쿼리-작성",
    "href": "etl.html#쿼리-작성",
    "title": "14  ETL 데이터베이스",
    "section": "14.6 쿼리 작성",
    "text": "14.6 쿼리 작성\n\n14.6.1 다작 저자\n가장 활발히 논문을 저술한 저자를 찾아보자. SQL 쿼리문을 작성해서 가장 빈도수가 높은 저자를 찾아 상위 10명을 추려보자.\n```{sql}\nsqlite&gt; SELECT author, count(*)\n   ...&gt; FROM key_author\n   ...&gt; GROUP BY author\n   ...&gt; ORDER BY count(*) desc\n   ...&gt; LIMIT 10;\n```\n그동안 노력이 결실을 맺은 첫번째 결과로, 단 하나의 명령으로 가장 많이 저술한 저자들을 알아낼 수 있다는 것이다. 두번째로 알게 된 것은 작업이 아직 끝나지 않았다는 점이다. “Bengio, Yoshua”와 “Bengio, Y.”는 거의 확실히 동일 인물이며, “LeCun, Yann”과 “LeCun, Y.”도 마찬가지다. 정말로 누가 가장 많은 논문을 썼는지 알고 싶다면, 동일 인물에 대한 식별작업을 별도로 수행해야 한다.\nAuthor                 count(*)\n---------------------  --------\nBengio, Yoshua         122\nBengio, Y.             111\nHinton, Geoffrey E.    78\nLeCun, Yann            56\nHinton, G. E.          45\nSalakhutdinov, Ruslan  34\nLeCun, Y.              31\nVincent, Pascal        29\nJordan, M. I.          27\nFrasconi, P.           25\n\n\n\n\n\n\n비정규화(Denormalization)는 많은 악의 뿌리가 된다.\n\n\n\n데이터가 표준을 따르고, 어떤 군더더기도 없다면 정규화된 것이다. 예제 데이터는 비정규화(denormalized) 적절한 사례다. 이유는 특정 저자명이 몇가지 다른 방식으로 표현되었다. 경험적(heuristics, 휴리스틱)으로 데이터를 정규화할 수 있다. 예를 들어, “만약 성과 다른 이름의 첫부분이 매칭되면, 동일인으로 간주한다.”와 같은 방식이다. 하지만, 오류가 항상 끼어들 여지가 있다. 예제 데이터에서, “Albar, M.”이 Mohammd Albar 혹은 Michael Albar인지 어느 것이 맞는지 알 수가 없다. 따라서, 경헙적으로 정규화된 데이터에 기초한 대답은 항상 현실에 대한 근사다. 이런 경우에 사용한 경험적 방법과 직접적으로 수행한 변환에 대해 기록하는 것이 매우 중요하다. 그렇게 해서 다른 사람(미래의 본인 자신을 포함해서)이 작업한 결과물을 상호검사할 수 있게 한다.\n\n\n\n\n14.6.2 공저자\n파이썬 데이터 전처리 단계의 일부로 이름을 정규화하고 데이터를 정제하는 작업은 별도로 하지 않고, 다른 질문에 답할 수 있는지 살펴봅시다. 먼저, 공저자로 가장 많이 참여한 저자를 찾아보자.\n```{sql}\nSELECT a.author, b.author \n  FROM key_author a \n  JOIN key_author b USING(key) \n WHERE a.author &gt; b.author\n LIMIT 10;\n```\nAuthor             Author           \n-----------------  -----------------\nMcNaughton, B. L.  McClelland, J. L.\nO'Reilly, R. C.    McClelland, J. L.\nO'Reilly, R. C.    McNaughton, B. L.\nMcCloskey, M.      Cohen, N. J.     \nCaruana, Rich      Buciluǎ, Cristian\nNiculescu-Mizil,   Buciluǎ, Cristian\nNiculescu-Mizil,   Caruana, Rich    \nRigamonti, Robert  Fua, Pascal      \nRigamonti, Robert  Lepetit, Vincent \nSironi, Amos       Fua, Pascal \n(a.author &gt; b.author를 사용하여 각기 다른 저자 쌍이 한 번만 나타나도록 한다.) 만약 다른 저자들이 얼마나 자주 함께 작업했는지 알고 싶다면 어떻게 해야 할까?\n```{sql}\nSELECT a.author, b.author, count(*)\n  FROM key_author a \n  JOIN key_author b USING(key) \n WHERE a.author &gt; b.author\n GROUP BY a.author, b.author\n ORDER BY count(*) desc\nlimit 10;\n```\nAuthor           Author          count(*)  \n---------------  --------------  ----------\nVincent, Pascal  Bengio, Yoshua  27        \nRoux, Nicolas L  Bengio, Yoshua  20        \nDelalleau, Oliv  Bengio, Yoshua  19        \nBengio, Y.       Bengio, S.      18        \nLarochelle, Hug  Bengio, Yoshua  15        \nRoux, Nicolas L  Delalleau, Oli  15        \nVincent, P.      Bengio, Y.      15        \nChapados, N.     Bengio, Y.      14        \nGori, M.         Frasconi, P.    14        \nSalakhutdinov,   Hinton, Geoffr  14  \n다시 한번, 우리는 데이터 정규화 문제에 직면하고 있다: “Vincent, Pascal”과 “Bengio, Yoshua” 쌍은 거의 확실히 “Vincent, P.”와 “Bengio, S.” 쌍과 동일할 것이다. 하지만 이 문제는 수작업으로 데이터를 분석할 때에도 존재했으며, 데이터베이스에 데이터를 넣음으로써 새로운 질문들을 쉽게 물어볼 수 있게 되어, 그렇지 않았다면 다룰 수 없었을 연구를 진행할 수 있게 되었다. 마지막 단계는 작업한 스크립트를 Git에 커밋하고 커피 한잔 하면서 자축할 시간만 남았다.",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>ETL 데이터베이스</span>"
    ]
  },
  {
    "objectID": "etl.html#다른-접근방법",
    "href": "etl.html#다른-접근방법",
    "title": "14  ETL 데이터베이스",
    "section": "14.7 다른 접근방법",
    "text": "14.7 다른 접근방법\n\n14.7.1 R 프로그래밍\n난이도가 있는 복잡한 데이터의 경우 ETL 과정을 통해 데이터베이스에 넣고 SQL 쿼리를 사용하여 원하는 정보를 추출하는 것도 가능하지만 R 프로그래밍을 사용하여 동일한 작업을 수행하는 것도 가능하다. tidyverse 라이브러리를 사용하여 bibliography.csv 데이터를 읽고 처리하는 방식은 다음과 같다. 먼저, read_csv 함수로 파일을 불러오고, janitor::clean_names()로 칼럼명을 정리한 후, select와 set_names로 원하는 칼럼을 선택하고 칼럼명을 지정한다. 그런 다음 mutate와 str_split로 저자 이름을 분할하고, unnest로 이를 펼친 후, count로 각 key와 author 조합의 빈도를 계산하고 필요없는 열을 제거한다. 이후 inner_join을 사용하여 같은 데이터 프레임을 자기 자신과 조인하고, filter로 특정 조건을 만족하는 행을 필터링한다. group_by와 summarise로 그룹별로 집계하고, ungroup, arrange, top_n을 통해 결과를 정렬하고 상위 10개의 결과를 추출한다. 작성된 코드를 통해 저자들 간의 공동 작업 빈도를 분석하여 가장 자주 협업한 저자 쌍을 찾을 수 있다.\n\nlibrary(tidyverse)\n\nbiblio &lt;-  read_csv(\"data/bibliography.csv\", col_names = FALSE )\n\nbiblio_tbl &lt;- biblio |&gt; \n  janitor::clean_names() |&gt; \n  select(x1:x5) |&gt; \n  set_names(c(\"key\", \"jounral\", \"year\", \"author\", \"affiliation\"))\n\nkey_author &lt;- biblio_tbl |&gt; \n  mutate(author = str_split(author, \"; \")) |&gt; \n  unnest(author) |&gt; \n  count(key, author) |&gt; \n  select(-n)\n\nkey_author %&gt;%\n  inner_join(key_author, by = \"key\", suffix = c(\".a\", \".b\")) %&gt;%\n  filter(author.a &gt; author.b) %&gt;%\n  group_by(author.a, author.b) %&gt;%\n  summarise(count = n()) %&gt;%\n  ungroup() %&gt;%\n  arrange(desc(count)) %&gt;%\n  top_n(10, count)\n\n# A tibble: 10 × 3\n   author.a              author.b            count\n   &lt;chr&gt;                 &lt;chr&gt;               &lt;int&gt;\n 1 Vincent, Pascal       Bengio, Yoshua         27\n 2 Roux, Nicolas Le      Bengio, Yoshua         20\n 3 Delalleau, Olivier    Bengio, Yoshua         19\n 4 Bengio, Y.            Bengio, S.             18\n 5 Larochelle, Hugo      Bengio, Yoshua         15\n 6 Roux, Nicolas Le      Delalleau, Olivier     15\n 7 Vincent, P.           Bengio, Y.             15\n 8 Chapados, N.          Bengio, Y.             14\n 9 Gori, M.              Frasconi, P.           14\n10 Salakhutdinov, Ruslan Hinton, Geoffrey E.    14\n\n\n14.7.2 쉘 프로그래밍\n쉘 기반 파이썬 프로그래밍으로 SQL 데이터베이스를 제작하는 방식은 명령줄 인터페이스(CLI)를 통해 파이썬 스크립트를 실행하여 데이터베이스와 테이블을 생성하고 데이터를 조작하는 것이다. 파이썬 sqlite3 라이브러리를 사용하여 데이터베이스 파일을 생성하고 연결을 설정한다. 연결 객체를 사용하여 커서 객체를 생성하고, SQL 명령어를 커서를 통해 실행하여 데이터베이스 테이블을 생성하고 데이터를 삽입한다. 예를 들어, CREATE TABLE SQL 명령어로 테이블을 생성하고, INSERT INTO 명령어로 데이터를 삽입한다. 모든 작업이 끝나면 데이터베이스 연결을 커밋하고 닫아서 변경사항을 저장한다. 이러한 방식을 통해 쉘 환경에서 파이썬 스크립트를 실행하여 데이터베이스를 제어하고 데이터를 처리함으로써, 데이터베이스 작업을 자동화하고 프로그래밍적으로 접근할 수 있는 장점을 제공한다.\nCSV 파일에서 행을 데이터베이스 레코드로 SQL INSERT 문장 통해 삽입한다. 먼저, SQL INSERT 코드를 다음과 같이 작성한다.\nINSERT INTO data VALUES ('8SW85SQM', 'McClelland, James L');\nINSERT INTO data VALUES ('85QV9X5F', 'McClelland, J. L.');\nINSERT INTO data VALUES ('85QV9X5F', 'McNaughton, B. L.');\n그래서, 대신에 상기 데이터를 출력하도록 프로그램을 변경하자:\n```{python}\n# convert-1.py\n# 데이터베이스에 (키값, 저자명) 짝을 집어넣는 SQL 문장을 생성한다.\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nINSERT = \"INSERT INTO data VALUES('{0}', '{1}');\"\n\nraw = open(sys.argv[1], 'r', encoding='utf-8')\n\nreader = csv.reader(raw);\n\nfor line in reader:\n  key, authors = line[0], line[3]\n  for auth in authors.split('; '): # 세미콜론 대신에, 세미콜론과 공백 사용\n    print(INSERT.format(key, auth))\n        \nraw.close()\n```\n첫번째 변경사항이 INSERT 정의로, 삽입 문장에 대한 형식 문자열(format string)이 된다. 두번째 변경사항은 키값과 저자명을 직접적으로 출력하는 대신에, 데이터 값을 str.format 을 사용하는 INSERT 안으로 삽입하는 것이다.\n잘 동작한다, 하지만 “동작한다”라는 말은 단지 “분명한 오류없이 작업완료가 되도록 동작한다”라는 의미다. 더 가까이 검사하면, 문제가 두가지가 보인다:\n\n실제로 어떤 누구도 데이터를 삽입하는데 데이터베이스를 생성해주지는 않는다.\n저자명에 단일 인용부호를 포함할 수 있다.\n\n첫번째 문제는 풀기 쉽다. 프로그램 시작부분에 다음 코드를 추가한다.\nCREATE = 'CREATE TABLE data(key text not null, author text not null);'\n어떤 insert 문장을 출력하기 전에 출력한다. 두번째 문제는 더 까다롭다: 만약 “O’Mear, Fiona” 같은 저자명을 INSERT해서 끼워넣으려면, 결과가 다음과 같이 된다:\n\"INSERT INTO data VALUES('RJS8QDC4', 'O'Mear, Fiona');\"\n상기 방식은 적법한 파이썬 방법이 아니다. 문제 해결방식은 단일 인용부호 대신에 문자열 주위를 이중 인용부호를 사용하는 것이다. 왜냐하면 사람 이름에 이중 인용부호는 포함될 수 없기 때문이다. 변경사항을 마치고 나면, 전체 프로그램은 다음과 같다:\n```{python}\n# convert-2.py\n# 키값과 저자명에 대한 데이터베이스 생성.\n# -*- coding: utf-8 -*-\n\nimport sys\nimport csv\n\nCREATE = 'CREATE TABLE data(key text not null, author text not null);'\nINSERT = 'INSERT INTO data VALUES(\"{0}\", \"{1}\");'\n\nprint(CREATE)\n\nraw = open(sys.argv[1], 'r')\nreader = csv.reader(raw);\nfor line in reader:\n    key, authors = line[0], line[3]\n    for auth in authors.split('; '): # 세미콜론 대신에, 세미콜론과 공백 사용\n        print INSERT.format(key, auth)\nraw.close()\n```\n프로그램을 실행해보자:\n$ python code/convert-2.py data/bibliography.csv | head -5\nCREATE TABLE data(key text not null, author text not null);\nINSERT INTO data VALUES(\"8SW85SQM\", \"McClelland, James L\");\nINSERT INTO data VALUES(\"85QV9X5F\", \"McClelland, J. L.\");\nINSERT INTO data VALUES(\"85QV9X5F\", \"McNaughton, B. L.\");\nINSERT INTO data VALUES(\"85QV9X5F\", \"O'Reilly, R. C.\");\n결과가 상당히 좋아 보인다. 그래서, 실제 데이터베이스를 생성하는데 이것을 사용하기로 한다:\n$ python code/convert-2.py data/bibliography.csv | sqlite3 bibliography.db\n상기 파이프라인 작업은 저자 컴퓨터에서 실행하는데 약 4초 걸렸고, 205 킬로바이트 bibliography.db 파일을 생성했다. 데이터베이스가 담고 있는 것을 살펴보자:\n$ sqlite3 bibliography.db\nSQLite version 3.8.5 2014-08-15 22:37:57\nEnter \".help\" for usage hints.\n\nsqlite&gt; .schema\nCREATE TABLE data(key text not null, author text not null);\n\nsqlite&gt; SELECT * FROM data LIMIT 10;\n8SW85SQM|McClelland, James L\n85QV9X5F|McClelland, J. L.\n85QV9X5F|McNaughton, B. L.\n85QV9X5F|O'Reilly, R. C.\nZ4X6DT6N|Ratcliff, R.\nF5DGU3Q4|McCloskey, M.\nF5DGU3Q4|Cohen, N. J.\nPNGQMCP5|Buciluǎ, Cristian\nPNGQMCP5|Caruana, Rich\nPNGQMCP5|Niculescu-Mizil, Alexandru\n결과가 좋아보인다. 그래서, 질의를 던져보자:\nSELECT author, COUNT(*)\nFROM data\nGROUP BY author\nORDER BY COUNT(*) DESC\nLIMIT 10;\n\nBengio, Yoshua|122\nBengio, Y.|111\nHinton, Geoffrey E.|78\nLeCun, Yann|56\nHinton, G. E.|45\nSalakhutdinov, Ruslan|34\nLeCun, Y.|31\nVincent, Pascal|29\nJordan, M. I.|27\nFrasconi, P.|25\n첫번째로 보이는 것은 프로그램 작업이 성과를 내고 있다는 것이다: 누가 가장 다작하는 저자인지 명령문 하나로 이제는 알아낼 수 있다. 두번째로 보이는 것이 아직 작업을 완수한 것은 아니라는 것이다: “Bengio, Yoshua”와 “Bengio, Y.”는 거의 확실히 동일한 사람이다. 마찬가지로 “LeCun, Yann”와 “LeCun, Y.”도 동일인이다. 정말로 누가 가장 많은 논문을 썼는지 알아내려고 한다면, 동일인에 대한 다른 이름을 맞출 필요가 있다.\n저자명을 정규화하는 대신에, 대답할 수 있는 다른 질문을 살펴보자. 누가 누구와 공동으로 논문을 썼을까?\nSELECT a.author, b.author\nFROM data a\nJOIN data b ON a.key = b.key AND a.author &gt; b.author\nLIMIT 10;\n\n\nMcNaughton, B. L.|McClelland, J. L.\nO'Reilly, R. C.|McClelland, J. L.\nO'Reilly, R. C.|McNaughton, B. L.\nMcCloskey, M.|Cohen, N. J.\nCaruana, Rich|Buciluǎ, Cristian\nNiculescu-Mizil, Alexandru|Buciluǎ, Cristian\nNiculescu-Mizil, Alexandru|Caruana, Rich\nRigamonti, Roberto|Fua, Pascal\nRigamonti, Roberto|Lepetit, Vincent\nSironi, Amos|Fua, Pascal\n(a.author &gt; b.author 을 사용하게 되면, 완전히 다른 저자명 짝이 한번만 나오게 한다.) 다른 저자 짝이 얼마나 자주 함께 논문을 작성했는지 알고자 한다면 어떨까?\nselect a.author, b.author, count(*)\nfrom data a join data b\non a.key=b.key and a.author &gt; b.author\ngroup by a.author, b.author\norder by count(*) desc\nlimit 10;\n\nVincent, Pascal|Bengio, Yoshua|27\nRoux, Nicolas Le|Bengio, Yoshua|20\nDelalleau, Olivier|Bengio, Yoshua|19\nBengio, Y.|Bengio, S.|18\nLarochelle, Hugo|Bengio, Yoshua|15\nRoux, Nicolas Le|Delalleau, Olivier|15\nVincent, P.|Bengio, Y.|15\nChapados, N.|Bengio, Y.|14\nGori, M.|Frasconi, P.|14\nSalakhutdinov, Ruslan|Hinton, Geoffrey E.|14",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>ETL 데이터베이스</span>"
    ]
  },
  {
    "objectID": "etl.html#연습문제",
    "href": "etl.html#연습문제",
    "title": "14  ETL 데이터베이스",
    "section": "연습문제",
    "text": "연습문제\n\n작업을 올바른 방식으로 수행하기\nprint 문장 대신에, sqlite3 라이브러리를 사용해서, 데이터베이스를 생성하도록 파이썬 프로그램을 다시 작성하시오.\n\n\n고유한 쌍\na.author &gt; b.author 을 사용하게 되면 왜 완전히 다른 저자명 짝이 한번만 나타나게 되는지 설명하시오.\n\n\n데이터 정제\n입력값으로 저자명 두명을 받아서 만약 아마도 동일인이면 True를 반환하고 만약 동일인이 아니라면 False를 반환하는 함수를 작성하시오. 작성한 함수를 옆사람과 비교하고, 두명이 불일치하는 사례를 찾을 수 있는가?\n\n\n데이터 정제 (계속)\n지금까지 작성한 함수를 재활용하여 저자명을 정규화하시오. 작업 결과를 옆사람과 비교하시오. 정확하게 저자명과 동일한 목록을 만들어 냈는지 확인하시고, 만약 그렇지 못하다면, 상응하는 목록을 만들어 냈는지 확인하세요.",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>ETL 데이터베이스</span>"
    ]
  },
  {
    "objectID": "spreadsheet.html#엑셀의-한계",
    "href": "spreadsheet.html#엑셀의-한계",
    "title": "13  엑셀에서 데이터베이스로",
    "section": "13.2 엑셀의 한계",
    "text": "13.2 엑셀의 한계\n엑셀은 작은 데이터 분석과 계산에 최적화되어 있지만, 데이터베이스로 사용하는 것에는 제약이 있다. 많은 기업과 조직이 중요한 데이터를 엑셀 스프레드시트에 보관하고 작업하는데, 이는 사소한 실수로 중요한 의사결정이 왜곡될 위험이 있다.\n엑셀을 사용하는 주된 이유는 엑셀 사용 습관으로 데이터를 엑셀로 저장하고 분석하는 습관이 있으며, 데이터 내보내기가 쉽기 때문이다. 또한, 데이터가 작아서 데이터베이스가 필요 없다고 생각하지만, 사업이 커지고 업무량이 늘면서 엑셀의 작업량과 복잡성이 증가한다.\n엑셀 스프레드시트의 단점으로 다음이 많이 언급된다.\n\n한 번에 한 사람만 작업 가능: 다른 사람이 작업 중이면 읽기 전용으로만 접근 가능.\n데이터 감사의 부재: 한 사람이 주로 관리하므로, 그 사람이 떠나면 지식과 정보가 손실될 수 있다.\n정형화된 작업흐름 부족: 엑셀로 정의된 업무 프로세스는 수작업으로 취합과 정리가 필요하다.\n모형 지원 부족: 엑셀은 크기가 커지면 오류에 취약해진다.\n보고서 생성의 어려움: 데이터베이스에서는 쿼리를 통해 보고서를 더 쉽게 생성할 수 있다.\n보안과 규제의 어려움: 스프레드시트는 보안과 규제를 가하기 어렵다.\n\n“여러 기업이 엑셀 사용을 중요한 업무에서 단순히 피하는 것을 넘어 전면 중단시킨 사례가 존재한다. 다음은 스프레드시트 참사1를 기록한 사례들인데, 최근 들어 이런 사례들은 크게 줄어들었다.”\n\n\n\n표 13.2: 역대 엑셀 참사 사례\n\n\n\n\n\n회사\n참사 비용\n발생일\n영향\n참사 개요\n\n\n\n\n옥스포드 대학\n미확인\n’11.12월\n학생 인터뷰 일정 지연\n엑셀이 수식이 꼬여 인터뷰 일정이 뒤죽박죽 2\n\n\nMI5\n미확인\n’11년\n잘못된 전화번호 작업\n엑셀 서식 수식이 꼬여 엉뚱한 전화번호 작업 3\n\n\n’12년 런던 올림픽\n£ 0.5백만\n’12.01월\n티켓 환불 소동\n수영장 10,000 티켓이 초과 판매 (엑셀 입력 오류) 4\n\n\nMouchel\n£ 4.3백만\n’10.11월\nCEO 사임, 주가폭락\n연금펀드평가 £ 4.3백만 엑셀 오류 5\n\n\nC&C Group\n£ 9 백만\n’09.7월\n주가 15% 하락 등\n매출 3% 상승이 아니고 5% 하락, 엑셀 오류 6\n\n\nUK 교통부\n최소 £ 50 백만\n’12.10월\n영국민 추가 세금 부담\n영국 철도 입찰 오류 7\n\n\nKing 펀드\n£ 130 백만\n’11.05월\n브래드 이미지 하락\n웨일즈 지방 NHS 지출 엑셀 오류 8\n\n\nAXA Rosenberg\n£ 150 백만\n’11.02월\n은폐, 벌금, 브래드 이미지 하락\n엑셀 오류를 감춰서 $242 백만 벌금\n\n\nJP Morgan Chase\n£ 250 백만\n’13.01월\n명성, 고객 신뢰도 저하\n바젤 II VaR 위험 평가 엑셀 오류 9\n\n\nFidelity Magellan 펀드\n£ 1.6 십억\n’95.01월\n투자자에게 약속한 배당금 지급 못함\n음수 부호 누락으로 자본이득 과대계상 10\n\n\n미연방준비위원회\n£ 2.5 십억\n’10.10월\n명확하지 않음\n리볼빙 카드 신용액 산출 과정에 엑셀 오류 11\n\n\n하버드 대학\n평가 불능\n’13.04월\n유럽 정부 긴축예산 편성 근거\nGDP 대비 정부 부채 영향도 분석 엑셀 오류 12\n\n\n\n\n\n\n반면, 데이터베이스는 사용자 활동 기록, 정형화된 작업흐름 지원, 오류 감소, 효율적인 보고서 생성 및 강력한 보안과 규제 기능을 제공한다. 따라서 엑셀 스프레드시트 대신 데이터베이스를 사용하는 것이 여러 면에서 이점을 제공한다.\n\n\n\n\n\n\n도널드 럼스펠트와 제니 브라이언\n\n\n\n“전쟁은 가지고 있는 군대와 함께 가야지, 나중에 원하거나 바라는 군대와 함께 가는 것이 아니다” – 도널드 럼스펠트\n“데이터 분석은 알고 있는 도구와 함께 시작하지, 필요한 도구와 함께 시작하는 것이 아니다” – 제니 브라이언",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>엑셀에서 데이터베이스로</span>"
    ]
  },
  {
    "objectID": "spreadsheet.html#엑셀-문제점",
    "href": "spreadsheet.html#엑셀-문제점",
    "title": "14  엑셀에서 데이터베이스로",
    "section": "14.4 엑셀 문제점",
    "text": "14.4 엑셀 문제점\n\n14.4.1 1. 스프레드쉬트를 버려야 하는 6가지 이유 13\n엑셀은 작은 데이터를 가지고 임의 분석과 계산을 하는데 최적화 되었지만, 데이터베이스 기능으로 사용하는 것은 자제하여야 한다. 아주 많은 기업이나 조직에서 마이크로소프트 엑셀 스프레드쉬트에 매우 중요한 데이터로 보관하고 작업을 해서, 사소한 실수로 중요한 의사결정이 왜곡되는 위험에 처해 있다.\n\n스프레드쉬트를 사용하는 이유\n\n항상 엑셀을 사용했다: 항상 데이터를 엑셀로 저장하고 분석해서 사용했다. 하지만, 버튼 하나로 데이터를 내보내기 쉽다.\n데이터베이스를 사용할 만큼 데이터가 충분하지 않다: 데이터가 작아서 데이터베이스를 사용할 이유를 찾지 못하지만, 사업이 커지고, 업무량이 늘어나면서 엑셀 작업량이 높아지고, 복잡성도 커지고, 엑셀 자체에서 처리되는 시간도 늘어난다.\n\n\n\n1.1. 한번에 한사람만 작업이 가능하다.\n해당 시간에 한번만 엑셀로 작업이 가능하다. 만약 다른 직원이 엑셀을 열어 작업을 하게 되면 “읽기 전용(Read-Only)”으로만 볼 수만 있다.\n\n\n1.2. 데이터 감사는 데이터베이스에서만 가능\n보통 한 사람만 엑셀 스프레드쉬트 파일을 생성하고 유지보수한다. 이 직원이 다른 부서로 전보되거나 회사를 떠나게 되면, 모든 지식이 직원과 함께 날아간다. 고로, 해당 업무를 담고 있는 엑셀 스프레드쉬트를 익히는데 수개월이 소요된다.\n이와 비교하여 감사 기능이 제공되는 데이터베이스는 주기적으로 사용자 활동을 기록해서 엑셀 스프레드쉬트가 담고 있는 정보 및 직관도 전달한다.\n\n\n1.3. 데이터베이스는 정형화된 작업흐름을 지원한다.\n업무 프로세스를 엑셀 스프레드쉬트로 정의할 경우, 엑셀 스프레드쉬트 파일을 전자우편으로 다수 개발자, 검토자, 승인자에게 셀 수 없이 많이 전달해야 한다. 더 큰 문제는 이를 취합해서 수작업으로 정리해야 된다.\n하지만, 업무 프로세스를 데이터베이스로 정의할 경우, 특정 사업 요구사항을 해결하는데 작업을 매핑하고, 추적하고 관리하기 편하다. 효과적으로 중앙에서 체계적으로 관리되는 스프레드쉬트, 데이터베이스로 할당된 작업에 대응하기 좋다.\n\n\n1.4. 데이터베이스는 엑셀보다 모형을 보다 잘 지원한다.\n엑셀 스프레드쉬트 업무가 늘어나고 크기가 커지게 되면, 오류에 취약해 진다. 예를 들어, 새로운 수식을 새로운 곳에 복사해서 넣게 되면 셀참조가 엉클어져서 엉뚱한 값이 반영되는 경우도 흔히 발견된다.\n\n\n1.5. 데이터베이스로 보고서 생성이 수월하다.\n데이터베이스에서 쿼리, 쿼리에 기반한 보고서를 작성하기 더 쉽다. 정적 스프레드쉬트와 반대로 관계형 환경에서 데이터를 정렬, 매칭, 조합하기 더 좋다.\n\n\n1.6. 데이터베이스는 보안이 강력하고 규제하기 좋다.\n스프레드쉬트는 규제를 가하고 보안기능을 두기가 마땅치 않는다. 보안과 제한 기능은 완전히 사용자 몫으로 남겨진다. 엑셀 사용자가 수작업으로 모든 것을 식별해서 작업해야 되고 실수한 것도 고쳐야 된다. 스프레드쉬트에 이러한 기능이 거의 전무하기 때문에, 실수한 것도 알아차리지 못한 상태로 그냥 넘어가는 경우가 상당히 많다.\n\n\n\n14.4.2 2. 스프레드쉬트 참사 14\n\n\n\n회사\n참사 비용\n발생일\n영향\n참사 개요\n\n\n\n\n옥스포드 대학\n미확인\n’11.12월\n학생 인터뷰 일정 지연\n엑셀이 수식이 꼬여 인터뷰 일정이 뒤죽박죽 15\n\n\nMI5\n미확인\n’11년\n잘못된 전화번호 작업\n엑셀 서식 수식이 꼬여 엉뚱한 전화번호 작업 16\n\n\n’12년 런던 올림픽\n£ 0.5백만\n’12.01월\n티켓 환불 소동\n수영장 10,000 티켓이 초과 판매 (엑셀 입력 오류) 17\n\n\nMouchel\n£ 4.3백만\n’10.11월\nCEO 사임, 주가폭락\n연금펀드평가 £ 4.3백만 엑셀 오류 18\n\n\nC&C Group\n£ 9 백만\n’09.7월\n주가 15% 하락 등\n매출 3% 상승이 아니고 5% 하락, 엑셀 오류 19\n\n\nUK 교통부\n최소 £ 50 백만\n’12.10월\n영국민 추가 세금 부담\n영국 철도 입찰 오류 20\n\n\nKing 펀드\n£ 130 백만\n’11.05월\n브래드 이미지 하락\n웨일즈 지방 NHS 지출 엑셀 오류 21\n\n\nAXA Rosenberg\n£ 150 백만\n’11.02월\n은폐, 벌금, 브래드 이미지 하락\n엑셀 오류를 감춰서 $242 백만 벌금\n\n\nJP Morgan Chase\n£ 250 백만\n’13.01월\n명성, 고객 신뢰도 저하\n바젤 II VaR 위험 평가 엑셀 오류 22\n\n\nFidelity Magellan 펀드\n£ 1.6 십억\n’95.01월\n투자자에게 약속한 배당금 지급 못함\n음수 부호 누락으로 자본이득 과대계상 23\n\n\n미연방준비위원회\n£ 2.5 십억\n’10.10월\n명확하지 않음\n리볼빙 카드 신용액 산출 과정에 엑셀 오류 24\n\n\n하버드 대학\n평가 불능\n’13.04월\n유럽 정부 긴축예산 편성 근거\nGDP 대비 정부 부채 영향도 분석 엑셀 오류 25",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>엑셀에서 데이터베이스로</span>"
    ]
  },
  {
    "objectID": "spreadsheet.html#엑셀-사용",
    "href": "spreadsheet.html#엑셀-사용",
    "title": "13  엑셀에서 데이터베이스로",
    "section": "13.1 엑셀 사용",
    "text": "13.1 엑셀 사용\n회계부정으로 파산한 엔론(Enron)은 많은 유산(Hermans 와/과 Murphy-Hill 2015)을 남겼다. 유산중에 대기업에서 스프레드쉬트 엑셀을 어떻게 사용했는지에 대한 다양한 사례를 파악할 수 있다. 엑셀 코퍼스 분석 결과에 따르면, 엔론 스프레드시트 중 24%에서 엑셀 오류가 발견되었다. 사용된 함수들 중 핵심적인 15개의 함수가 전체 스프레드시트의 76%를 차지했고, 매일 100개의 스프레드시트가 이메일에 첨부되어 유통되었으며, 전체 전자주편 중 10%에서 스프레드시트가 첨부되거나 주제로 전달되었다.\n\n\n\n표 13.1: 엑셀 빈도수 높은 함수\n\n\n\n\n\n순위\n함수\n스프레드쉬트 갯수\n누적 백분율(%)\n\n\n\n\n1\nSUM\n578\n6.4%\n\n\n2\n+\n1259\n14.0%\n\n\n3\n-\n2262\n25.1%\n\n\n4\n/\n2625\n29.1%\n\n\n5\n*\n3959\n43.9%\n\n\n6\nIF\n4260\n47.3%\n\n\n7\nNOW\n5322\n59.1%\n\n\n8\nAVERAGE\n5664\n62.8%\n\n\n9\nVLOOKUP\n5733\n63.6%\n\n\n10\nROUND\n5990\n66.5%\n\n\n11\nTODAY\n6182\n68.6%\n\n\n12\nSUBTOTAL\n6480\n71.9%\n\n\n13\nMONTH\n6520\n72.3%\n\n\n14\nCELL\n6774\n75.2%\n\n\n15\nYEAR\n6812\n75.6%",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>엑셀에서 데이터베이스로</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "참고문헌",
    "section": "",
    "text": "Hermans, Felienne, and Emerson Murphy-Hill. n.d. “Enron’s\nSpreadsheets and Related Emails: A Dataset and Analysis.” In\n37th International Conference on Software Engineering,\nICSE ’15.",
    "crumbs": [
      "참고문헌"
    ]
  },
  {
    "objectID": "spreadsheet.html#스프레드쉬트-이해하기",
    "href": "spreadsheet.html#스프레드쉬트-이해하기",
    "title": "13  엑셀에서 데이터베이스로",
    "section": "13.3 스프레드쉬트 이해하기",
    "text": "13.3 스프레드쉬트 이해하기\n데이터 분석을 위해, 사람과 컴퓨터 모두 읽을 수 있는 프로그램들이 많이 존재한다. 컴퓨터 프로그램을 열어보면, 컴퓨터가 실행하는 코드와 함께, 컴퓨터에서는 무시되지만 사람에게 매우 중요한 주석이 포함되어 있다. 따라서 컴퓨터와 사람 모두가 읽을 수 있는 코드는 데이터 과학에 필수적이다.\n코드는 사람과 컴퓨터 모두에게 가독성을 제공해야 한다. 그러나 데이터 역시 사람과 컴퓨터 모두에게 가독성을 제공해야 한다는 것이 문제다. 특히 스프레드시트는 사람과 컴퓨터 양쪽 모두에게 가독성을 제공하지 않는 경우가 많다. 스프레드시트는 처음에는 쉽게 접근할 수 있지만, 1주일 지난 후 해독하기 어려운 복잡성을 종종 경험하게 된다.\n“ALGORITHMS BY COMPLEXITY” 그림 13.1 제목 아래에 다양한 알고리즘과 시스템이 복잡도에 따라 나열되어 있으며, 왼쪽에서 오른쪽으로 갈수록 복잡도가 증가한다. 가장 왼쪽에는 “LEFTPAD”와 “QUICKSORT”가 있고, 그 오른쪽에는 “GIT MERGE”가 있다. 그 다음에는 “SELF-DRIVING CAR”과 “GOOGLE SEARCH BACKEND”가 위치하고 있으며 오른쪽 끝에 “SPRAWLING EXCEL SPREADSHEET BUILT UP OVER 20 YEARS BY A CHURCH GROUP IN NEBRASKA TO COORDINATE THEIR SCHEDULING”이라는 문구가 있고, 20년 동안 네브래스카의 한 교회 그룹이 그들의 스케줄링을 조정하기 위해 만들어온 방대한 엑셀 스프레드시트 복잡성을 강조하고 있다.\n\n\n\n\n\n\n그림 13.1: 엑셀 알고리즘 복잡성\n\n\n\n스프레드쉬트는 데이터, 서식, 수식으로 구성된다. 숫자 데이터를 엑셀로 가져오게 되면 엑셀 내장 함수를 통해 수식 계산을 수행하고, 엑셀 사용자 본인 혹은 외부 사람을 위해 서식을 입히는 과정을 거쳐 비로소 완성된 스프레드쉬트가 된다.\n\n\n\n\n\n\n그림 13.2: 엑셀 구성요소\n\n\n\n스프레드쉬트와 R을 비교해 보면, 서로 상응하는 기능이 일대일로 대응되는 것을 확인할 수 있다.\n\n\n\n스프레드쉬트\nR\n\n\n\n\n* 데이터\n* 데이터\n\n\n* 로직\n* .R, .Rmd\n\n\n* 그림\n* .png, .svg\n\n\n* 서식을 갖춘 표\n* .md, .html, .pdf, Shiny 앱\n\n\n* 반응성(reactivity)\n* 빌드와 배포",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>엑셀에서 데이터베이스로</span>"
    ]
  },
  {
    "objectID": "setup.html#r-db-firefox",
    "href": "setup.html#r-db-firefox",
    "title": "1  SQLite3",
    "section": "1.4 파이어폭스 SQLite 관리자",
    "text": "1.4 파이어폭스 SQLite 관리자\nSQLite 데이터베이스 파일에 있는 데이터를 다루기 위해서 이번장에서 주로 R 사용에 집중을 하지만, 다음 웹사이트에서 무료로 이용 가능한 SQLite 데이터베이스 매니저(SQLite Database Manager)로 불리는 파이어폭스 애드온(add-on)을 사용해서 좀더 쉽게 많은 작업을 수행할 수 있다. 파이어폭스 애드온은 크롬 확장 프로그램과 유사한 개념으로 파이어폭스는 개발자들이 많이 사용하는 웹브라우져 중 하나다.\n\nhttps://addons.mozilla.org/en-us/firefox/addon/sqlite-manager/\n\n브라우져를 사용해서 쉽게 테이블을 생성하고, 데이터를 삽입, 편집하고 데이터베이스 데이터에 대해 간단한 SQL 질의를 실행할 수 있다.\n이러한 점에서 데이터베이스 매니저는 텍스트 파일을 작업할 때 사용하는 텍스트 편집기와 유사하다. 텍스트 파일에 하나 혹은 몇개 작업만 수행하고자 하면, 텍스트 편집기에서 파일을 열어 필요한 수정작업을 하고 닫으면 된다. 텍스트 파일에 작업할 사항이 많은 경우는 종종 간단한 R 프로그램을 작성하여 수행한다. 데이터베이스로 작업할 때도 동일한 패턴이 발견된다. 간단한 작업은 데이터베이스 매니저를 통해서 수행하고, 좀더 복잡한 작업은 R로 수행하는 것이 더 편리하다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>SQLite3</span>"
    ]
  },
  {
    "objectID": "prog-r.html#r-도우미-함수",
    "href": "prog-r.html#r-도우미-함수",
    "title": "12  데이터베이스 프로그래밍",
    "section": "12.1 R 도우미 함수",
    "text": "12.1 R 도우미 함수\nR의 데이터베이스 인터페이스 패키지들(예: RSQLite)은 데이터베이스를 탐색하고 전체 테이블을 한 번에 읽거나 쓰는 데 유용한 공통된 도우미 함수(helper function)들을 공유한다.\n데이터베이스의 모든 테이블을 보기 위해서는 dbListTables()를 사용한다.\n```{r}\nconnection &lt;- dbConnect(SQLite(), \"survey.db\")\ndbListTables(connection)\n```\n\"Person\"  \"Site\"    \"Survey\"  \"Visited\"\n테이블 모든 칼럼 이름을 보려면 dbListFields()를 사용한다.\n```{r}\ndbListFields(connection, \"Survey\")\n```\n\"taken\"   \"person\"  \"quant\"   \"reading\"\n전체 테이블을 데이터프레임으로 읽으려면 dbReadTable()을 사용한다.\n```{r}\ndbReadTable(connection, \"Person\")\n```\n        id  personal   family\n1     dyer   William     Dyer\n2       pb     Frank  Pabodie\n3     lake  Anderson     Lake\n4      roe Valentina  Roerich\n5 danforth     Frank Danforth\n데이터베이스에 전체 테이블을 쓰기 위해 dbWriteTable()을 사용한다. R이 행 이름을 별도 열로 쓰는 것을 방지하고자 할 경우, row.names = FALSE 인수를 설정한다. 예시에서 R에 내장된 iris 데이터셋을 survey.db 데이터베이스에 테이블로 쓰는 방법은 다음과 같다.\n```{r}\ndbWriteTable(connection, \"iris\", iris, row.names = FALSE)\nhead(dbReadTable(connection, \"iris\"))\n```\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n그리고 항상 그렇듯이 완료되면 데이터베이스 연결을 닫는 것을 잊지 말자.\n```{r}\ndbDisconnect(connection)\n```",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>데이터베이스 프로그래밍</span>"
    ]
  },
  {
    "objectID": "intro.html#r-db-what-it-is",
    "href": "intro.html#r-db-what-it-is",
    "title": "들어가며",
    "section": "데이터베이스가 뭔가요?",
    "text": "데이터베이스가 뭔가요?\n데이터베이스(database)는 데이터를 저장하기 위한 목적으로 조직된 파일이다. 대부분의 데이터베이스는 키(key)와 값(value)를 매핑한다는 의미에서 딕셔너리처럼 조직되었다. 가장 큰 차이점은 데이터베이스는 디스크(혹은 다른 영구 저장소)에 위치하고 있어서, 프로그램 종료 후에도 정보가 계속 저장된다. 데이터베이스가 영구 저장소에 저장되어서, 컴퓨터 주기억장치(memory) 크기에 제한받는 딕셔너리보다 훨씬 더 많은 정보를 저장할 수 있다.\n딕셔너리처럼, 데이터베이스 소프트웨어는 엄청난 양의 데이터 조차도 매우 빠르게 삽입하고 접근하도록 설계되었다. 컴퓨터가 특정 항목으로 빠르게 찾아갈 수 있도록 데이터베이스에 인덱스(indexes)를 추가한다. 데이터베이스 소프트웨어는 인덱스를 구축하여 성능을 보장한다.\n다양한 목적에 맞춰 서로 다른 많은 데이터베이스 시스템이 개발되어 사용되고 있다. Oracle, MySQL, Microsoft SQL Server, PostgreSQL, SQLite이 여기에 포함된다. 이 책에서는 SQLite를 집중해서 살펴볼 것이다. 왜냐하면 매우 일반적인 데이터베이스이며 파이썬에 이미 내장되어 있기 때문이다. 응용프로그램 내부에서 데이터베이스 기능을 제공하도록 SQLite가 다른 응용프로그램 내부에 내장(embedded)되도록 설계되었다. 예를 들어, 다른 많은 소프트웨어 제품이 그렇듯이, 파이어폭스 브라우져도 SQLite를 사용한다.\n\nhttp://sqlite.org/\n\n이번 장에서 기술하는 트위터 스파이더링 응용프로그램처럼 정보과학(Informatics)에서 마주치는 몇몇 데이터 조작 문제에 SQLite가 적합하다.",
    "crumbs": [
      "들어가며"
    ]
  },
  {
    "objectID": "intro.html#r-db-concept",
    "href": "intro.html#r-db-concept",
    "title": "들어가며",
    "section": "데이터베이스 개념",
    "text": "데이터베이스 개념\n처음 데이터베이스를 볼때 드는 생각은 마치 엑셀같은 다중 시트를 지닌 스프레드쉬트(spreadsheet)같다는 것이다. 데이터베이스에서 주요 데이터 구조물은 테이블(tables), 행(rows), and 열(columns)이 된다.\n\n\n\n데이터베이스 개념\n\n\n관계형 데이터베이스의 기술적인 면을 설명하면 테이블, 행, 열의 개념은 관계(relation), 튜플(tuple), 속성(attribute) 각각 형식적으로 매칭된다. 이번 장에서는 조금 덜 형식 용어를 사용한다.",
    "crumbs": [
      "들어가며"
    ]
  },
  {
    "objectID": "intro.html#r-db-create-table",
    "href": "intro.html#r-db-create-table",
    "title": "들어가며",
    "section": "데이터베이스 테이블 생성",
    "text": "데이터베이스 테이블 생성\n데이터베이스는 R 리스트 혹은 딕셔너리보다 좀더 명확히 정의된 구조를 요구한다. 1\n데이터베이스에 테이블(table)을 생성할 때, 열(column)의 명칭과 각 열(column)에 저장하는 테이터 형식을 사전에 정의해야 한다. 데이터베이스 소프트웨어가 각 열의 데이터 형식을 인식하게 되면, 데이터 형식에 따라 데이터를 저장하고 찾아오는 방법을 가장 효율적인 방식을 선택할 수 있다.\n다음 url에서 SQLite에서 지원되는 다양한 데이터 형식을 살펴볼 수 있다.\n\nhttp://www.sqlite.org/datatypes.html\n\n처음에는 데이터 구조를 사전에 정의하는 것이 불편하게 보이지만, 대용량의 데이터가 데이터베이스에 포함되더라도 데이터의 빠른 접근을 보장하는 잇점이 있다.\n데이터베이스 파일과 데이터베이스에 두개의 열을 가진 Tracks 이름의 테이블을 생성하는 코드는 다음과 같다.\n\nlibrary(RSQLite)\n\nmusic_db  &lt;- \"data/music.sqlite\"\nconn &lt;- dbConnect(drv = SQLite(), dbname= music_db)\n\ndbSendQuery(conn, \"INSERT INTO Tracks (title, plays) VALUES ( ?, ? )\", c('Thunderstruck', 20))\ndbSendQuery(conn, \"INSERT INTO Tracks (title, plays) VALUES ( ?, ? )\", c('My Way', 15))\n\ndbDisconnect(conn)\n\n연결 (connect) 연산은 현재 디렉토리 data/music.sqlite3 파일에 저장된 데이터베이스에 “연결(connection)”한다. 파일이 존재하지 않으면, 자동 생성된다. “연결(connection)”이라고 부르는 이유는 때때로 데이터베이스가 응용프로그램이 실행되는 서버로부터 분리된 “데이터베이스 서버(database server)”에 저장되기 때문이다. 지금 간단한 예제 파일의 경우에 데이터베이스가 로컬 파일 형태로 R 코드 마찬가지로 동일한 디렉토리에 있다.\n파일을 다루는 파일 핸들(file handle)처럼 데이터베이스에 저장된 파일에 연산을 수행하기 위해서 커서(cursor)를 사용한다. cursor()를 호출하는 것은 개념적으로 텍스트 파일을 다룰 때 readLines()을 호출하는 것과 개념적으로 매우 유사하다.\n\n\n\n데이터베이스 커서\n\n\n커서가 생성되면, dbGetQuery() 함수를 사용하여 데이터베이스 콘텐츠에 명령어 실행을 할 수 있다.\n데이터베이스 명령어는 특별한 언어로 표현된다. 단일 데이터베이스 언어를 학습하도록 서로 다른 많은 데이터베이스 업체 사이에서 표준화되었다.\n데이터베이스 언어를 SQL(Structured Query Language 구조적 질의 언어)로 부른다.\n\nhttp://en.wikipedia.org/wiki/SQL\n\n상기 예제에서, 데이터베이스에 두개의 SQL 명령어를 실행했다. 관습적으로 데이터베이스 키워드는 대문자로 표기한다. 테이블명이나 열의 명칭처럼 사용자가 추가한 명령어 부분은 소문자로 표기한다.\n첫 SQL 명령어는 만약 존재한다면 데이터베이스에서 Tracks 테이블을 삭제한다. 동일한 프로그램을 실행해서 오류 없이 반복적으로 Tracks 테이블을 생성하도록하는 패턴이다. DROP TABLE 명령어는 데이터베이스 테이블 및 테이블 콘텐츠 전부를 삭제하니 주의한다. (즉, “실행취소(undo)”가 없다.)\n`dbGetQuery(conn, 'DROP TABLE IF EXISTS Tracks ') `\n두번째 명령어는 title 문자형 열과 plays 정수형 열을 가진 Tracks으로 명명된 테이블을 생성한다.\n`dbGetQuery(conn, 'CREATE TABLE Tracks (title TEXT, plays INTEGER)')`\n이제 Tracks으로 명명된 테이블을 생성했으니, SQL INSERT 연산을 통해 테이블에 데이터를 넣을 수 있다. 다시 한번, 데이터베이스에 연결하여 커서(cursor)를 얻어 작업을 시작한다. 그리고 나서 커서를 사용해서 SQL 명령어를 수행한다.\nSQL INSERT 명령어는 어느 테이블을 사용할지 특정한다. 그리고 나서 (title, plays) 포함할 필드 목록과 테이블 새로운 행에 저장될 VALUES 나열해서 신규 행을 정의를 마친다. 실제 값이 execute() 호출의 두번째 매개변수로 튜플 ('My Way', 15) 로 넘겨는 것을 표기하기 위해서 값을 물음표 (?, ?)로 명기한다.\n\nlibrary(RSQLite)\n\nmusic_db  &lt;- \"data/music.sqlite\"\nconn &lt;- dbConnect(drv = SQLite(), dbname= music_db)\n\ndbSendQuery(conn, \"INSERT INTO Tracks (title, plays) VALUES ( ?, ? )\", \n            c('Thunderstruck', 20))\ndbSendQuery(conn, \"INSERT INTO Tracks (title, plays) VALUES ( ?, ? )\", \n            c('My Way', 15))\n\nprint('Tracks:')\n\ndbGetQuery(conn, 'SELECT title, plays FROM Tracks')\n\ndbSendQuery(conn, \"DELETE FROM Tracks WHERE plays &lt; 100\")\n\ndbDisconnect(conn)\n\n먼저 테이블에 두개 열을 삽입(INSERT)하여 데이터를 데이터베이스에 저장되도록 했다. 그리고 나서, SELECT 명령어를 사용하여 테이블에 방금 전에 삽입한 행을 불러왔다. SELECT 명령어에서 데이터를 어느 열(title, plays)에서, 어느 테이블Tracks에서 가져올지 명세한다. 프로그램 실행결과는 다음과 같다.\n\n&gt; dbGetQuery(conn, 'SELECT title, plays FROM Tracks')\n          title plays\n1 Thunderstruck    20\n2        My Way    15\n\n프로그램 마지막에 SQL 명령어를 실행 사용해서 방금전에 생성한 행을 모두 삭제(DELETE)했기 때문에 프로그램을 반복해서 실행할 수 있다. 삭제(DELETE) 명령어는 WHERE 문을 사용하여 선택 조건을 표현할 수 있다. 따라서 명령문에 조건을 충족하는 행에만 명령문을 적용한다. 이번 예제에서 기준이 모든 행에 적용되어 테이블에 아무 것도 없게 된다. 따라서 프로그램을 반복적으로 실행할 수 있다. 삭제(DELETE)를 실행한 후에 데이터베이스에서 데이터를 완전히 제거했다.",
    "crumbs": [
      "들어가며"
    ]
  },
  {
    "objectID": "intro.html#r-db-sql",
    "href": "intro.html#r-db-sql",
    "title": "들어가며",
    "section": "SQL 요약",
    "text": "SQL 요약\n지금까지, R 예제를 통해서 SQL(Structured Query Language)을 사용했고, SQL 명령어에 대한 기본을 다루었다. 이번 장에서는 SQL 언어를 보고 SQL 구문 개요를 살펴본다.\n대단히 많은 데이터베이스 업체가 존재하기 때문에 호환성의 문제로 SQL(Structured Query Language)이 표준화되었다. 그래서, 여러 업체가 개발한 데이터베이스 시스템 사이에 호환하는 방식으로 커뮤니케이션 가능하다.\n관계형 데이터베이스는 테이블, 행과 열로 구성된다. 열(column)은 일반적으로 텍스트, 숫자, 혹은 날짜 자료형을 갖는다. 테이블을 생성할 때, 열의 명칭과 자료형을 지정한다.\nCREATE TABLE Tracks (title TEXT, plays INTEGER)\n테이블에 행을 삽입하기 위해서 SQL INSERT 명령어를 사용한다.\nINSERT INTO Tracks (title, plays) VALUES ('My Way', 15)\nINSERT 문장은 테이블 이름을 명기한다. 그리고 나서 새로운 행에 놓고자 하는 열/필드 리스트를 명시한다. 그리고 나서 키워드 VALUES와 각 필드 별로 해당하는 값을 넣는다.\nSQL SELECT 명령어는 데이터베이스에서 행과 열을 가져오기 위해 사용된다. SELECT 명령문은 가져오고자 하는 행과 WHERE절을 사용하여 어느 행을 가져올지 지정한다. 선택 사항으로 ORDER BY 절을 이용하여 반환되는 행을 정렬할 수도 있다.\nSELECT * FROM Tracks WHERE title = 'My Way'\n* 을 사용하여 WHERE 절에 매칭되는 각 행의 모든 열을 데이터베이스에서 가져온다.\n주목할 점은 R과 달리 SQL WHERE 절은 등식을 시험하기 위해서 두개의 등치 기호 대신에 단일 등치 기호를 사용한다. WHERE에서 인정되는 다른 논리 연산자는 &lt;,&gt;,&lt;=,&gt;=,!= 이고, 논리 표현식을 생성하는데 AND, OR, 괄호를 사용한다.\n다음과 같이 반환되는 행이 필드값 중 하나에 따라 정렬할 수도 있다.\nSELECT title,plays FROM Tracks ORDER BY title\n행을 제거하기 위해서, SQL DELETE 문장에 WHERE 절이 필요하다. WHERE 절이 어느 행을 삭제할지 결정한다.\nSELECT title,plays FROM Tracks ORDER BY title\n다음과 같이 SQL UPDATE 문장을 사용해서 테이블에 하나 이상의 행 내에 있는 하나 이상의 열을 갱신(UPDATE)할 수 있다.\nUPDATE Tracks SET plays = 16 WHERE title = 'My Way'\nUPDATE 문장은 먼저 테이블을 명시한다. 그리고 나서, SET 키워드 다음에 변경할 필드 리스트 와 값을 명시한다. 그리고 선택사항으로 갱신될 행을 WHERE절에 지정한다. 단일 UPDATE 문장은 WHERE절에서 매칭되는 모든 행을 갱신한다. 혹은 만약 WHERE절이 지정되지 않으면,테이블 모든 행에 대해서 갱신(UPDATE)을 한다.\n네가지 기본 SQL 명령문(INSERT, SELECT, UPDATE, DELETE)은 데이터를 생성하고 유지 관리하는데 필요한 기본적인 4가지 작업을 가능케 한다.",
    "crumbs": [
      "들어가며"
    ]
  },
  {
    "objectID": "hygene.html#db-three-keys",
    "href": "hygene.html#db-three-keys",
    "title": "9  데이터 위생",
    "section": "9.1 세 종류 키",
    "text": "9.1 세 종류 키\n지금까지 데이터를 다중 연결된 테이블에 넣고 키(keys)를 사용하여 행을 연결하는 방식으로 데이터 모델을 생성했는데, 키와 관련된 몇몇 용어를 살펴볼 필요가 있다. 일반적으로 데이터베이스 모델에서 세가지 종류의 키가 사용된다.\n\n논리 키(logical key)는 “실제 세상”이 행을 찾기 위해서 사용하는 키다. 데이터 모델 예제에서, name 필드는 논리키다. 사용자에 대해서 screen_name이고, name 필드를 사용하여 프로그램에서 여러번 사용자 행을 찾을 수 있다. 논리 키에 UNIQUE 제약 사항을 추가하는 것이 의미있다는 것을 종종 이해하게 된다. 논리 키는 어떻게 바깥 세상에서 행을 찾는지 다루기 때문에, 테이블에 동일한 값을 가진 다중 행이 존재한다는 것은 의미가 없다.\n주키(primary key)는 통상적으로 데이터베이스에서 자동 대입되는 숫자다. 프로그램 밖에서는 일반적으로 의미가 없고, 단지 서로 다른 테이블에서 행을 열결할 때만 사용된다. 테이블에 행을 찾을 때, 통상적으로 주키를 사용해서 행을 찾는 것이 가장 빠르게 행을 찾는 방법이다. 주키는 정수형이어서, 매우 적은 저장공간을 차지하고 매우 빨리 비교 혹은 정렬할 수 있다. 이번에 사용된 데이터 모델에서 id 필드가 주키의 한 예가 된다.\n외부 키(foreign key)는 일반적으로 다른 테이블에 연관된 행의 주키를 가리키는 숫자다. 이번에 사용된 데이터 모델의 외부 키의 사례는 from_id다.\n\n주키 id필드명을 호출하고, 항상 외부키에 임의 필드명에 접미사로 _id 붙이는 명명규칙을 사용한다.",
    "crumbs": [
      "SQL",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>데이터 위생</span>"
    ]
  },
  {
    "objectID": "etl.html#db-debugging",
    "href": "etl.html#db-debugging",
    "title": "14  ETL 데이터베이스",
    "section": "14.8 디버깅",
    "text": "14.8 디버깅\nSQLite 데이터베이스에 연결하는 파이썬 프로그램을 개발할 때 하나의 일반적인 패턴은 파이썬 프로그램을 실행하고 SQLite 데이터베이스 브라우저를 통해서 결과를 확인하는 것이다. 브라우저를 통해서 빠르게 프로그램이 정상적으로 작동하는지를 확인할 수 있다.\nSQLite에서 두 프로그램이 동시에 동일한 데이터를 변경하지 못하기 때문에 주의가 필요하다. 예를 들어, 브라우저에서 데이터베이스를 열고 데이터베이스에 변경을 하고 “저장(save)”버튼을 누르지 않는다면, 브라우져는 데이터베이스 파일에 “락(lock)”을 걸구, 다른 프로그램이 파일에 접근하는 것을 막는다. 특히, 파일이 잠겨져 있으면 작성하고 있는 파이썬 프로그램이 파일에 접근할 수 없다.\n해결책은 데이터베이스가 잠겨져 있어서 파이썬 코드가 작동하지 않는 문제를 피하도록 파이썬에서 데이터베이스에 접근하려 시도하기 전에 데이터베이스 브라우져를 닫거나 혹은 File 메뉴를 사용해서 브라우져 데이터베이스를 닫는 것이다.",
    "crumbs": [
      "활용사례",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>ETL 데이터베이스</span>"
    ]
  },
  {
    "objectID": "application.html#about-postgreSQL",
    "href": "application.html#about-postgreSQL",
    "title": "15  DVD 대여 데이터베이스",
    "section": "15.1 PostgreSQL 1 2",
    "text": "15.1 PostgreSQL 1 2\nPostgreSQL은 확장 가능성 및 표준 준수를 강조하는 객체-관계형 데이터베이스 관리 시스템(ORDBMS)의 하나로 BSD 라이선스로 배포되며 오픈소스 개발자 및 관련 회사들이 개발에 참여하고 있다. 소규모의 단일 머신 애플리케이션에서부터 수많은 동시 접속 사용자가 있는 대형의 인터넷 애플리케이션(또는 데이터 웨어하우스용)에 이르기까지 여러 부하를 관리할 수 있으며 macOS 서버의 경우 PostgreSQL은 기본 데이터베이스로 상용 오라클 데이터베이스를 대체하는 오픈소스 데이터베이스로 알려져 있다.\n\n15.1.1 PostgreSQL 설치 3\nPostgreSQL: The World’s Most Advanced Open Source Relational Database 웹사이트에서 PostgreSQL 다운로드 한다. 윈도우에 설치하는 경우 다음을 참고한다. 설치과정에서 나중에 도움이 될만한 정보는 다음과 같다.\n\n설치 디렉토리: C:\\Program Files\\PostgreSQL\\11\n포트: 5432\n사용자명: postgres\n\n\n\n\npostgreSQL 설치\n\n\nPostgreSQL 11 → SQL Shell (psql)을 클릭한 후에 postgreSQL 헬로월드를 찍어본다. 설치과정에서 등록한 비번만 넣어주고 나머지는 로컬호스트와 기본 디폴트 설정된 데이터베이스를 사용할 것이라 postgres 사용자 비밀번호만 넣어준다. 그리고 나서 postgre=# 쉘에 SELECT version() 명령어를 넣어준다.\n\n\n\npostgreSQL 헬로월드\n\n\n\n\n15.1.2 예제 데이터베이스 - pagila 4\nPostgreSQL Sample Database를 Github에서 구해서 설치하거나, PostgreSQL Sample Database, Load PostgreSQL Sample Database을 참조하여 DVD 대여 데이터베이스를 설치한다.\n\nSQL Shell (psql) 쉘을 실행하여 dvd 데이터베이스를 생성한다.\n\n\nDatabase [postgres]:\nPort [5432]:\nUsername [postgres]:\npostgres 사용자의 암호:\npsql (11.5)\n도움말을 보려면 \"help\"를 입력하십시오.\n\npostgres=# CREATE DATABASE dvd;\nCREATE DATABASE\n\n\nWindows + R 단축키를 실행시켜 cmd를 입력하여 윈도우 쉘을 구동시킨다. 그리고 postgreSQL을 설치한 윈도우 디렉토리로 이동한다. C:\\Program Files\\PostgreSQL\\11\\bin 디렉토리가 된다. 그리고 나서 다운받은 dvdrental.zip 파일 압축을 풀어 dvdrental.tar을 지정한다.\n\n\npg_restore 명령어는 데이터베이스를 생성시키는 역할을 한다.\n-U postgres 인자는 사용자를 지정한다.\n-d dvd 인자는 데이터베이스를 지정한다.\nC:\\dvdrental\\dvdrental.tar 인자는 파일로 저장된 데이터베이스 정보를 담고 있다.\n\n\nC:\\Program Files\\PostgreSQL\\11\\bin&gt; pg_restore -U postgres -d dvd C:\\dvdrental\\dvdrental.tar\n암호:\nC:\\Program Files\\PostgreSQL\\11\\bin&gt;\n\n\n\n\npostgreSQL DVD 데이터베이스\n\n\n\n\n15.1.3 DVD 대여 질의문 작성 5\ndvd 데이터베이스가 설치되었기 때문에 쿼리를 던지기 위해서는 postgreSQL 데이터베이스에 접속을 해야한다. 이를 위해서 pgAdmin 4를 실행시키게 되면 웹브라우져에 웹인터페이스가 생기게 된다. 데이터베이스를 dvd로 지정하고 하고 나서, Tools → Query Tool을 클릭하게 되면 해당 데이터베이스 테이블에 쿼리를 던질 수가 있게 된다.\n\n\n\npostgreSQL select 쿼리문 예시\n\n\n\n데이터베이스 사용자 추가\npostgres 사용자는 이미 존재하기 때문에 별도로 tidyverse 사용자를 추가하고 권한을 부여한다. \\du 명령어로 사용자가 정상 등록되었는지 확인한다.\n\npostgres=# create user tidyverse with encrypted password '1234';\nCREATE ROLE\npostgres=# grant all privileges on database dvd to tidyverse;\nGRANT\npostgres=# \\du\n                                 롤 목록\n  롤 이름  |                      속성                      | 소속 그룹:\n-----------+------------------------------------------------+------------\n postgres  | 슈퍼유저, 롤 만들기, DB 만들기, 복제, RLS 통과 | {}\n tidyverse |                                                | {}\n\n\n\nR에서 postgreSQL 연결\npostgreSQL DBMS 내부에 dvd 데이터베이스가 생성되었다. 이를 R에서 작업하기 위해서 RPostgreSQL, DBI 팩키지를 도입한다. dbConnect() 함수에 데이터베이스와 연결에 필요한 모든 정보를 저장시킨다. 그리고 나서 dbGetQuery() 함수로 쿼리를 던져 원하는 결과를 받아온다.\n\nlibrary(DBI)\nlibrary(RPostgres)\n\ncon &lt;- dbConnect(RPostgres::Postgres(), dbname=\"dvd\", \n                 host=\"localhost\",\n                 port=\"5432\", \n                 user=\"postgres\", \n                 password=\"1234\")\n\nactor &lt;- dbGetQuery(con, \"SELECT * FROM actor LIMIT 5\")\n\nDBI::dbDisconnect(con)\n\ndbGetQuery()로 가져온 데이터프레임을 dplyr 동사로 후속작업을 진행한다.\n\nlibrary(tidyverse)\n\nactor %&gt;% \n  filter(actor_id ==1)\n\n  actor_id first_name last_name         last_update\n1        1   Penelope   Guiness 2013-05-26 14:47:57\n\n\n작업에 필요한 테이블 찾기\n데이터베이스에서 쿼리 작업을 수행할 때 가장 먼저 해야 되는 일중의 하나가 적합한 테이블을 찾는 것이다. 이를 위해서 각 DBMS마다 나름대로 정리를 해둔 메타테이블이 존재한다. postgreSQL의 경우는 pg_catalog.pg_tables가 된다. 가장 많이 사용되는 SQL 데이터베이스별로 동일한 사안에 대해서 찾아보자.\n\npostgreSQL: SELECT * FROM pg_catalog.pg_tables;\nsqlite3: .tables\nMS SQL 서버 - Transact-SQL: SELECT * FROM INFORMATION_SCHEMA.TABLES;\nMySQL: SHOW TABLES;\n\n\nqry &lt;- \"SELECT *\n        FROM pg_catalog.pg_tables\"\n\ndbGetQuery(con, qry) %&gt;% \n  filter(schemaname == 'public') \n\n   schemaname     tablename tableowner tablespace hasindexes hasrules hastriggers rowsecurity\n1      public         actor   postgres       &lt;NA&gt;       TRUE    FALSE        TRUE       FALSE\n2      public         store   postgres       &lt;NA&gt;       TRUE    FALSE        TRUE       FALSE\n3      public       address   postgres       &lt;NA&gt;       TRUE    FALSE        TRUE       FALSE\n4      public      category   postgres       &lt;NA&gt;       TRUE    FALSE        TRUE       FALSE\n5      public          city   postgres       &lt;NA&gt;       TRUE    FALSE        TRUE       FALSE\n6      public       country   postgres       &lt;NA&gt;       TRUE    FALSE        TRUE       FALSE\n7      public      customer   postgres       &lt;NA&gt;       TRUE    FALSE        TRUE       FALSE\n8      public    film_actor   postgres       &lt;NA&gt;       TRUE    FALSE        TRUE       FALSE\n9      public film_category   postgres       &lt;NA&gt;       TRUE    FALSE        TRUE       FALSE\n10     public     inventory   postgres       &lt;NA&gt;       TRUE    FALSE        TRUE       FALSE\n11     public      language   postgres       &lt;NA&gt;       TRUE    FALSE        TRUE       FALSE\n12     public        rental   postgres       &lt;NA&gt;       TRUE    FALSE        TRUE       FALSE\n13     public         staff   postgres       &lt;NA&gt;       TRUE    FALSE        TRUE       FALSE\n14     public       payment   postgres       &lt;NA&gt;       TRUE    FALSE        TRUE       FALSE\n15     public          film   postgres       &lt;NA&gt;       TRUE    FALSE        TRUE       FALSE\n\n\n테이블 별 칼럼명\n다음으로 테이블을 찾았다고 하면, 해당되는 칼럼명을 찾을 수 있어야 한다. 이를 통해서 유의미한 의미를 찾아낼 수 있는데 칼럼명을 통해 영감을 받아 다가설 수 있게 된다.\n\ncol_qry &lt;- \"SELECT table_name,\n                   STRING_AGG(column_name, ', ') AS columns\n            FROM information_schema.columns\n            WHERE table_schema = 'public'\n            GROUP BY table_name;\"\n\ndbGetQuery(con, col_qry) %&gt;% \n  filter(table_name %in% c( \"actor\", \"rental\", \"store\"))\n  \nDBI::dbDisconnect(con)\n\n  table_name                                                                               columns\n1      actor                                          actor_id, last_update, first_name, last_name\n2     rental rental_id, rental_date, inventory_id, customer_id, return_date, staff_id, last_update\n3      store                                   store_id, manager_staff_id, address_id, last_update\n\n\nDVD ER 다이어그램\n후속 쿼리 분석 작업을 위해서 도움이 되는 ER 다이어그램은 다음과 같다.\n\n\n\nDVD ER 다이어그램",
    "crumbs": [
      "챗GPT SQL",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>DVD 대여 데이터베이스</span>"
    ]
  },
  {
    "objectID": "application.html#dvd-insight-rental",
    "href": "application.html#dvd-insight-rental",
    "title": "15  DVD 대여 데이터베이스",
    "section": "15.2 DVD DB 인사이트",
    "text": "15.2 DVD DB 인사이트\nDVT 대여 데이터베이스를 설치했다면 다음 단계로 다양한 SQL 쿼리문을 던져 뭔가 가치 있는 정보를 추출해야만 한다. 데이터 과학: “postgreSQL - DVD 대여 데이터베이스”에서 데이터베이스 설치와 접속에 대한 사항은 확인한다.\n\n15.2.1 DB 접속 헬로월드 6\n먼저 DBI::dbConnect()를 통해 접속하고 SQL 쿼리 헬로월드를 던져보자.\n\nlibrary(RPostgres)\n\ncon &lt;- dbConnect(RPostgres::Postgres(), dbname=\"dvd\", \n                 host=\"localhost\",\n                 port=\"5432\", \n                 user=\"postgres\", \n                 password=\"1234\")\n\nactor &lt;- dbGetQuery(con, \"SELECT * FROM actor LIMIT 5\")\n\nactor\n\n  actor_id first_name    last_name         last_update\n1        1   Penelope      Guiness 2013-05-26 14:47:57\n2        2       Nick     Wahlberg 2013-05-26 14:47:57\n3        3         Ed        Chase 2013-05-26 14:47:57\n4        4   Jennifer        Davis 2013-05-26 14:47:57\n5        5     Johnny Lollobrigida 2013-05-26 14:47:57\n\n\n15.2.2 이탈/잔존고객 구매금액\ncustomer 테이블에는 active 칼럼을 통해 잔존고객과 이탈고객을 파악할 수 있다. 이를 통해서 잔존고객과 이탈고객이 몇명이고 구매금액을 파악할 수 있다. 먼저 datamodelr 팩키지를 통해 해당 테이블을 뽑아내서 이를 시각화해보자.\n\nlibrary(tidyverse)\nlibrary(datamodelr)\n\npayment &lt;- tbl(con, \"payment\") %&gt;% collect()\ncustomer &lt;- tbl(con, \"customer\") %&gt;% collect()\n\npayment_customer_model &lt;- dm_from_data_frames(payment, customer)\n\npayment_customer_model &lt;- dm_add_references(\n  payment_customer_model,\n  customer$customer_id ==  payment$customer_id\n)\n\npayment_customer_graph &lt;- dm_create_graph(payment_customer_model, rankdir = \"LR\", col_attr = c(\"column\", \"type\"))\ndm_render_graph(payment_customer_graph)\n\n\n\n\n테이블 구조 시각화 - 구매금액\n\n\ncon을 통해 DVD 대여 데이터베이스에 접속이 이루어진 상태다. 이탈고객과 잔존고객별로 구매금액에 대한 평균, 최소, 최대, 총합계를 구하려면 두 테이블을 INNER JOIN으로 customer_id를 키값으로 합치고 나서 기술통계를 산출한다.\n\nsql_query &lt;- \n\"SELECT active, \n       COUNT(*) AS num_active, \n       MIN(amount) AS min_amt, \n       AVG(amount) AS avg_amt,\n       MAX(amount) AS max_amt, \n       SUM(amount) AS total_amt\nFROM payment AS p\nINNER JOIN customer AS c\n  ON p.customer_id = c.customer_id\nGROUP BY c.active;\"\n\ndbGetQuery(con, sql_query)\n\n  active num_active min_amt  avg_amt max_amt total_amt\n1      0        369    0.99 4.092981   11.99   1510.31\n2      1      14227    0.00 4.203397   11.99  59801.73\n\n\n15.2.3 쟝르별 평균 대여평점\n앞서와 마찬가지로 쟝르별 평균 대여평점을 계산할 수 있는 테이블을 쭉 뽑아본다. 이를 통해서 3개 테이블, 즉 category, film_category, film을 뽑아놓고 각 해당 키값을 사용하여 결합시킨다.\n\ncategory &lt;- tbl(con, \"category\") %&gt;% collect()\nfilm_category &lt;- tbl(con, \"film_category\") %&gt;% collect()\nfilm &lt;- tbl(con, \"film\") %&gt;% collect()\n\nrental_rating_model &lt;- dm_from_data_frames(category, film_category, film)\n\nrental_rating_model &lt;- dm_add_references(\n  rental_rating_model,\n  category$category_id == film_category$category_id,\n  film_category$film_id == film$film_id\n)\n\nrental_rating_graph &lt;- dm_create_graph(rental_rating_model, rankdir = \"LR\", col_attr = c(\"column\", \"type\"))\ndm_render_graph(rental_rating_graph)\n\n\n\n\n테이블 구조 시각화 - 쟝르별 대여평점\n\n\n먼저 film_category와 category를 결합시켜 영화(film)가 속한 쟝르(category)를 파악한다.\n\nrate_qry &lt;- \n\"SELECT * \nFROM category AS c\nINNER JOIN film_category AS fc\n  ON c.category_id = fc.category_id\nLIMIT 5;\"\n\ndbGetQuery(con, rate_qry)\n\n  category_id        name         last_update film_id category_id..5      last_update..6\n1           6 Documentary 2006-02-15 09:46:27       1              6 2006-02-15 10:07:09\n2          11      Horror 2006-02-15 09:46:27       2             11 2006-02-15 10:07:09\n3           6 Documentary 2006-02-15 09:46:27       3              6 2006-02-15 10:07:09\n4          11      Horror 2006-02-15 09:46:27       4             11 2006-02-15 10:07:09\n5           8      Family 2006-02-15 09:46:27       5              8 2006-02-15 10:07:09\n다음으로 film 테이블을 조인하여 rental_rate를 결합하고 쟝르(category) 별로 평균평점을 구하고 이를 ORDER BY ... DESC를 사용해서 내림차순으로 정렬한다.\n\nrate_qry &lt;- \n\"SELECT c.name,\n        AVG(rental_rate) AS avg_rental_rate\nFROM category AS c\nINNER JOIN film_category AS fc\n  ON c.category_id = fc.category_id \nINNER JOIN film AS f\n  ON fc.film_id = f.film_id\nGROUP BY c.category_id\nORDER BY avg_rental_rate DESC;\"\n\ndbGetQuery(con, rate_qry)\n\n          name avg_rental_rate\n1        Games        3.252295\n2       Travel        3.235614\n3       Sci-Fi        3.219508\n4       Comedy        3.162414\n5       Sports        3.125135\n6          New        3.116984\n7      Foreign        3.099589\n8       Horror        3.025714\n9        Drama        3.022258\n10       Music        2.950784\n11    Children        2.890000\n12   Animation        2.808182\n13      Family        2.758116\n14    Classics        2.744386\n15 Documentary        2.666471\n16      Action        2.646250\n\n\n15.2.4 Top 10 DVD 영화\n가장 많이 대여된 Top 10 DVD 영화를 찾아내기 위해서 이에 해당되는 연관 테이블을 검색하여 찾아낸다. film, inventory, rental 테이블을 특정하고 서로 연결시킬 수 있는 키값을 찾아 연결시킨다.\n\nfilm &lt;- tbl(con, \"film\") %&gt;% collect()\ninventory &lt;- tbl(con, \"inventory\") %&gt;% collect()\nrental &lt;- tbl(con, \"rental\") %&gt;% collect()\n\ntop_10_model &lt;- dm_from_data_frames(film, inventory, rental)\n\ntop_10_model &lt;- dm_add_references(\n  top_10_model,\n  film$film_id == inventory$film_id,\n  inventory$inventory_id == rental$inventory_id\n)\n\ntop_10_graph &lt;- dm_create_graph(top_10_model, rankdir = \"LR\", col_attr = c(\"column\", \"type\"))\ndm_render_graph(top_10_graph)\n\n\n\n\n테이블 구조 시각화 - Top 10 DVD 영화\n\n\nfilm → inventory → rental 테이블을 순차적으로 film_id, inventory_id를 키값으로 삼아 결합시킨다. 그리고 나서 가장 많이 대여된 영화를 찾기 위해서 COUNT() 함수로 개수하고 나서 이를 내림차순 정리한다.\n\ntop_query &lt;- \n\"SELECT f.title AS movie_title, \n        COUNT(f.title) AS num_rentals\nFROM film AS f\nINNER JOIN inventory AS i\n  ON f.film_id = i.film_id\nINNER JOIN rental AS r\n  ON i.inventory_id = r.inventory_id\nGROUP BY f.title\nORDER BY num_rentals DESC;\"\n\ndbGetQuery(con, top_query) %&gt;% \n  slice_max(n=10, order_by = num_rentals)\n\n           movie_title num_rentals\n1   Bucket Brotherhood          34\n2     Rocketeer Mother          33\n3       Juggler Hardly          32\n4  Ridgemont Submarine          32\n5        Scalawag Duck          32\n6       Grit Clockwork          32\n7       Forward Temple          32\n8       Timberland Sky          31\n9            Zorro Ark          31\n10        Robbers Joon          31\n11        Hobbit Alien          31\n12        Network Peak          31\n13       Apache Divine          31\n14     Rush Goodfellas          31\n15           Wife Turn          31\n16   Goodfellas Salute          31",
    "crumbs": [
      "챗GPT SQL",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>DVD 대여 데이터베이스</span>"
    ]
  },
  {
    "objectID": "application.html#db-summary",
    "href": "application.html#db-summary",
    "title": "15  DVD 대여 데이터베이스",
    "section": "15.3 요약",
    "text": "15.3 요약\n이번 장은 파이썬에서 데이터베이스 사용 기본적인 개요에 대해 폭넓게 다루었다. 데이터를 저장하기 위해서 파이썬 딕셔너리나 일반적인 파일보다 데이터베이스를 사용하여 코드를 작성하는 것이 훨씬 복잡하다. 그래서, 만약 작성하는 응용프로그램이 실질적으로 데이터베이스 역량을 필요하지 않는다면 굳이 데이터베이스를 사용할 이유는 없다. 데이터베이스가 특히 유용한 상황은 (1) 큰 데이터셋에서 작은 임의적인 갱신이 많이 필요한 응용프로그램을 작성할 때 (2) 데이터가 너무 커서 딕셔너리에 담을 수 없고 반복적으로 정보를 검색할 때, (3) 한번 실행에서 다음 실행 때까지 데이터를 보관하고, 멈추고, 재시작하는데 매우 긴 실행 프로세스를 갖는 경우다.\n많은 응용프로그램 요구사항을 충족시키기 위해서 단일 테이블로 간단한 데이터베이스를 구축할 수 있다. 하지만, 대부분의 문제는 몇개의 테이블과 서로 다른 테이블간에 행이 연결된 관계를 요구한다. 테이블 사이 연결을 만들 때, 좀더 사려깊은 설계와 데이터베이스의 역량을 가장 잘 사용할 수 있는 데이터베이스 정규화 규칙을 따르는 것이 중요하다. 데이터베이스를 사용하는 주요 동기는 처리할 데이터의 양이 많기 때문에, 데이터를 효과적으로 모델링해서 프로그램이 가능하면 빠르게 실행되게 만드는 것이 중요하다.",
    "crumbs": [
      "챗GPT SQL",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>DVD 대여 데이터베이스</span>"
    ]
  }
]