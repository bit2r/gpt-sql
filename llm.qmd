---
editor: 
  markdown: 
    wrap: 72
editor_options: 
  chunk_output_type: console
---

# 오픈 LLM 리더보드


1. mkdir AI_Projects
1. conda create -n sql python=3.11
1. conda activate sql



## LM 스튜디오 설치

LM Studio는 사용자가 다양한 오픈 소스 거대 언어 모델(LLM)을 실험할 수 있는 데스크톱 앱으로 로컬 컴퓨터에서 비용 걱정 없이 LM Studio를 사용해서 OpenAI 호환 로컬 LLM 서버를 업무에 활용할 수 있다. LM Studio에서 오픈소스 LLM 모델을 로컬 서버에 배포하고 OpenAI에서 개발한 `openai` 패키지를 사용해서 OpenAI API와 동일한 방식으로 로컬 LLM 서버에 접근할 수 있기 때문에 기존 OpenAI API를 가정하고 제작한 소스코드를 재사용할 수 있다는 점에서 매우 유용하다.

먼저 LM Studio를 설치하기 위해서는 [LM Studio 웹사이트](https://lmstudio.ai/)에서 운영체제에 맞게 앱을 다운로드 받아서 설치한다. 좌측 돋보기 모양 아이콘을 클릭하여 검색창에 `sql`을 입력하면 `sql`을 학습한 LLM 모델을 찾을 수 있고 안내에 따라 다운로드하면 SQL 코드를 생성하는 AI 모델을 로컬 컴퓨터에 설치하게 된다.

![SQL 코드 생성 LLM 검색](images/llm_studio_sql.jpg){#fig:llm_studio_sql}


좌측 메뉴에서 채팅 아이콘을 클릭하면, 다운로드 받은 LLM 모델을 상단 "Select a model to load"에서 골라 로드하면 OpenAI 챗GPT 서비스처럼 대화형으로 SQL 코드를 작성해 나갈 수 있다.

![`sqlcoder` 34B LLM 모형 채팅](images/llm_sqlcoder_chat.jpg){#fig:llm_sqlcoder_chat}

좌측 채팅 아이콘 아래 양방향 화살표(&harr;)를 클릭하면 "Local Inference Server" 아래 "Start Server" 버튼이 있고 이를 클릭하면 오픈소스 LLM 모델을 서버로 배포하여 OpenAI 호환 API를 사용하는 것처럼 로컬 LLM 서버에 접근할 수 있게 된다. "Client Code Example"에서 `curl`, 파이썬(`chat`, `ai assistant`, `vision`) 예제 코드가 주석과 함께 제시되어 있어 이를 참고하여 후속 개발작업에 유용하게 활용할 수 있다.


![](images/llm_studio_code.jpg)

## `survey.db` 쿼리

앞서 개발자가 직접 SQL 쿼리를 직접 작성하는 대신 SQL 특화된 LLM 모델을 사용하여 SQL 쿼리를 생성하는 것도 가능하다. 정확도 높은 SQL 쿼리를 작성하기 위해 명확하게 역할도 부여하고 데이터베이스 스키마 정보도 함께 제공하여 LLM 모델이 SQL 쿼리를 생성할 수 있도록 환경을 설정하고 자연어로 원하는 바를 지정하면 SQL 쿼리를 생성하고 관련 설명도 함께 출력하다. 

주목할 점은 4GB 전후 크기를 갖는 SQL LLM은 생각보다 SQL 쿼리 생성이 눈높이에 맞게 되는 것은 아닌 것으로 보이며, 35.86 GB 크기를 갖는 `sqlcoder` LLM 모델은 SQL 쿼리 생성에 있어서 더욱 정확한 결과를 보여주고 있다. 물론, OpenAI GPT-4와 비교하면 속도를 비롯하여 여러가지 면에서 부족한 것으로 보이지만 가격이 무료이며, 다른 제약조건이 없다는 점을 생각하면 충분히 사용할 만한 수준이라고 생각된다. 또한, 오픈소스 SQL LLM은 지속적으로 발전을 할 것이기 때문에 작년과 비교하여 올해 비약적인 발전이 이뤄질 것으로 예상된다.


``` {{python}}

# Example: reuse your existing OpenAI setup
from openai import OpenAI

# Point to the local server
client = OpenAI(base_url = "http://localhost:1234/v1", 
                api_key  = "not-needed")

system_message = """
You are an expert in SQL. The following table definitions have been provided to you. Please convert my query into an appropriate SQL statement. \n
    
    CREATE TABLE Person(
            ident    text,
            personal text,
            family   text
    );
    CREATE TABLE Site(
            name text,
            lat  real,
            long real
    );
    CREATE TABLE Visited(
            ident integer,
            site  text,
            dated text
    );
    CREATE TABLE Survey(
            taken   integer,
            person  text,
            quant   text,
            reading real
    ); \n
"""    

completion = client.chat.completions.create(
  model="local-model", # this field is currently unused
  messages=[
    {"role": "system", 
    "content": system_message},
    {"role": "user", 
    "content": "No explanation. Write only SQL query that returns - display the names of scientists"}
  ],
  temperature=0.7,
)

print(completion.choices[0].message.content)
```

``` bash
SELECT DISTINCT p.ident FROM person p JOIN visited v ON p.ident = v.ident JOIN survey s ON p.ident = s.person WHERE s.quant ILIKE '%radiation%';
```

## SQL 데이터셋

[@dataherald2023texttosql]

GPT-4와 Bard 같은 AI 모델의 자연어 처리 능력이 급격히 향상되면서,
자연어로 질문된 내용에 대한 SQL 쿼리를 생성하는 '텍스트-투-SQL'과 같은
다양한 NLP 사용 사례에 대한 발전이 가속화되고 있다. 여러 접근 방식과
솔루션이 시장에 나오면서 어느 것이 가장 효율적인지, 어느 것이 정확한
답을 더 신뢰성 있게 생성하는지, 어느 것이 다양한 데이터셋에 가장 잘
적응하는지 평가하는 문제가 생겼다. 이 질문들에 답하기 위해 오픈소스
산업과 학계는 여러 벤치마크를 제시했지만, 오늘날 가장 많이 사용되는 세
가지는 WikiSQL, Spider, BIRD(BIg Bench for LaRge-scale Database Grounded
Text-to-SQL Evaluation)이다. WikiSQL은 Salesforce에 의해 2017년 말에
소개된 최초의 대규모 텍스트-투-SQL 데이터 집합이지만, 단순함이라는 큰
단점이 있다. 제공되는 모든 SQL 쿼리는 SELECT, FROM, WHERE 절만을
포함하는 매우 간단하며, 데이터셋 내의 테이블들은 다른 테이블과의 연결이
없다. WikiSQL로 훈련된 모델은 새로운 데이터베이스에서도 작동할 수
있지만, 간단한 자연어 질문에 대해서만 답할 수 있다. 이러한 이유로 최근
텍스트-투-SQL 분야의 연구는 더 복잡한 벤치마크에 초점을 맞추고 있다.
실제로 WikiSQL 리더보드에는 2021년 이전의 제출물만 있으며, 테스트 정확도
90% 이상을 달성한 여러 제출물들이 있지만(가장 성능이 좋은 제출물은 93%에
도달함), 이제 실무자들은 WikiSQL로는 턱없이 부족한 훨씬 더 복잡한 쿼리
생성에 초점을 맞추고 있다.

Spider 데이터셋은 WikiSQL 데이터셋의 단점 중 일부를 보완하려고 한다.
예일 대학의 11명 학생들이 1,000시간 이상의 노력을 통해 개발된 Spider
데이터셋은 복잡성과 교차 도메인성이라는 두 가지 중요한 요소를 도입한다.
복잡성 측면에서 SQL 쿼리는 WikiSQL이 한정된 간단한 SELECT와 WHERE 절을
넘어서, 더 복잡한 GROUP BY, ORDER BY, HAVING 절과 중첩된 쿼리를
포함한다. 또한, 모든 데이터베이스는 외래 키를 통해 여러 테이블이
연결되어 있어 테이블 간에 조인하는 복잡한 쿼리를 가능하게 한다. 교차
도메인성 측면에서 Spider는 200개의 복잡한 데이터베이스를 많은 도메인에
걸쳐 포함하여, 테스트 세트에서 본 적 없는 데이터베이스를 포함시켜 모델의
일반화 가능성을 테스트할 수 있게 한다. 

